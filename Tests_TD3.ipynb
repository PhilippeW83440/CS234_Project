{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twin Delayed DDPG\n",
    "Out of https://github.com/openai/spinningup/blob/master/spinup/algos/td3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.py  __pycache__  td3.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls spinup/algos/td3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# td3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spinup.algos.td3 import core\n",
    "from spinup.algos.td3.core import get_vars\n",
    "from spinup.utils.logx import EpochLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A simple FIFO experience replay buffer for TD3 agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs1_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.obs2_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, act_dim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs1_buf[self.ptr] = obs\n",
    "        self.obs2_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr+1) % self.max_size\n",
    "        self.size = min(self.size+1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size=32):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        return dict(obs1=self.obs1_buf[idxs],\n",
    "                    obs2=self.obs2_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TD3 (Twin Delayed DDPG)\n",
    "\"\"\"\n",
    "def td3(env_fn, actor_critic=core.mlp_actor_critic, ac_kwargs=dict(), seed=0, \n",
    "        steps_per_epoch=5000, epochs=100, replay_size=int(1e6), gamma=0.99, \n",
    "        polyak=0.995, pi_lr=1e-3, q_lr=1e-3, batch_size=100, start_steps=10000, \n",
    "        act_noise=0.1, target_noise=0.2, noise_clip=0.5, policy_delay=2, \n",
    "        max_ep_len=1000, logger_kwargs=dict(), save_freq=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        env_fn : A function which creates a copy of the environment.\n",
    "            The environment must satisfy the OpenAI Gym API.\n",
    "        actor_critic: A function which takes in placeholder symbols \n",
    "            for state, ``x_ph``, and action, ``a_ph``, and returns the main \n",
    "            outputs from the agent's Tensorflow computation graph:\n",
    "            ===========  ================  ======================================\n",
    "            Symbol       Shape             Description\n",
    "            ===========  ================  ======================================\n",
    "            ``pi``       (batch, act_dim)  | Deterministically computes actions\n",
    "                                           | from policy given states.\n",
    "            ``q1``       (batch,)          | Gives one estimate of Q* for \n",
    "                                           | states in ``x_ph`` and actions in\n",
    "                                           | ``a_ph``.\n",
    "            ``q2``       (batch,)          | Gives another estimate of Q* for \n",
    "                                           | states in ``x_ph`` and actions in\n",
    "                                           | ``a_ph``.\n",
    "            ``q1_pi``    (batch,)          | Gives the composition of ``q1`` and \n",
    "                                           | ``pi`` for states in ``x_ph``: \n",
    "                                           | q1(x, pi(x)).\n",
    "            ===========  ================  ======================================\n",
    "        ac_kwargs (dict): Any kwargs appropriate for the actor_critic \n",
    "            function you provided to TD3.\n",
    "        seed (int): Seed for random number generators.\n",
    "        steps_per_epoch (int): Number of steps of interaction (state-action pairs) \n",
    "            for the agent and the environment in each epoch.\n",
    "        epochs (int): Number of epochs to run and train agent.\n",
    "        replay_size (int): Maximum length of replay buffer.\n",
    "        gamma (float): Discount factor. (Always between 0 and 1.)\n",
    "        polyak (float): Interpolation factor in polyak averaging for target \n",
    "            networks. Target networks are updated towards main networks \n",
    "            according to:\n",
    "            .. math:: \\\\theta_{\\\\text{targ}} \\\\leftarrow \n",
    "                \\\\rho \\\\theta_{\\\\text{targ}} + (1-\\\\rho) \\\\theta\n",
    "            where :math:`\\\\rho` is polyak. (Always between 0 and 1, usually \n",
    "            close to 1.)\n",
    "        pi_lr (float): Learning rate for policy.\n",
    "        q_lr (float): Learning rate for Q-networks.\n",
    "        batch_size (int): Minibatch size for SGD.\n",
    "        start_steps (int): Number of steps for uniform-random action selection,\n",
    "            before running real policy. Helps exploration.\n",
    "        act_noise (float): Stddev for Gaussian exploration noise added to \n",
    "            policy at training time. (At test time, no noise is added.)\n",
    "        target_noise (float): Stddev for smoothing noise added to target \n",
    "            policy.\n",
    "        noise_clip (float): Limit for absolute value of target policy \n",
    "            smoothing noise.\n",
    "        policy_delay (int): Policy will only be updated once every \n",
    "            policy_delay times for each update of the Q-networks.\n",
    "        max_ep_len (int): Maximum length of trajectory / episode / rollout.\n",
    "        logger_kwargs (dict): Keyword args for EpochLogger.\n",
    "        save_freq (int): How often (in terms of gap between epochs) to save\n",
    "            the current policy and value function.\n",
    "    \"\"\"\n",
    "\n",
    "    logger = EpochLogger(**logger_kwargs)\n",
    "    logger.save_config(locals())\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    env, test_env = env_fn(), env_fn()\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    # Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "    act_limit = env.action_space.high[0]\n",
    "\n",
    "    # Share information about action space with policy architecture\n",
    "    ac_kwargs['action_space'] = env.action_space\n",
    "\n",
    "    # Inputs to computation graph\n",
    "    x_ph, a_ph, x2_ph, r_ph, d_ph = core.placeholders(obs_dim, act_dim, obs_dim, None, None)\n",
    "\n",
    "    # Main outputs from computation graph\n",
    "    with tf.variable_scope('main'):\n",
    "        pi, q1, q2, q1_pi = actor_critic(x_ph, a_ph, **ac_kwargs)\n",
    "    \n",
    "    # Target policy network\n",
    "    with tf.variable_scope('target'):\n",
    "        pi_targ, _, _, _  = actor_critic(x2_ph, a_ph, **ac_kwargs)\n",
    "    \n",
    "    # Target Q networks\n",
    "    with tf.variable_scope('target', reuse=True):\n",
    "\n",
    "        # Target policy smoothing, by adding clipped noise to target actions\n",
    "        epsilon = tf.random_normal(tf.shape(pi_targ), stddev=target_noise)\n",
    "        epsilon = tf.clip_by_value(epsilon, -noise_clip, noise_clip)\n",
    "        a2 = pi_targ + epsilon\n",
    "        a2 = tf.clip_by_value(a2, -act_limit, act_limit)\n",
    "\n",
    "        # Target Q-values, using action from target policy\n",
    "        _, q1_targ, q2_targ, _ = actor_critic(x2_ph, a2, **ac_kwargs)\n",
    "\n",
    "    # Experience buffer\n",
    "    replay_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=replay_size)\n",
    "\n",
    "    # Count variables\n",
    "    var_counts = tuple(core.count_vars(scope) for scope in ['main/pi', 'main/q1', 'main/q2', 'main'])\n",
    "    print('\\nNumber of parameters: \\t pi: %d, \\t q1: %d, \\t q2: %d, \\t total: %d\\n'%var_counts)\n",
    "\n",
    "    # Bellman backup for Q functions, using Clipped Double-Q targets\n",
    "    min_q_targ = tf.minimum(q1_targ, q2_targ)\n",
    "    backup = tf.stop_gradient(r_ph + gamma*(1-d_ph)*min_q_targ)\n",
    "\n",
    "    # TD3 losses\n",
    "    pi_loss = -tf.reduce_mean(q1_pi)\n",
    "    q1_loss = tf.reduce_mean((q1-backup)**2)\n",
    "    q2_loss = tf.reduce_mean((q2-backup)**2)\n",
    "    q_loss = q1_loss + q2_loss\n",
    "\n",
    "    # Separate train ops for pi, q\n",
    "    pi_optimizer = tf.train.AdamOptimizer(learning_rate=pi_lr)\n",
    "    q_optimizer = tf.train.AdamOptimizer(learning_rate=q_lr)\n",
    "    train_pi_op = pi_optimizer.minimize(pi_loss, var_list=get_vars('main/pi'))\n",
    "    train_q_op = q_optimizer.minimize(q_loss, var_list=get_vars('main/q'))\n",
    "\n",
    "    # Polyak averaging for target variables\n",
    "    target_update = tf.group([tf.assign(v_targ, polyak*v_targ + (1-polyak)*v_main)\n",
    "                              for v_main, v_targ in zip(get_vars('main'), get_vars('target'))])\n",
    "\n",
    "    # Initializing targets to match main variables\n",
    "    target_init = tf.group([tf.assign(v_targ, v_main)\n",
    "                              for v_main, v_targ in zip(get_vars('main'), get_vars('target'))])\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(target_init)\n",
    "\n",
    "    # Setup model saving\n",
    "    logger.setup_tf_saver(sess, inputs={'x': x_ph, 'a': a_ph}, outputs={'pi': pi, 'q1': q1, 'q2': q2})\n",
    "\n",
    "    def get_action(o, noise_scale):\n",
    "        a = sess.run(pi, feed_dict={x_ph: o.reshape(1,-1)})[0]\n",
    "        a += noise_scale * np.random.randn(act_dim)\n",
    "        return np.clip(a, -act_limit, act_limit)\n",
    "\n",
    "    def test_agent(n=10):\n",
    "        for j in range(n):\n",
    "            o, r, d, ep_ret, ep_len = test_env.reset(), 0, False, 0, 0\n",
    "            while not(d or (ep_len == max_ep_len)):\n",
    "                # Take deterministic actions at test time (noise_scale=0)\n",
    "                o, r, d, _ = test_env.step(get_action(o, 0))\n",
    "                ep_ret += r\n",
    "                ep_len += 1\n",
    "            logger.store(TestEpRet=ep_ret, TestEpLen=ep_len)\n",
    "\n",
    "    start_time = time.time()\n",
    "    o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "\n",
    "    # Main loop: collect experience in env and update/log each epoch\n",
    "    for t in range(total_steps):\n",
    "\n",
    "        \"\"\"\n",
    "        Until start_steps have elapsed, randomly sample actions\n",
    "        from a uniform distribution for better exploration. Afterwards, \n",
    "        use the learned policy (with some noise, via act_noise). \n",
    "        \"\"\"\n",
    "        if t > start_steps:\n",
    "            a = get_action(o, act_noise)\n",
    "        else:\n",
    "            a = env.action_space.sample()\n",
    "\n",
    "        # Step the env\n",
    "        o2, r, d, _ = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "\n",
    "        # Ignore the \"done\" signal if it comes from hitting the time\n",
    "        # horizon (that is, when it's an artificial terminal signal\n",
    "        # that isn't based on the agent's state)\n",
    "        d = False if ep_len==max_ep_len else d\n",
    "\n",
    "        # Store experience to replay buffer\n",
    "        replay_buffer.store(o, a, r, o2, d)\n",
    "\n",
    "        # Super critical, easy to overlook step: make sure to update \n",
    "        # most recent observation!\n",
    "        o = o2\n",
    "\n",
    "        if d or (ep_len == max_ep_len):\n",
    "            \"\"\"\n",
    "            Perform all TD3 updates at the end of the trajectory\n",
    "            (in accordance with source code of TD3 published by\n",
    "            original authors).\n",
    "            \"\"\"\n",
    "            for j in range(ep_len):\n",
    "                batch = replay_buffer.sample_batch(batch_size)\n",
    "                feed_dict = {x_ph: batch['obs1'],\n",
    "                             x2_ph: batch['obs2'],\n",
    "                             a_ph: batch['acts'],\n",
    "                             r_ph: batch['rews'],\n",
    "                             d_ph: batch['done']\n",
    "                            }\n",
    "                q_step_ops = [q_loss, q1, q2, train_q_op]\n",
    "                outs = sess.run(q_step_ops, feed_dict)\n",
    "                logger.store(LossQ=outs[0], Q1Vals=outs[1], Q2Vals=outs[2])\n",
    "\n",
    "                if j % policy_delay == 0:\n",
    "                    # Delayed policy update\n",
    "                    outs = sess.run([pi_loss, train_pi_op, target_update], feed_dict)\n",
    "                    logger.store(LossPi=outs[0])\n",
    "\n",
    "            logger.store(EpRet=ep_ret, EpLen=ep_len)\n",
    "            o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "        # End of epoch wrap-up\n",
    "        if t > 0 and t % steps_per_epoch == 0:\n",
    "            epoch = t // steps_per_epoch\n",
    "\n",
    "            # Save model\n",
    "            if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
    "                logger.save_state({'env': env}, None)\n",
    "\n",
    "            # Test the performance of the deterministic version of the agent.\n",
    "            test_agent()\n",
    "\n",
    "            # Log info about epoch\n",
    "            logger.log_tabular('Epoch', epoch)\n",
    "            logger.log_tabular('EpRet', with_min_and_max=True)\n",
    "            logger.log_tabular('TestEpRet', with_min_and_max=True)\n",
    "            logger.log_tabular('EpLen', average_only=True)\n",
    "            logger.log_tabular('TestEpLen', average_only=True)\n",
    "            logger.log_tabular('TotalEnvInteracts', t)\n",
    "            logger.log_tabular('Q1Vals', with_min_and_max=True)\n",
    "            logger.log_tabular('Q2Vals', with_min_and_max=True)\n",
    "            logger.log_tabular('LossPi', average_only=True)\n",
    "            logger.log_tabular('LossQ', average_only=True)\n",
    "            logger.log_tabular('Time', time.time()-start_time)\n",
    "            logger.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env='HalfCheetah-v1'\n",
    "env='InvertedPendulum-v1'\n",
    "env='Act-v0'\n",
    "hid=300\n",
    "l=1\n",
    "gamma=0.99\n",
    "seed=0\n",
    "epochs=10\n",
    "exp_name='td3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spinup.utils.run_utils import setup_logger_kwargs\n",
    "logger_kwargs = setup_logger_kwargs(exp_name, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:15,094] Making new env: Act-v0\n",
      "[2019-03-05 19:11:15,121] Making new env: Act-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Log dir /home/phw/rsl/CS234_Project/data/td3/td3_s0 already exists! Storing info there anyway.\n",
      "\u001b[32;1mLogging data to /home/phw/rsl/CS234_Project/data/td3/td3_s0/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"ac_kwargs\":\t{\n",
      "        \"hidden_sizes\":\t[\n",
      "            300\n",
      "        ]\n",
      "    },\n",
      "    \"act_noise\":\t0.1,\n",
      "    \"actor_critic\":\t\"mlp_actor_critic\",\n",
      "    \"batch_size\":\t100,\n",
      "    \"env_fn\":\t\"<function <lambda> at 0x7f169803fe18>\",\n",
      "    \"epochs\":\t10,\n",
      "    \"exp_name\":\t\"td3\",\n",
      "    \"gamma\":\t0.99,\n",
      "    \"logger\":\t{\n",
      "        \"<spinup.utils.logx.EpochLogger object at 0x7f1698045470>\":\t{\n",
      "            \"epoch_dict\":\t{},\n",
      "            \"exp_name\":\t\"td3\",\n",
      "            \"first_row\":\ttrue,\n",
      "            \"log_current_row\":\t{},\n",
      "            \"log_headers\":\t[],\n",
      "            \"output_dir\":\t\"/home/phw/rsl/CS234_Project/data/td3/td3_s0\",\n",
      "            \"output_file\":\t{\n",
      "                \"<_io.TextIOWrapper name='/home/phw/rsl/CS234_Project/data/td3/td3_s0/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "                    \"mode\":\t\"w\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"logger_kwargs\":\t{\n",
      "        \"exp_name\":\t\"td3\",\n",
      "        \"output_dir\":\t\"/home/phw/rsl/CS234_Project/data/td3/td3_s0\"\n",
      "    },\n",
      "    \"max_ep_len\":\t1000,\n",
      "    \"noise_clip\":\t0.5,\n",
      "    \"pi_lr\":\t0.001,\n",
      "    \"policy_delay\":\t2,\n",
      "    \"polyak\":\t0.995,\n",
      "    \"q_lr\":\t0.001,\n",
      "    \"replay_size\":\t1000000,\n",
      "    \"save_freq\":\t1,\n",
      "    \"seed\":\t0,\n",
      "    \"start_steps\":\t10000,\n",
      "    \"steps_per_epoch\":\t5000,\n",
      "    \"target_noise\":\t0.2\n",
      "}\n",
      "SEED 14848834666164876081\n",
      "SEED 1552366166952441554\n",
      "\n",
      "Number of parameters: \t pi: 13801, \t q1: 14101, \t q2: 14101, \t total: 42003\n",
      "\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:26,864] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:26,866] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:27,059] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               1 |\n",
      "|      AverageEpRet |            -694 |\n",
      "|          StdEpRet |             459 |\n",
      "|          MaxEpRet |            44.6 |\n",
      "|          MinEpRet |       -1.01e+03 |\n",
      "|  AverageTestEpRet |            -960 |\n",
      "|      StdTestEpRet |            18.1 |\n",
      "|      MaxTestEpRet |            -910 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |             321 |\n",
      "|         TestEpLen |            20.1 |\n",
      "| TotalEnvInteracts |           5e+03 |\n",
      "|     AverageQ1Vals |            -545 |\n",
      "|         StdQ1Vals |             318 |\n",
      "|         MaxQ1Vals |            87.3 |\n",
      "|         MinQ1Vals |       -2.43e+03 |\n",
      "|     AverageQ2Vals |            -545 |\n",
      "|         StdQ2Vals |             320 |\n",
      "|         MaxQ2Vals |             392 |\n",
      "|         MinQ2Vals |       -3.35e+03 |\n",
      "|            LossPi |             545 |\n",
      "|             LossQ |        5.31e+03 |\n",
      "|              Time |            11.3 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:39,859] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:39,861] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:40,067] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               2 |\n",
      "|      AverageEpRet |            -731 |\n",
      "|          StdEpRet |             432 |\n",
      "|          MaxEpRet |           -10.4 |\n",
      "|          MinEpRet |       -1.01e+03 |\n",
      "|  AverageTestEpRet |            -745 |\n",
      "|      StdTestEpRet |             423 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -966 |\n",
      "|             EpLen |             292 |\n",
      "|         TestEpLen |            27.3 |\n",
      "| TotalEnvInteracts |           1e+04 |\n",
      "|     AverageQ1Vals |            -680 |\n",
      "|         StdQ1Vals |             362 |\n",
      "|         MaxQ1Vals |           -73.8 |\n",
      "|         MinQ1Vals |          -2e+03 |\n",
      "|     AverageQ2Vals |            -680 |\n",
      "|         StdQ2Vals |             361 |\n",
      "|         MaxQ2Vals |           -73.3 |\n",
      "|         MinQ2Vals |       -2.01e+03 |\n",
      "|            LossPi |             678 |\n",
      "|             LossQ |             229 |\n",
      "|              Time |            24.4 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:56,478] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:56,479] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:11:56,694] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               3 |\n",
      "|      AverageEpRet |            -882 |\n",
      "|          StdEpRet |             294 |\n",
      "|          MaxEpRet |             901 |\n",
      "|          MinEpRet |            -983 |\n",
      "|  AverageTestEpRet |            -751 |\n",
      "|      StdTestEpRet |             426 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -982 |\n",
      "|             EpLen |            25.4 |\n",
      "|         TestEpLen |            24.6 |\n",
      "| TotalEnvInteracts |         1.5e+04 |\n",
      "|     AverageQ1Vals |            -603 |\n",
      "|         StdQ1Vals |             318 |\n",
      "|         MaxQ1Vals |           -49.8 |\n",
      "|         MinQ1Vals |       -1.83e+03 |\n",
      "|     AverageQ2Vals |            -603 |\n",
      "|         StdQ2Vals |             318 |\n",
      "|         MaxQ2Vals |           -54.2 |\n",
      "|         MinQ2Vals |       -1.87e+03 |\n",
      "|            LossPi |             601 |\n",
      "|             LossQ |             806 |\n",
      "|              Time |              41 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:12,072] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:12,073] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:12,301] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               4 |\n",
      "|      AverageEpRet |            -812 |\n",
      "|          StdEpRet |             372 |\n",
      "|          MaxEpRet |            98.8 |\n",
      "|          MinEpRet |            -983 |\n",
      "|  AverageTestEpRet |            -956 |\n",
      "|      StdTestEpRet |            12.9 |\n",
      "|      MaxTestEpRet |            -934 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |              23 |\n",
      "|         TestEpLen |              22 |\n",
      "| TotalEnvInteracts |           2e+04 |\n",
      "|     AverageQ1Vals |            -622 |\n",
      "|         StdQ1Vals |             300 |\n",
      "|         MaxQ1Vals |             175 |\n",
      "|         MinQ1Vals |       -1.57e+03 |\n",
      "|     AverageQ2Vals |            -622 |\n",
      "|         StdQ2Vals |             300 |\n",
      "|         MaxQ2Vals |             136 |\n",
      "|         MinQ2Vals |       -1.56e+03 |\n",
      "|            LossPi |             622 |\n",
      "|             LossQ |        1.43e+03 |\n",
      "|              Time |            56.6 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:29,183] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:29,184] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:29,423] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               5 |\n",
      "|      AverageEpRet |            -844 |\n",
      "|          StdEpRet |             333 |\n",
      "|          MaxEpRet |            98.7 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -965 |\n",
      "|      StdTestEpRet |            9.55 |\n",
      "|      MaxTestEpRet |            -944 |\n",
      "|      MinTestEpRet |            -978 |\n",
      "|             EpLen |            23.1 |\n",
      "|         TestEpLen |            17.3 |\n",
      "| TotalEnvInteracts |         2.5e+04 |\n",
      "|     AverageQ1Vals |            -618 |\n",
      "|         StdQ1Vals |             301 |\n",
      "|         MaxQ1Vals |             282 |\n",
      "|         MinQ1Vals |       -1.39e+03 |\n",
      "|     AverageQ2Vals |            -618 |\n",
      "|         StdQ2Vals |             301 |\n",
      "|         MaxQ2Vals |             276 |\n",
      "|         MinQ2Vals |       -1.41e+03 |\n",
      "|            LossPi |             619 |\n",
      "|             LossQ |        2.34e+03 |\n",
      "|              Time |            73.7 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:44,679] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:44,681] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:12:44,929] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               6 |\n",
      "|      AverageEpRet |            -857 |\n",
      "|          StdEpRet |             314 |\n",
      "|          MaxEpRet |            99.1 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -963 |\n",
      "|      StdTestEpRet |            8.99 |\n",
      "|      MaxTestEpRet |            -944 |\n",
      "|      MinTestEpRet |            -976 |\n",
      "|             EpLen |            23.2 |\n",
      "|         TestEpLen |            18.3 |\n",
      "| TotalEnvInteracts |           3e+04 |\n",
      "|     AverageQ1Vals |            -615 |\n",
      "|         StdQ1Vals |             304 |\n",
      "|         MaxQ1Vals |             352 |\n",
      "|         MinQ1Vals |       -1.24e+03 |\n",
      "|     AverageQ2Vals |            -615 |\n",
      "|         StdQ2Vals |             304 |\n",
      "|         MaxQ2Vals |             346 |\n",
      "|         MinQ2Vals |       -1.23e+03 |\n",
      "|            LossPi |             615 |\n",
      "|             LossQ |         3.4e+03 |\n",
      "|              Time |            89.2 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:00,278] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:00,279] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:00,571] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               7 |\n",
      "|      AverageEpRet |            -824 |\n",
      "|          StdEpRet |             357 |\n",
      "|          MaxEpRet |            98.7 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -841 |\n",
      "|      StdTestEpRet |             314 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -976 |\n",
      "|             EpLen |            23.3 |\n",
      "|         TestEpLen |            29.6 |\n",
      "| TotalEnvInteracts |         3.5e+04 |\n",
      "|     AverageQ1Vals |            -617 |\n",
      "|         StdQ1Vals |             308 |\n",
      "|         MaxQ1Vals |             431 |\n",
      "|         MinQ1Vals |       -1.16e+03 |\n",
      "|     AverageQ2Vals |            -617 |\n",
      "|         StdQ2Vals |             308 |\n",
      "|         MaxQ2Vals |             400 |\n",
      "|         MinQ2Vals |       -1.16e+03 |\n",
      "|            LossPi |             616 |\n",
      "|             LossQ |        3.79e+03 |\n",
      "|              Time |             105 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:16,083] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:16,084] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:16,371] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               8 |\n",
      "|      AverageEpRet |            -858 |\n",
      "|          StdEpRet |             318 |\n",
      "|          MaxEpRet |              99 |\n",
      "|          MinEpRet |            -983 |\n",
      "|  AverageTestEpRet |            -751 |\n",
      "|      StdTestEpRet |             426 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -982 |\n",
      "|             EpLen |            21.6 |\n",
      "|         TestEpLen |            24.5 |\n",
      "| TotalEnvInteracts |           4e+04 |\n",
      "|     AverageQ1Vals |            -624 |\n",
      "|         StdQ1Vals |             315 |\n",
      "|         MaxQ1Vals |             434 |\n",
      "|         MinQ1Vals |       -1.13e+03 |\n",
      "|     AverageQ2Vals |            -624 |\n",
      "|         StdQ2Vals |             315 |\n",
      "|         MaxQ2Vals |             414 |\n",
      "|         MinQ2Vals |       -1.17e+03 |\n",
      "|            LossPi |             624 |\n",
      "|             LossQ |        3.83e+03 |\n",
      "|              Time |             121 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:32,244] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:32,245] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:13:32,563] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/td3/td3_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               9 |\n",
      "|      AverageEpRet |            -868 |\n",
      "|          StdEpRet |             304 |\n",
      "|          MaxEpRet |            98.5 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -646 |\n",
      "|      StdTestEpRet |             488 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -978 |\n",
      "|             EpLen |            21.3 |\n",
      "|         TestEpLen |            27.1 |\n",
      "| TotalEnvInteracts |         4.5e+04 |\n",
      "|     AverageQ1Vals |            -635 |\n",
      "|         StdQ1Vals |             320 |\n",
      "|         MaxQ1Vals |             448 |\n",
      "|         MinQ1Vals |       -1.16e+03 |\n",
      "|     AverageQ2Vals |            -635 |\n",
      "|         StdQ2Vals |             320 |\n",
      "|         MaxQ2Vals |             435 |\n",
      "|         MinQ2Vals |       -1.14e+03 |\n",
      "|            LossPi |             635 |\n",
      "|             LossQ |        3.93e+03 |\n",
      "|              Time |             137 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "td3(lambda : gym.make(env), \n",
    "    actor_critic=core.mlp_actor_critic,\n",
    "    ac_kwargs=dict(hidden_sizes=[hid]*l),\n",
    "    gamma=gamma, \n",
    "    seed=seed, \n",
    "    epochs=epochs,\n",
    "    logger_kwargs=logger_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
