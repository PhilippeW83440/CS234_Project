{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Collision Tests Environment - openai gym compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def  resize_images(images, f=3):\n",
    "    big_images = []\n",
    "    for img in images:\n",
    "        big_images.append(cv2.resize(img, None, fx=f, fy=f))\n",
    "    return big_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist(obj1, obj2):\n",
    "    return math.sqrt((obj1[0]-obj2[0])**2 + (obj1[1]-obj2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_nearest_obj(s):\n",
    "    nobjs = int(len(s)/4 - 1)\n",
    "    ego = s[0:4]\n",
    "    \n",
    "    dist_nearest_obj = math.inf\n",
    "    num_nearest_obj = -1\n",
    "    \n",
    "    idx = 4\n",
    "    for n in range(nobjs):\n",
    "        obj = s[idx:idx+4]\n",
    "        dist = get_dist(ego, obj)\n",
    "        \n",
    "        if dist < dist_nearest_obj:\n",
    "            dist_nearest_obj = dist\n",
    "            num_nearest_obj = n\n",
    "        idx += 4\n",
    "    \n",
    "    return dist_nearest_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_to_goal(s, goal):\n",
    "    return get_dist(s[0:4], goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Constraint w.r.t. Time To Collision\n",
    "\n",
    "We want to find out the TTC between ego and each object objects  \n",
    "This is a key information in the decision making process  \n",
    "\n",
    "**We want to define a Hard Constraint s.t. $s_{t+1}=\\pi_{\\theta}(a_t \\mid s_t)$, get_smallest_TTC($s_{t+1}$) >= margin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the TTC between 2 objects:  \n",
    "* Compute $t=TTC$ such that distance$(\\begin{bmatrix}x_1+\\dot{x_1}t \\\\ y_1+ \\dot{y_1}t \\end{bmatrix} - \\begin{bmatrix}x_2+\\dot{x_2}t \\\\ y_2+\\dot{y_2}t \\end{bmatrix}) <= R$    \n",
    "* R should be replaced by the delta of the 2 objects' radius... i.e. when they collide...    \n",
    "* That's just a quadratic equation in t  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[(x_1 - x_2) + (\\dot{x}_1 - \\dot{x}_2)t]^2 + [(y_1 - y_2) + (\\dot{y}_1 - \\dot{y}_2)t]^2 \\leq R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ t^2 [(\\dot{x}_1 - \\dot{x}_2)^2+(\\dot{y}_1 - \\dot{y}_2)^2] + 2t [(x_1 - x_2)(\\dot{x}_1-\\dot{x}_2)+(y_1 - y_2) (\\dot{y}_1 - \\dot{y}_2)] + [(x_1 - x_2)^2 + (y_1 - y_2)^2] \\leq R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find $t=TTC$ s.t.:\n",
    "$$ at^2 + bt + c = 0$$  \n",
    "with:  \n",
    "* $a=[(\\dot{x}_1 - \\dot{x}_2)^2+(\\dot{y}_1 - \\dot{y}_2)^2]$   \n",
    "* $b= 2 [(x_1 - x_2)(\\dot{x}_1 - \\dot{x}_2)+(y_1 - y_2) (\\dot{y}_1 - \\dot{y}_2)]$  \n",
    "* $c=[(x_1 - x_2)^2 + (y_1 - y_2)^2] - R^2$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_TTC(ego, obj, radius):\n",
    "    x1, y1, vx1, vy1 = ego[0], ego[1], ego[2], ego[3]\n",
    "    x2, y2, vx2, vy2 = obj[0], obj[1], obj[2], obj[3]\n",
    "\n",
    "    a = (vx1 - vx2) **2 + (vy1 - vy2) **2\n",
    "    b = 2 * ((x1 - x2) * (vx1 - vx2) + (y1 - y2) * (vy1 - vy2))\n",
    "    c = (x1 - x2) **2 + (y1 - y2) **2 - radius **2\n",
    "\n",
    "    if a == 0 and b == 0:\n",
    "        if c == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.inf\n",
    "\n",
    "    if a == 0 and b != 0:\n",
    "        t = -c / b\n",
    "        if t < 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return t\n",
    "\n",
    "    delta = b **2 - 4 * a * c\n",
    "    if delta < 0:\n",
    "        return np.inf\n",
    "\n",
    "    t1 = (-b - np.sqrt(delta)) / (2 * a)\n",
    "    t2 = (-b + np.sqrt(delta)) / (2 * a)\n",
    "    if t1 < 0:\n",
    "        t1 = np.inf\n",
    "\n",
    "    if t2 < 0:\n",
    "        t2 = np.inf\n",
    "\n",
    "    return min(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smallest_TTC(s):\n",
    "    radius = 15.0\n",
    "    ego = s[0:4]\n",
    "    \n",
    "    smallest_TTC = np.Inf\n",
    "    smallest_TTC_obj = -1\n",
    "    \n",
    "    idx = 4\n",
    "    for n in range(int((len(s)-4)/4)):\n",
    "        obj = s[idx:idx+4]\n",
    "        TTC = get_TTC(ego, obj, radius)\n",
    "        \n",
    "        if TTC < smallest_TTC:\n",
    "            smallest_TTC = TTC\n",
    "            smallest_TTC_obj = n\n",
    "        idx += 4\n",
    "    \n",
    "    return smallest_TTC, smallest_TTC_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist:  141.4213562373095\n",
      "TTC:  4.4696699141100895\n"
     ]
    }
   ],
   "source": [
    "# just checking\n",
    "obj1 = np.array([0.0, 100, 20, 0])\n",
    "obj2 = np.array([100, 0.0, 0, 20])\n",
    "print(\"dist: \", get_dist(obj1, obj2))\n",
    "print(\"TTC: \", get_TTC(obj1, obj2, 15.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Made up ...\n",
    "\n",
    "class BasicDriverModel():\n",
    "    # stationarity: 1 is very aggressive, 4 is not very aggressive\n",
    "    def __init__(self, statio=3.0, dt=0.2):\n",
    "        self.state = \"SPEED_CONSTANT\" # SACCEL SCONSTANT\n",
    "        self.stationarity = statio # every 1, 2, 3 or 4 seconds\n",
    "        self.accel = 0 # -1 0 1 random uniform on ax\n",
    "        self.duration = 0\n",
    "        self.dt = dt\n",
    "        \n",
    "    def step(self):\n",
    "        if self.state == \"SPEED_CONSTANT\":\n",
    "            self.duration += self.dt\n",
    "            if self.duration >= self.stationarity:\n",
    "                self.accel = np.random.randint(low=-1, high=2)\n",
    "                self.state = \"SPEED_CHANGE\"\n",
    "                self.duration = 0\n",
    "        elif self.state == \"SPEED_CHANGE\":\n",
    "            self.duration += self.dt\n",
    "            if self.duration >= self.stationarity:\n",
    "                self.accel = 0\n",
    "                self.state = \"SPEED_CONSTANT\"\n",
    "                self.duration = 0\n",
    "        return self.accel, self.state  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n",
      "accel 1 state SPEED_CHANGE\n"
     ]
    }
   ],
   "source": [
    "driver = BasicDriverModel(statio=2.0)\n",
    "for i in range(20):\n",
    "    accel, state = driver.step()\n",
    "    print(\"accel {} state {}\".format(accel, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cf https://en.wikipedia.org/wiki/Intelligent_driver_model\n",
    "# cf https://github.com/sisl/AutoUrban.jl/blob/master/src/drivermodels/IDMDriver.jl\n",
    "\n",
    "class IntelligentDriverModel():\n",
    "    def __init__(self, v_des = 29.0):\n",
    "        self.a = None # predicted acceleration\n",
    "        self.sigma = 0 # optional stdev on top of the model, set to zero for deterministic behavior\n",
    "        \n",
    "        self.k_spd = 1.0 # proportional constant for speed tracking when in freeflow [s⁻¹]\n",
    "        \n",
    "        self.delta = 4.0 # acceleration exponent [-]\n",
    "        self.T = 1.5 # desired time headway [s]\n",
    "        self.v_des = v_des # desired speed [m/s], typically overwritten\n",
    "        self.s_min = 5.0 # minimum acceptable gap [m]\n",
    "        self.a_max = 3.0 # maximum acceleration ability [m/s²]\n",
    "        self.d_cmf = 2.0 # comfortable deceleration [m/s²] (positive)\n",
    "        self.d_max = 9.0 # maximum decelleration [m/s²] (positive)\n",
    "        \n",
    "    def step(self, v_ego, v_oth, headway):\n",
    "        if v_oth is not None:\n",
    "            assert headway is not None and headway > 0, \"v_oth None but headway > 0\"\n",
    "            if headway > 0.0:\n",
    "                dv = v_oth - v_ego\n",
    "                s_des = self.s_min + v_ego * self.T - v_ego * dv / (2 * math.sqrt(self.a_max * self.d_cmf))\n",
    "                \n",
    "                if self.v_des > 0.0:\n",
    "                    v_ratio = v_ego / self.v_des\n",
    "                else:\n",
    "                    v_ratio = 1.0\n",
    "                                        \n",
    "                self.a = self.a_max * (1.0 - v_ratio**self.delta - (s_des / headway)**2)\n",
    "            # elseif headway > -3.0\n",
    "            #    model.a = -model.d_max\n",
    "            else:\n",
    "                dv = self.v_des - v_ego\n",
    "                self.a = dv * self.k_spd\n",
    "        else:\n",
    "            # no lead vehicle, just drive to match desired speed\n",
    "            dv = self.v_des - v_ego\n",
    "            self.a = dv * self.k_spd # predicted accel to match target speed\n",
    "\n",
    "        if self.a is None:\n",
    "            print(\"headway: {} v_oth: {} v_ego: {}\".format(headway, v_oth, v_ego))\n",
    "        assert self.a is not None, \"idm accel None\"\n",
    "\n",
    "        self.a = np.clip(self.a, -self.d_max, self.a_max)\n",
    "        \n",
    "        if self.sigma > 0:\n",
    "            self.a += self.sigma * np.random.randn()\n",
    "            self.a = np.clip(self.a, -self.d_max, self.a_max)\n",
    "            \n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_ego 10.6 a 3.0\n",
      "v_ego 11.2 a 3.0\n",
      "v_ego 11.799999999999999 a 3.0\n",
      "v_ego 12.399999999999999 a 3.0\n",
      "v_ego 12.999999999999998 a 3.0\n",
      "v_ego 13.599999999999998 a 3.0\n",
      "v_ego 14.199999999999998 a 3.0\n",
      "v_ego 14.799999999999997 a 3.0\n",
      "v_ego 15.399999999999997 a 3.0\n",
      "v_ego 15.999999999999996 a 3.0\n",
      "v_ego 16.599999999999998 a 3.0\n",
      "v_ego 17.2 a 3.0\n",
      "v_ego 17.8 a 3.0\n",
      "v_ego 18.400000000000002 a 3.0\n",
      "v_ego 19.000000000000004 a 3.0\n",
      "v_ego 19.600000000000005 a 3.0\n",
      "v_ego 20.200000000000006 a 3.0\n",
      "v_ego 20.800000000000008 a 3.0\n",
      "v_ego 21.40000000000001 a 3.0\n",
      "v_ego 22.00000000000001 a 3.0\n",
      "v_ego 22.600000000000012 a 3.0\n",
      "v_ego 23.200000000000014 a 3.0\n",
      "v_ego 23.800000000000015 a 3.0\n",
      "v_ego 24.400000000000016 a 3.0\n",
      "v_ego 25.000000000000018 a 3.0\n",
      "v_ego 25.60000000000002 a 3.0\n",
      "v_ego 26.20000000000002 a 3.0\n",
      "v_ego 26.800000000000022 a 3.0\n",
      "v_ego 27.400000000000023 a 3.0\n",
      "v_ego 27.92000000000002 a 2.5999999999999766\n",
      "v_ego 28.336000000000016 a 2.0799999999999805\n",
      "v_ego 28.66880000000001 a 1.6639999999999837\n",
      "v_ego 28.935040000000008 a 1.3311999999999884\n",
      "v_ego 29.148032000000008 a 1.0649599999999921\n",
      "v_ego 29.318425600000005 a 0.8519679999999923\n",
      "v_ego 29.454740480000005 a 0.6815743999999953\n",
      "v_ego 29.563792384000003 a 0.5452595199999948\n",
      "v_ego 29.651033907200002 a 0.43620761599999724\n",
      "v_ego 29.720827125760003 a 0.3489660927999978\n",
      "v_ego 29.776661700608003 a 0.2791728742399968\n",
      "v_ego 29.821329360486402 a 0.22333829939199745\n",
      "v_ego 29.857063488389123 a 0.17867063951359796\n",
      "v_ego 29.8856507907113 a 0.14293651161087695\n",
      "v_ego 29.90852063256904 a 0.11434920928870085\n",
      "v_ego 29.926816506055232 a 0.09147936743095997\n",
      "v_ego 29.941453204844187 a 0.07318349394476797\n",
      "v_ego 29.95316256387535 a 0.05854679515581296\n",
      "v_ego 29.96253005110028 a 0.04683743612465108\n",
      "v_ego 29.970024040880226 a 0.03746994889971944\n",
      "v_ego 29.976019232704182 a 0.02997595911977413\n",
      "v_ego 29.980815386163346 a 0.023980767295817884\n",
      "v_ego 29.984652308930677 a 0.019184613836653597\n",
      "v_ego 29.98772184714454 a 0.015347691069322877\n",
      "v_ego 29.990177477715633 a 0.012278152855458302\n",
      "v_ego 29.992141982172505 a 0.009822522284366642\n",
      "v_ego 29.993713585738004 a 0.007858017827494734\n",
      "v_ego 29.994970868590404 a 0.006286414261996498\n",
      "v_ego 29.995976694872322 a 0.005029131409596488\n",
      "v_ego 29.99678135589786 a 0.004023305127677901\n",
      "v_ego 29.997425084718287 a 0.0032186441021408996\n"
     ]
    }
   ],
   "source": [
    "driver = IntelligentDriverModel(v_des=30.0)\n",
    "v_ego = 10\n",
    "dt = 0.2\n",
    "for i in range(60):\n",
    "    a = driver.step(v_ego, None, None)\n",
    "    v_ego += a*dt\n",
    "    print(\"v_ego {} a {}\".format(v_ego, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai gym Anti Collision Test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Anti Collision Tests env compatible with gym openai interface\n",
    "##################################################################\n",
    "\n",
    "# API eg https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "\n",
    "stationarity = 4.0\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "def draw_arrow(image, p, q, color, arrow_magnitude=5, thickness=1, line_type=4, shift=0):\n",
    "    # adapted from http://mlikihazar.blogspot.com.au/2013/02/draw-arrow-opencv.html\n",
    "    # draw arrow tail\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "    # calc angle of the arrow\n",
    "    angle = np.arctan2(p[1]-q[1], p[0]-q[0])\n",
    "    # starting point of first line of arrow head\n",
    "    p = (int(q[0] + arrow_magnitude * np.cos(angle + np.pi/4)),\n",
    "    int(q[1] + arrow_magnitude * np.sin(angle + np.pi/4)))\n",
    "    # draw first half of arrow head\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "    # starting point of second line of arrow head\n",
    "    p = (int(q[0] + arrow_magnitude * np.cos(angle - np.pi/4)),\n",
    "    int(q[1] + arrow_magnitude * np.sin(angle - np.pi/4)))\n",
    "    # draw second half of arrow head\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "\n",
    "# Transition with Constant Acceleration model\n",
    "def transition_ca(s, a, dt=0.2):\n",
    "    Ts = np.matrix([[1.0, 0.0, dt,  0.0], \n",
    "                [0.0, 1.0, 0.0, dt],\n",
    "                [0.0, 0.0, 1.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 1.0]])\n",
    "    Ta = np.matrix([[0.5*dt**2, 0.0],\n",
    "                [0.0,      0.5*dt**2],\n",
    "                [dt,       0.0],\n",
    "                [0.0,      dt]])\n",
    "    return np.dot(Ts, s) + np.dot(Ta, a)\n",
    "\n",
    "\n",
    "class ActEnv(gym.Env):\n",
    "    def __init__(self, nobjs, max_accel=2, dist_collision=10, reward_shaping=True):    \n",
    "        self.nobjs = nobjs\n",
    "        self.max_accel = max_accel\n",
    "        self.dist_collision = dist_collision\n",
    "        self.reward_shaping = reward_shaping\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-self.max_accel, high=self.max_accel, shape=(1,))\n",
    "        # 1+nobjs: x,y,vx,vy with x,y in [0,200] and vx,vy in [0,40]\n",
    "        self.observation_space = spaces.Box(low=0.0, high=200.0, shape=((1+nobjs)*4,))\n",
    "        \n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        print(\"SEED {}\".format(seed))\n",
    "        return [seed]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.reward = None\n",
    "        self.steps_beyond_done = 0\n",
    "        self.steps = 0\n",
    "        self.smallest_TTC_obj = -1\n",
    "        \n",
    "        self.drivers = []\n",
    "        \n",
    "        # x, y, vx, vy\n",
    "        self.start = np.array([100.0,   0.0,  0.0,  20.0], dtype=int)\n",
    "        self.goal  = np.array([100.0, 200.0, 0.0, 0.0], dtype=int)\n",
    "        # states init\n",
    "        state = ego = self.start\n",
    "        for n in range(int(self.nobjs/2)):\n",
    "            x = self.np_random.randint(low=0, high=50)\n",
    "            y = self.np_random.randint(low=25, high=190)\n",
    "            vx = self.np_random.randint(low=10, high=25)\n",
    "            vy = self.np_random.randint(low=0, high=5)\n",
    "            obj = np.array([x, y, vx, vy])\n",
    "            state = np.append(state, obj)\n",
    "            driver = BasicDriverModel(statio=stationarity)\n",
    "            self.drivers.append(driver)\n",
    "        \n",
    "        for n in range(int(self.nobjs/2)):\n",
    "            x = self.np_random.randint(low=150, high=200)\n",
    "            y = self.np_random.randint(low=25, high=190)\n",
    "            vx = - self.np_random.randint(low=10, high=25)\n",
    "            vy = - self.np_random.randint(low=0, high=5)\n",
    "            obj = np.array([x, y, vx, vy])\n",
    "            state = np.append(state, obj)\n",
    "            driver = BasicDriverModel(statio=stationarity)\n",
    "            self.drivers.append(driver)\n",
    "            \n",
    "        print(state)  \n",
    "        self.s = state\n",
    "        \n",
    "        return self.s\n",
    "    \n",
    "    # TODO reward shaping and reward basic\n",
    "    def _reward(self, s, a, sp):\n",
    "        # Keep track for visualization, plots ...\n",
    "        self.dist_to_goal = get_dist_to_goal(sp, self.goal)\n",
    "        self.dist_nearest_obj = get_dist_nearest_obj(sp)\n",
    "        self.smallest_TTC, self.smallest_TTC_obj = get_smallest_TTC(sp)\n",
    "\n",
    "        # We are dealiong with 3 types of objectives:\n",
    "        # - COMFORT (weiht 1)\n",
    "        # - EFFICIENCY (weight 10)\n",
    "        # - SAFETY (weight 100)\n",
    "\n",
    "        r_comfort = r_efficiency = r_safety = 0\n",
    "\n",
    "        if self.reward_shaping and self.smallest_TTC <= 10.0:\n",
    "            r_safety += -10 - (10 - self.smallest_TTC) * 10 # between [-100, -10]\n",
    "\n",
    "        # SAFETY related + terminal state (overwrite)\n",
    "        if self.dist_nearest_obj <= self.dist_collision:\n",
    "            r_safety += -1000\n",
    "\n",
    "        # The faster we go in this test setup\n",
    "        r_efficiency += a\n",
    "\n",
    "        if a < -2:\n",
    "            r_comfort += -1\n",
    "\n",
    "        # Keep track for visualization, plots ...\n",
    "        self.r_comfort = r_comfort\n",
    "        self.r_efficiency = r_efficiency\n",
    "        self.r_safety = r_safety\n",
    "\n",
    "        return r_comfort + r_efficiency + r_safety\n",
    "        \n",
    "    def render(self):\n",
    "        pos_left = 40\n",
    "        #color_text = (255,255,255)\n",
    "        color_text = (0,0,0)\n",
    "        img = np.zeros([250, 250, 3],dtype=np.uint8)\n",
    "        img.fill(255) # or img[:] = 255\n",
    "        cv2.putText(img, 'Anti Collision Tests', (pos_left, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "        \n",
    "        x = self.s[0]; y = self.s[1]; vx = self.s[2]; vy = self.s[3]; v = int(math.sqrt(vx**2 + vy**2)*3.6)\n",
    "        color = (0, 0, 255) # blue\n",
    "        cv2.circle(img, (x, y), 2, color, -1)\n",
    "        draw_arrow(img, (int(x), int(y)), (int(x+vx), int(y+vy)), color)        \n",
    "        cv2.putText(img, str(v) + ' kmh', (x+vx+5, y+vy), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color)\n",
    "        \n",
    "        for i in range(self.nobjs):\n",
    "            if i == self.smallest_TTC_obj:\n",
    "                color = (255, 0, 0) # red\n",
    "            else:\n",
    "                color = (0, 2500, 0) # green\n",
    "            idx = (i+1)*4\n",
    "            x = self.s[idx]; y = self.s[idx+1]; vx = self.s[idx+2]; vy = self.s[idx+3]; v = int(math.sqrt(vx**2 + vy**2)*3.6)\n",
    "            cv2.circle(img, (x, y), 2, color, -1)\n",
    "            draw_arrow(img, (int(x), int(y)), (int(x+vx), int(y+vy)), color)        \n",
    "            cv2.putText(img, str(v) + ' kmh', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "        \n",
    "        if self.reward is not None:\n",
    "            str_reward = \"R_com %.2f , R_eff %.2f R_saf %.2f\" % (self.r_comfort, self.r_efficiency, self.r_safety)\n",
    "            cv2.putText(img, str_reward, (pos_left, 205), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "        \n",
    "            str_safety = \"TTC %.2f seconds, D_min %.2f meters\" % (self.smallest_TTC, self.dist_nearest_obj)\n",
    "            cv2.putText(img, str_safety, (pos_left, 215), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "            \n",
    "            str_step = \"Step %d with action %d reward %.2f\" % (self.steps, self.action, self.reward)\n",
    "            cv2.putText(img, str_step, (pos_left, 225), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0,0,255))\n",
    "        \n",
    "        #img = cv2.resize(img, None, fx=20, fy=20)\n",
    "        #img = cv2.resize(img,(2500, 2500))\n",
    "        return img\n",
    "        \n",
    "    #state, reward, done, info = env.step(action)\n",
    "    def step(self, action):\n",
    "        reward = -1; done = False; info = {}        \n",
    "        sp = copy.copy(self.s)\n",
    "        \n",
    "        s = self.s[0:4]\n",
    "        a = np.array([0.0, action])\n",
    "        sp[0:4] = transition_ca(s, a)\n",
    "        \n",
    "        idx = 4\n",
    "        for n in range(self.nobjs):\n",
    "            s_obj = self.s[idx:idx+4]\n",
    "            accel, state = self.drivers[n].step() # CALL driver model\n",
    "            #print(\"OBJ {} accel {} state {}\".format(n, accel, state))\n",
    "            a_obj = np.array([accel, 0.0])\n",
    "            sp[idx:idx+4] = transition_ca(s_obj, a_obj)\n",
    "            idx += 4\n",
    "            \n",
    "        reward = self._reward(self.s, action, sp)\n",
    "        \n",
    "        self.s = sp\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.dist_nearest_obj <= self.dist_collision or self.s[1] >= self.goal[1]:\n",
    "            print(\"done: dist_nearest_obj {}, y-ego {}\".format(self.dist_nearest_obj, self.s[1]))\n",
    "            done = True\n",
    "            if self.steps_beyond_done > 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            if self.dist_nearest_obj <= self.dist_collision:\n",
    "                info = \"fail\"\n",
    "            else:\n",
    "                info = \"success\"\n",
    "                \n",
    "        return self.s, reward, done, info\n",
    "    \n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 2786379769262599224\n",
      "[100   0   0  20  49  69  11   1  31  59  19   3  15  43  14   3  26  47\n",
      "  17   1  15 150  21   4 159  66 -13  -1 188 132 -17  -1 150 132 -11   0\n",
      " 152 129 -16   0 151 153 -13   0]\n"
     ]
    }
   ],
   "source": [
    "env = ActEnv(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz8DNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = env.render()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Start episode 0\n",
      "[100   0   0  20   7  94  12   0   7  39  15   3  39 101  24   1  34 165\n",
      "  14   3  19 123  22   3 181  68 -23  -1 172  94 -14  -1 172 100 -11  -2\n",
      " 153 156 -16   0 161  80 -17  -1]\n",
      "Step 0: action=0.0 reward=-82.91177543510673 done=False\n",
      "Step 1: action=0.0 reward=-85.14434161198112 done=False\n",
      "Step 2: action=0.0 reward=-87.37426590974255 done=False\n",
      "Step 3: action=0.0 reward=-89.60148054994593 done=False\n",
      "Step 4: action=0.0 reward=-91.82591033773106 done=False\n",
      "Step 5: action=0.0 reward=-94.04747184147246 done=False\n",
      "Step 6: action=0.0 reward=-96.26607242980111 done=False\n",
      "Step 7: action=0.0 reward=-98.48160913632361 done=False\n",
      "Step 8: action=0.0 reward=-100.6939673145641 done=False\n",
      "Step 9: action=0.0 reward=-102.90301903540424 done=False\n",
      "Step 10: action=0.0 reward=-105.10862116568576 done=False\n",
      "Step 11: action=0.0 reward=-107.31061304835626 done=False\n",
      "Step 12: action=0.0 reward=-109.50881367967048 done=False\n",
      "Step 13: action=0.0 reward=-103.94646629140396 done=False\n",
      "done: dist_nearest_obj 5.0990195135927845, y-ego 60\n",
      "Step 14: action=0.0 reward=-1106.2925731860341 done=True\n",
      "End of episode 0 with cumulated_reward -2461.4170009732234\n",
      "====> Start episode 1\n",
      "[100   0   0  20  27  85  17   2  37 168  23   0  27 155  15   3  16 126\n",
      "  12   1  30  41  18   0 193  40 -23  -3 173  86 -22   0 199  78 -13  -1\n",
      " 165 101 -16  -3 166  62 -21  -1]\n",
      "Step 0: action=0.0 reward=-86.86492063238087 done=False\n",
      "Step 1: action=0.0 reward=-89.24587301333325 done=False\n",
      "Step 2: action=0.0 reward=-91.62682539428562 done=False\n",
      "Step 3: action=0.0 reward=-94.00777777523801 done=False\n",
      "Step 4: action=0.0 reward=-96.38873015619039 done=False\n",
      "Step 5: action=0.0 reward=-98.76968253714278 done=False\n",
      "Step 6: action=0.0 reward=-101.15063491809515 done=False\n",
      "Step 7: action=0.0 reward=-103.53158729904754 done=False\n",
      "Step 8: action=0.0 reward=-105.91253967999991 done=False\n",
      "Step 9: action=0.0 reward=-108.2934920609523 done=False\n",
      "Step 10: action=0.0 reward=-100.75412698666675 done=False\n",
      "done: dist_nearest_obj 6.324555320336759, y-ego 48\n",
      "Step 11: action=0.0 reward=-1103.135079367619 done=True\n",
      "End of episode 1 with cumulated_reward -2179.6812698209515\n",
      "====> Start episode 2\n",
      "[100   0   0  20  46  60  20   3  44  44  13   2  24 152  14   1  31 139\n",
      "  18   3   7  34  22   3 150  94 -20  -2 190  88 -11  -1 152  84 -15   0\n",
      " 163 177 -22  -4 168 102 -18  -2]\n",
      "Step 0: action=0.0 reward=-85.82836861564792 done=False\n",
      "Step 1: action=0.0 reward=-88.13387430851812 done=False\n",
      "Step 2: action=0.0 reward=-90.42704152585432 done=False\n",
      "Step 3: action=0.0 reward=-92.70903928467678 done=False\n",
      "Step 4: action=0.0 reward=-94.9808187600526 done=False\n",
      "Step 5: action=0.0 reward=-97.24316472667081 done=False\n",
      "Step 6: action=0.0 reward=-99.4967321453907 done=False\n",
      "Step 7: action=0.0 reward=-101.74207281926289 done=False\n",
      "Step 8: action=0.0 reward=-103.97965521939405 done=False\n",
      "Step 9: action=0.0 reward=-106.20987949502391 done=False\n",
      "Step 10: action=0.0 reward=-108.43308901284976 done=False\n",
      "Step 11: action=0.0 reward=-99.94548596661737 done=False\n",
      "done: dist_nearest_obj 8.246211251235321, y-ego 52\n",
      "Step 12: action=0.0 reward=-1102.0315412381995 done=True\n",
      "End of episode 2 with cumulated_reward -2271.1607631181587\n",
      "====> Start episode 3\n",
      "[100   0   0  20  39  32  20   3  16  88  23   1  41  26  17   3  15 154\n",
      "  11   2   0 175  11   3 190 101 -19  -1 154 145 -22  -4 157 134 -14  -1\n",
      " 156 174 -14   0 194 180 -21  -1]\n",
      "Step 0: action=0.0 reward=-73.35572661877556 done=False\n",
      "Step 1: action=0.0 reward=-75.62256464264608 done=False\n",
      "Step 2: action=0.0 reward=-77.82388815687561 done=False\n",
      "Step 3: action=0.0 reward=-79.98085376820788 done=False\n",
      "Step 4: action=0.0 reward=-82.10482010008994 done=False\n",
      "Step 5: action=0.0 reward=-84.20273404723771 done=False\n",
      "Step 6: action=0.0 reward=-86.27921485727633 done=False\n",
      "Step 7: action=0.0 reward=-88.3375185878391 done=False\n",
      "Step 8: action=0.0 reward=-90.38004106160712 done=False\n",
      "Step 9: action=0.0 reward=-92.40860376369865 done=False\n",
      "Step 10: action=0.0 reward=-94.42462734082355 done=False\n",
      "Step 11: action=0.0 reward=-96.42924244474162 done=False\n",
      "Step 12: action=0.0 reward=-98.42336354346038 done=False\n",
      "Step 13: action=0.0 reward=-100.40773977431405 done=False\n",
      "Step 14: action=0.0 reward=-102.38299098591284 done=False\n",
      "Step 15: action=0.0 reward=-104.3496338957656 done=False\n",
      "Step 16: action=0.0 reward=-106.30810145523245 done=False\n",
      "Step 17: action=0.0 reward=-108.25875742412435 done=False\n",
      "Step 18: action=0.0 reward=-109.90988354303516 done=False\n",
      "done: dist_nearest_obj 8.94427190999916, y-ego 80\n",
      "Step 19: action=0.0 reward=-1102.5649873734965 done=True\n",
      "End of episode 3 with cumulated_reward -2853.9552933851605\n",
      "====> Start episode 4\n",
      "[100   0   0  20  47  94  17   1   0  97  19   0  34 150  14   3  32 103\n",
      "  21   0   1 162  19   1 186  96 -20  -4 174 162 -23  -4 153 173 -24  -1\n",
      " 167 105 -15  -2 193 153 -14  -1]\n",
      "Step 0: action=0.0 reward=-75.3753092562591 done=False\n",
      "Step 1: action=0.0 reward=-77.41064235015082 done=False\n",
      "Step 2: action=0.0 reward=-79.44556212447262 done=False\n",
      "Step 3: action=0.0 reward=-81.48006466097239 done=False\n",
      "Step 4: action=0.0 reward=-83.51414587485867 done=False\n",
      "Step 5: action=0.0 reward=-85.54780150825201 done=False\n",
      "Step 6: action=0.0 reward=-87.5810271232214 done=False\n",
      "Step 7: action=0.0 reward=-89.61381809437609 done=False\n",
      "Step 8: action=0.0 reward=-91.64616960098031 done=False\n",
      "Step 9: action=0.0 reward=-93.67807661855579 done=False\n",
      "Step 10: action=0.0 reward=-95.70953390993321 done=False\n",
      "Step 11: action=0.0 reward=-97.7405360157107 done=False\n",
      "Step 12: action=0.0 reward=-99.77107724407313 done=False\n",
      "Step 13: action=0.0 reward=-101.80115165992154 done=False\n",
      "Step 14: action=0.0 reward=-103.83075307325745 done=False\n",
      "Step 15: action=0.0 reward=-105.85987502676082 done=False\n",
      "Step 16: action=0.0 reward=-107.88851078249476 done=False\n",
      "Step 17: action=0.0 reward=-109.91665330766315 done=False\n",
      "Step 18: action=0.0 reward=-106.06239184746565 done=False\n",
      "done: dist_nearest_obj 7.211102550927978, y-ego 80\n",
      "Step 19: action=0.0 reward=-1109.2327120422656 done=True\n",
      "End of episode 4 with cumulated_reward -2883.105812121645\n",
      "METRICS: SAFETY %collisions = 1.0, COMFORT MeanHardBrake = nan, EFFICIENCY MeanStepsToGoal = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phw/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/phw/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "max_episodes = 5\n",
    "max_steps = 120\n",
    "\n",
    "# METRICS\n",
    "metric_success = 0 # EFFICIENCY\n",
    "metric_steps_to_goal = [] # SAFETY\n",
    "metric_hardbrake = [] # COMFORT\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    print(\"====> Start episode {}\".format(episode))\n",
    "    env.reset()\n",
    "    cumulated_reward = 0\n",
    "    images = []\n",
    "    \n",
    "    hardbrake = 0    \n",
    "    for n in range(max_steps):\n",
    "        action = 0.0\n",
    "        if action <= -2:\n",
    "            hardbrake += 1\n",
    "        state, reward, done, info = env.step(action)\n",
    "        cumulated_reward += reward\n",
    "        print(\"Step {}: action={} reward={} done={}\".format(n, action, reward, done)) # PHW DEBUG\n",
    "        img = env.render()\n",
    "        images.append(img)\n",
    "        if done is True:\n",
    "            if info == \"success\":\n",
    "                metric_success += 1\n",
    "                metric_steps_to_goal.append(n)\n",
    "                metric_hardbrake.append(hardbrake)\n",
    "            print(\"End of episode {} with cumulated_reward {}\".format(episode, cumulated_reward))\n",
    "            break\n",
    "            \n",
    "print(\"METRICS: SAFETY %collisions = {}, COMFORT MeanHardBrake = {}, EFFICIENCY MeanStepsToGoal = {}\".format(1-metric_success/max_episodes, np.mean(metric_hardbrake), np.mean(metric_steps_to_goal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(metric_hardbrake)\n",
    "print(metric_success)\n",
    "print(metric_steps_to_goal)\n",
    "print(max_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(images[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageio.mimsave('img/visu.gif', images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu2.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_images = resize_images(images, f=2)\n",
    "imageio.mimsave('img/visu2.gif', big_images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu2.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
