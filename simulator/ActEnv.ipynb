{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Collision Tests Environment - openai gym compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def  resize_images(images, f=3):\n",
    "    big_images = []\n",
    "    for img in images:\n",
    "        big_images.append(cv2.resize(img, None, fx=f, fy=f))\n",
    "    return big_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=10,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist(obj1, obj2):\n",
    "    return math.sqrt((obj1[0]-obj2[0])**2 + (obj1[1]-obj2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_nearest_obj(s):\n",
    "    nobjs = int(len(s)/4 - 1)\n",
    "    ego = s[0:4]\n",
    "    \n",
    "    dist_nearest_obj = math.inf\n",
    "    num_nearest_obj = -1\n",
    "    \n",
    "    idx = 4\n",
    "    for n in range(nobjs):\n",
    "        obj = s[idx:idx+4]\n",
    "        dist = get_dist(ego, obj)\n",
    "        \n",
    "        if dist < dist_nearest_obj:\n",
    "            dist_nearest_obj = dist\n",
    "            num_nearest_obj = n\n",
    "        idx += 4\n",
    "    \n",
    "    return dist_nearest_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_to_goal(s, goal):\n",
    "    return get_dist(s[0:4], goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time To Collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_TTC(ego, obj, radius):\n",
    "    x1, y1, vx1, vy1 = ego[0], ego[1], ego[2], ego[3]\n",
    "    x2, y2, vx2, vy2 = obj[0], obj[1], obj[2], obj[3]\n",
    "\n",
    "    a = (vx1 - vx2) **2 + (vy1 - vy2) **2\n",
    "    b = 2 * ((x1 - x2) * (vx1 - vx2) + (y1 - y2) * (vy1 - vy2))\n",
    "    c = (x1 - x2) **2 + (y1 - y2) **2 - radius **2\n",
    "\n",
    "    if a == 0 and b == 0:\n",
    "        if c == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.inf\n",
    "\n",
    "    if a == 0 and b != 0:\n",
    "        t = -c / b\n",
    "        if t < 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return t\n",
    "\n",
    "    delta = b **2 - 4 * a * c\n",
    "    if delta < 0:\n",
    "        return np.inf\n",
    "\n",
    "    t1 = (-b - np.sqrt(delta)) / (2 * a)\n",
    "    t2 = (-b + np.sqrt(delta)) / (2 * a)\n",
    "    if t1 < 0:\n",
    "        t1 = np.inf\n",
    "\n",
    "    if t2 < 0:\n",
    "        t2 = np.inf\n",
    "\n",
    "    return min(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smallest_TTC(s):\n",
    "    radius = 15.0\n",
    "    ego = s[0:4]\n",
    "    \n",
    "    smallest_TTC = np.Inf\n",
    "    smallest_TTC_obj = -1\n",
    "    \n",
    "    idx = 4\n",
    "    for n in range(int((len(s)-4)/4)):\n",
    "        obj = s[idx:idx+4]\n",
    "        TTC = get_TTC(ego, obj, radius)\n",
    "        \n",
    "        if TTC < smallest_TTC:\n",
    "            smallest_TTC = TTC\n",
    "            smallest_TTC_obj = n\n",
    "        idx += 4\n",
    "    \n",
    "    return smallest_TTC, smallest_TTC_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist:  141.4213562373095\n",
      "TTC:  4.4696699141100895\n"
     ]
    }
   ],
   "source": [
    "# just checking\n",
    "obj1 = np.array([0.0, 100, 20, 0])\n",
    "obj2 = np.array([100, 0.0, 0, 20])\n",
    "print(\"dist: \", get_dist(obj1, obj2))\n",
    "print(\"TTC: \", get_TTC(obj1, obj2, 15.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Made up ...\n",
    "\n",
    "class BasicDriverModel():\n",
    "    # stationarity: 1 is very aggressive, 4 is not very aggressive\n",
    "    def __init__(self, statio=3.0, dt=0.2):\n",
    "        self.state = \"SPEED_CONSTANT\" # SACCEL SCONSTANT\n",
    "        self.stationarity = statio # every 1, 2, 3 or 4 seconds\n",
    "        self.accel = 0 # -1 0 1 random uniform on ax\n",
    "        self.duration = 0\n",
    "        self.dt = dt\n",
    "        \n",
    "    def step(self):\n",
    "        if self.state == \"SPEED_CONSTANT\":\n",
    "            self.duration += self.dt\n",
    "            if self.duration >= self.stationarity:\n",
    "                self.accel = np.random.randint(low=-1, high=2)\n",
    "                self.state = \"SPEED_CHANGE\"\n",
    "                self.duration = 0\n",
    "        elif self.state == \"SPEED_CHANGE\":\n",
    "            self.duration += self.dt\n",
    "            if self.duration >= self.stationarity:\n",
    "                self.accel = 0\n",
    "                self.state = \"SPEED_CONSTANT\"\n",
    "                self.duration = 0\n",
    "        return self.accel, self.state  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel 0 state SPEED_CONSTANT\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n",
      "accel -1 state SPEED_CHANGE\n"
     ]
    }
   ],
   "source": [
    "driver = BasicDriverModel(statio=2.0)\n",
    "for i in range(20):\n",
    "    accel, state = driver.step()\n",
    "    print(\"accel {} state {}\".format(accel, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cf https://en.wikipedia.org/wiki/Intelligent_driver_model\n",
    "# cf https://github.com/sisl/AutoUrban.jl/blob/master/src/drivermodels/IDMDriver.jl\n",
    "\n",
    "class IntelligentDriverModel():\n",
    "    def __init__(self, v_des = 29.0):\n",
    "        self.a = None # predicted acceleration\n",
    "        self.sigma = 0 # optional stdev on top of the model, set to zero for deterministic behavior\n",
    "        \n",
    "        self.k_spd = 1.0 # proportional constant for speed tracking when in freeflow [s⁻¹]\n",
    "        \n",
    "        self.delta = 4.0 # acceleration exponent [-]\n",
    "        self.T = 1.5 # desired time headway [s]\n",
    "        self.v_des = v_des # desired speed [m/s], typically overwritten\n",
    "        self.s_min = 5.0 # minimum acceptable gap [m]\n",
    "        self.a_max = 3.0 # maximum acceleration ability [m/s²]\n",
    "        self.d_cmf = 2.0 # comfortable deceleration [m/s²] (positive)\n",
    "        self.d_max = 9.0 # maximum decelleration [m/s²] (positive)\n",
    "        \n",
    "    def step(self, v_ego, v_oth, headway):\n",
    "        if v_oth is not None:\n",
    "            assert headway is not None and headway > 0, \"v_oth None but headway > 0\"\n",
    "            if headway > 0.0:\n",
    "                dv = v_oth - v_ego\n",
    "                s_des = self.s_min + v_ego * self.T - v_ego * dv / (2 * math.sqrt(self.a_max * self.d_cmf))\n",
    "                \n",
    "                if self.v_des > 0.0:\n",
    "                    v_ratio = v_ego / self.v_des\n",
    "                else:\n",
    "                    v_ratio = 1.0\n",
    "                                        \n",
    "                self.a = self.a_max * (1.0 - v_ratio**self.delta - (s_des / headway)**2)\n",
    "            # elseif headway > -3.0\n",
    "            #    model.a = -model.d_max\n",
    "            else:\n",
    "                dv = self.v_des - v_ego\n",
    "                self.a = dv * self.k_spd\n",
    "        else:\n",
    "            # no lead vehicle, just drive to match desired speed\n",
    "            dv = self.v_des - v_ego\n",
    "            self.a = dv * self.k_spd # predicted accel to match target speed\n",
    "\n",
    "        if self.a is None:\n",
    "            print(\"headway: {} v_oth: {} v_ego: {}\".format(headway, v_oth, v_ego))\n",
    "        assert self.a is not None, \"idm accel None\"\n",
    "\n",
    "        self.a = np.clip(self.a, -self.d_max, self.a_max)\n",
    "        \n",
    "        if self.sigma > 0:\n",
    "            self.a += self.sigma * np.random.randn()\n",
    "            self.a = np.clip(self.a, -self.d_max, self.a_max)\n",
    "            \n",
    "        return self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_ego 10.6 a 3.0\n",
      "v_ego 11.2 a 3.0\n",
      "v_ego 11.799999999999999 a 3.0\n",
      "v_ego 12.399999999999999 a 3.0\n",
      "v_ego 12.999999999999998 a 3.0\n",
      "v_ego 13.599999999999998 a 3.0\n",
      "v_ego 14.199999999999998 a 3.0\n",
      "v_ego 14.799999999999997 a 3.0\n",
      "v_ego 15.399999999999997 a 3.0\n",
      "v_ego 15.999999999999996 a 3.0\n",
      "v_ego 16.599999999999998 a 3.0\n",
      "v_ego 17.2 a 3.0\n",
      "v_ego 17.8 a 3.0\n",
      "v_ego 18.400000000000002 a 3.0\n",
      "v_ego 19.000000000000004 a 3.0\n",
      "v_ego 19.600000000000005 a 3.0\n",
      "v_ego 20.200000000000006 a 3.0\n",
      "v_ego 20.800000000000008 a 3.0\n",
      "v_ego 21.40000000000001 a 3.0\n",
      "v_ego 22.00000000000001 a 3.0\n",
      "v_ego 22.600000000000012 a 3.0\n",
      "v_ego 23.200000000000014 a 3.0\n",
      "v_ego 23.800000000000015 a 3.0\n",
      "v_ego 24.400000000000016 a 3.0\n",
      "v_ego 25.000000000000018 a 3.0\n",
      "v_ego 25.60000000000002 a 3.0\n",
      "v_ego 26.20000000000002 a 3.0\n",
      "v_ego 26.800000000000022 a 3.0\n",
      "v_ego 27.400000000000023 a 3.0\n",
      "v_ego 27.92000000000002 a 2.5999999999999766\n",
      "v_ego 28.336000000000016 a 2.0799999999999805\n",
      "v_ego 28.66880000000001 a 1.6639999999999837\n",
      "v_ego 28.935040000000008 a 1.3311999999999884\n",
      "v_ego 29.148032000000008 a 1.0649599999999921\n",
      "v_ego 29.318425600000005 a 0.8519679999999923\n",
      "v_ego 29.454740480000005 a 0.6815743999999953\n",
      "v_ego 29.563792384000003 a 0.5452595199999948\n",
      "v_ego 29.651033907200002 a 0.43620761599999724\n",
      "v_ego 29.720827125760003 a 0.3489660927999978\n",
      "v_ego 29.776661700608003 a 0.2791728742399968\n",
      "v_ego 29.821329360486402 a 0.22333829939199745\n",
      "v_ego 29.857063488389123 a 0.17867063951359796\n",
      "v_ego 29.8856507907113 a 0.14293651161087695\n",
      "v_ego 29.90852063256904 a 0.11434920928870085\n",
      "v_ego 29.926816506055232 a 0.09147936743095997\n",
      "v_ego 29.941453204844187 a 0.07318349394476797\n",
      "v_ego 29.95316256387535 a 0.05854679515581296\n",
      "v_ego 29.96253005110028 a 0.04683743612465108\n",
      "v_ego 29.970024040880226 a 0.03746994889971944\n",
      "v_ego 29.976019232704182 a 0.02997595911977413\n",
      "v_ego 29.980815386163346 a 0.023980767295817884\n",
      "v_ego 29.984652308930677 a 0.019184613836653597\n",
      "v_ego 29.98772184714454 a 0.015347691069322877\n",
      "v_ego 29.990177477715633 a 0.012278152855458302\n",
      "v_ego 29.992141982172505 a 0.009822522284366642\n",
      "v_ego 29.993713585738004 a 0.007858017827494734\n",
      "v_ego 29.994970868590404 a 0.006286414261996498\n",
      "v_ego 29.995976694872322 a 0.005029131409596488\n",
      "v_ego 29.99678135589786 a 0.004023305127677901\n",
      "v_ego 29.997425084718287 a 0.0032186441021408996\n"
     ]
    }
   ],
   "source": [
    "driver = IntelligentDriverModel(v_des=30.0)\n",
    "v_ego = 10\n",
    "dt = 0.2\n",
    "for i in range(60):\n",
    "    a = driver.step(v_ego, None, None)\n",
    "    v_ego += a*dt\n",
    "    print(\"v_ego {} a {}\".format(v_ego, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai gym Anti Collision Test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Anti Collision Tests env compatible with gym openai interface\n",
    "##################################################################\n",
    "\n",
    "# API eg https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "\n",
    "stationarity = 1.0\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "def draw_arrow(image, p, q, color, arrow_magnitude=5, thickness=1, line_type=4, shift=0):\n",
    "    # adapted from http://mlikihazar.blogspot.com.au/2013/02/draw-arrow-opencv.html\n",
    "    # draw arrow tail\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "    # calc angle of the arrow\n",
    "    angle = np.arctan2(p[1]-q[1], p[0]-q[0])\n",
    "    # starting point of first line of arrow head\n",
    "    p = (int(q[0] + arrow_magnitude * np.cos(angle + np.pi/4)),\n",
    "    int(q[1] + arrow_magnitude * np.sin(angle + np.pi/4)))\n",
    "    # draw first half of arrow head\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "    # starting point of second line of arrow head\n",
    "    p = (int(q[0] + arrow_magnitude * np.cos(angle - np.pi/4)),\n",
    "    int(q[1] + arrow_magnitude * np.sin(angle - np.pi/4)))\n",
    "    # draw second half of arrow head\n",
    "    cv2.line(image, p, q, color, thickness, line_type, shift)\n",
    "\n",
    "# Transition with Constant Acceleration model\n",
    "def transition_ca(s, a, dt=0.2):\n",
    "    Ts = np.matrix([[1.0, 0.0, dt,  0.0], \n",
    "                [0.0, 1.0, 0.0, dt],\n",
    "                [0.0, 0.0, 1.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 1.0]])\n",
    "    Ta = np.matrix([[0.5*dt**2, 0.0],\n",
    "                [0.0,      0.5*dt**2],\n",
    "                [dt,       0.0],\n",
    "                [0.0,      dt]])\n",
    "    return np.dot(Ts, s) + np.dot(Ta, a)\n",
    "\n",
    "\n",
    "class ActEnv(gym.Env):\n",
    "    def __init__(self, nobjs, max_accel=2, dist_collision=10, reward_shaping=True):    \n",
    "        self.nobjs = nobjs\n",
    "        self.max_accel = max_accel\n",
    "        self.dist_collision = dist_collision\n",
    "        self.reward_shaping = reward_shaping\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-self.max_accel, high=self.max_accel, shape=(1,))\n",
    "        # 1+nobjs: x,y,vx,vy with x,y in [0,200] and vx,vy in [0,40]\n",
    "        self.observation_space = spaces.Box(low=0.0, high=200.0, shape=((1+nobjs)*4,))\n",
    "        \n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.reward = None\n",
    "        self.steps_beyond_done = 0\n",
    "        self.steps = 0\n",
    "        self.smallest_TTC_obj = -1\n",
    "        \n",
    "        self.drivers = []\n",
    "        \n",
    "        # x, y, vx, vy\n",
    "        self.start = np.array([100.0,   0.0,  0.0,  20.0], dtype=int)\n",
    "        self.goal  = np.array([100.0, 200.0, 0.0, 0.0], dtype=int)\n",
    "        # states init\n",
    "        state = ego = self.start\n",
    "        for n in range(int(self.nobjs/2)):\n",
    "            x = self.np_random.randint(low=0, high=50)\n",
    "            y = self.np_random.randint(low=25, high=190)\n",
    "            vx = self.np_random.randint(low=10, high=25)\n",
    "            vy = self.np_random.randint(low=0, high=5)\n",
    "            obj = np.array([x, y, vx, vy])\n",
    "            state = np.append(state, obj)\n",
    "            driver = BasicDriverModel(statio=stationarity)\n",
    "            self.drivers.append(driver)\n",
    "        \n",
    "        for n in range(int(self.nobjs/2)):\n",
    "            x = self.np_random.randint(low=150, high=200)\n",
    "            y = self.np_random.randint(low=25, high=190)\n",
    "            vx = - self.np_random.randint(low=10, high=25)\n",
    "            vy = - self.np_random.randint(low=0, high=5)\n",
    "            obj = np.array([x, y, vx, vy])\n",
    "            state = np.append(state, obj)\n",
    "            driver = BasicDriverModel(statio=stationarity)\n",
    "            self.drivers.append(driver)\n",
    "            \n",
    "        print(state)  \n",
    "        self.s = state\n",
    "        \n",
    "        return self.s\n",
    "    \n",
    "    # TODO reward shaping and reward basic\n",
    "    def _reward(self, s, a, sp):\n",
    "        # Keep track for visualization, plots ...\n",
    "        self.dist_to_goal = get_dist_to_goal(sp, self.goal)\n",
    "        self.dist_nearest_obj = get_dist_nearest_obj(sp)\n",
    "        self.smallest_TTC, self.smallest_TTC_obj = get_smallest_TTC(sp)\n",
    "\n",
    "        # We are dealiong with 3 types of objectives:\n",
    "        # - COMFORT (weiht 1)\n",
    "        # - EFFICIENCY (weight 10)\n",
    "        # - SAFETY (weight 100)\n",
    "\n",
    "        r_comfort = r_efficiency = r_safety = 0\n",
    "\n",
    "        if self.reward_shaping and self.smallest_TTC <= 10.0:\n",
    "            r_safety += -10 - (10 - self.smallest_TTC) * 10 # between [-100, -10]\n",
    "\n",
    "        # SAFETY related + terminal state (overwrite)\n",
    "        if self.dist_nearest_obj <= self.dist_collision:\n",
    "            r_safety += -1000\n",
    "\n",
    "        # The faster we go in this test setup\n",
    "        r_efficiency += a\n",
    "\n",
    "        if a < -2:\n",
    "            r_comfort += -1\n",
    "\n",
    "        # Keep track for visualization, plots ...\n",
    "        self.r_comfort = r_comfort\n",
    "        self.r_efficiency = r_efficiency\n",
    "        self.r_safety = r_safety\n",
    "\n",
    "        return r_comfort + r_efficiency + r_safety\n",
    "        \n",
    "    def render(self):\n",
    "        pos_left = 40\n",
    "        #color_text = (255,255,255)\n",
    "        color_text = (0,0,0)\n",
    "        img = np.zeros([250, 250, 3],dtype=np.uint8)\n",
    "        img.fill(255) # or img[:] = 255\n",
    "        cv2.putText(img, 'Anti Collision Tests', (pos_left, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "        \n",
    "        x = self.s[0]; y = self.s[1]; vx = self.s[2]; vy = self.s[3]; v = int(math.sqrt(vx**2 + vy**2)*3.6)\n",
    "        color = (0, 0, 255) # blue\n",
    "        cv2.circle(img, (x, y), 2, color, -1)\n",
    "        draw_arrow(img, (int(x), int(y)), (int(x+vx), int(y+vy)), color)        \n",
    "        cv2.putText(img, str(v) + ' kmh', (x+vx+5, y+vy), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color)\n",
    "        \n",
    "        for i in range(self.nobjs):\n",
    "            if i == self.smallest_TTC_obj:\n",
    "                color = (255, 0, 0) # red\n",
    "            else:\n",
    "                color = (0, 2500, 0) # green\n",
    "            idx = (i+1)*4\n",
    "            x = self.s[idx]; y = self.s[idx+1]; vx = self.s[idx+2]; vy = self.s[idx+3]; v = int(math.sqrt(vx**2 + vy**2)*3.6)\n",
    "            cv2.circle(img, (x, y), 2, color, -1)\n",
    "            draw_arrow(img, (int(x), int(y)), (int(x+vx), int(y+vy)), color)        \n",
    "            cv2.putText(img, str(v) + ' kmh', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "        \n",
    "        if self.reward is not None:\n",
    "            str_reward = \"R_com %.2f , R_eff %.2f R_saf %.2f\" % (self.r_comfort, self.r_efficiency, self.r_safety)\n",
    "            cv2.putText(img, str_reward, (pos_left, 205), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "        \n",
    "            str_safety = \"TTC %.2f seconds, D_min %.2f meters\" % (self.smallest_TTC, self.dist_nearest_obj)\n",
    "            cv2.putText(img, str_safety, (pos_left, 215), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color_text)\n",
    "            \n",
    "            str_step = \"Step %d with action %d reward %.2f\" % (self.steps, self.action, self.reward)\n",
    "            cv2.putText(img, str_step, (pos_left, 225), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0,0,255))\n",
    "        \n",
    "        #img = cv2.resize(img, None, fx=20, fy=20)\n",
    "        #img = cv2.resize(img,(2500, 2500))\n",
    "        return img\n",
    "        \n",
    "    #state, reward, done, info = env.step(action)\n",
    "    def step(self, action):\n",
    "        reward = -1; done = False        \n",
    "        sp = copy.copy(self.s)\n",
    "        \n",
    "        s = self.s[0:4]\n",
    "        a = np.array([0.0, action])\n",
    "        sp[0:4] = transition_ca(s, a)\n",
    "        \n",
    "        idx = 4\n",
    "        for n in range(self.nobjs):\n",
    "            s_obj = self.s[idx:idx+4]\n",
    "            accel, state = self.drivers[n].step() # CALL driver model\n",
    "            print(\"OBJ {} accel {} state {}\".format(n, accel, state))\n",
    "            a_obj = np.array([accel, 0.0])\n",
    "            sp[idx:idx+4] = transition_ca(s_obj, a_obj)\n",
    "            idx += 4\n",
    "            \n",
    "        reward = self._reward(self.s, action, sp)\n",
    "        \n",
    "        self.s = sp\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.steps += 1\n",
    "        \n",
    "        if self.dist_nearest_obj <= self.dist_collision or self.s[1] >= self.goal[1]:\n",
    "            print(\"done: dist_nearest_obj {}, y-ego {}\".format(self.dist_nearest_obj, self.s[1]))\n",
    "            done = True\n",
    "            if self.steps_beyond_done > 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            \n",
    "        return self.s, reward, done, {}\n",
    "    \n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100   0   0  20   6  51  10   4  44  65  20   2  41  97  20   3   2 146\n",
      "  24   4  10  68  19   3 189  94 -23  -2 194  28 -11  -2 196 176 -17  -2\n",
      " 162  98 -17  -3 179 116 -20  -3]\n"
     ]
    }
   ],
   "source": [
    "env = ActEnv(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHW5JREFUeJzt3U2o7OldJ/Dvb9LqQgUT+k4TOu0k\nSG/iYtrkkgkoQySMJtl03IS40EYC7aIDCm6iG126UUEYAy2GdEDNBDSkF40aGkFmoea2hJiXydho\nQrrppK86qIzgkPjM4tTpVNet+tX726nP53A5p6r+L8+tOnX41vf//KtqjBEAAOb7D8ceAADAKROW\nAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADT2Fpaq6l1V9eWqer6qPrSv/QAA7FPt400pq+o1Sf53\nkv+W5IUkn0nyk2OML+58ZwAAe3Tfnrb7tiTPjzH+Nkmq6uNJHk0yNyzdf//9441vfOOehgKX57nn\nVl/2rW/d3zgATtlzzz3392OMW8uW21dYejDJ16Yuv5Dkv0wvUFWPJ3k8Sb7/+78/d+7c2dNQ4PJU\nrb6spx5wqarqq6ssd7QJ3mOMJ8cYt8cYt2/dWhrqgDWMcfVv22UA2F9YejHJQ1OX3zC5DgDgrOwr\nLH0mycNV9aaq+s4k70/y9J72BSxw3R5NN0gaJYD17GXO0hjjm1X1wSR/nOQ1ST4yxvjCPvYFALBP\n+5rgnTHGM0me2df2AQAOwTt4AwA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEA\nNIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBD\nWAIAaAhLAAANYQkAoCEsAQA0hCUAgMZ9xx4AcLqq+tvH2GzZVfe7zjqbONR+gPOmWQIAaGiW4AaY\nbXV21eIs2k7XIs2us6xxAjh1miUAgIZmCW6A6zbnusVZZS7OJo3PJi3Uru2iqVql/TKPCbimWQIA\naGiW4AZZ1DBN22Z+0zp2caZZ1/gs2v70OqvOn5o3RmfKAdc0SwAADc0S3ECz7Uu3zCrWaVk0MsBN\no1kCAGgISwAADYfh4Aab93Ek+57QvejyJvvtJl4DHIpmCQCgoVmCC7FNo7TKurtsrLptLdvPOutu\nsx/gcmiWAAAawhIAQENYAgBomLMEwI1SefUpkyO7nYBWk1Myx4KJbdWcsrlonU32syuH2s850ywB\nADQ0SwDcCPtulJbuv2louraJ06dZAgBoaJYAOFuzbVKyn0bplJqhXY1ltgGb3a45TN+mWQIAaAhL\nAAANh+EAODv7Pvz2yvabI16HOjS36PDY9PWLDqmtM9m8Oyx36YfkNEsAAA3NEgA3wry2aZ6ugbpn\nG+PedRa1Nqc0CZzd0iwBADQ0SwCcneumZ7oJWjZn6XrZVRuoeeu2Y5ozl2gXNFjHp1kCAGholgC4\nEa7bn0UN0ypnyy1qkF617pLN7OrMsUXbWWX73TKzt22zn0uhWQIAaGiWADhbrzpLbYO5SIu2t6yl\n4rJolgAAGpolAG6EXbZAGiWmaZYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCW\nAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkA\noCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0Ljv2APY\nVlUtXWaMsfay6+x7nXU2caj9AAD30iwBADTOvlma17Ysa2K6dQAApmmWAAAaZ98sdRY1TPtukXa1\n/WXjNocJAPZPswQA0BCWAAAaWx2Gq6qvJPmXJN9K8s0xxu2qel2S/5HkjUm+kuR9Y4z/s90w5+w7\nk0NsufdQ1LK3Ctj1BO9Fh8emr190SG2dQ4Tdsg7JAcB+7KJZ+tExxiNjjNuTyx9K8uwY4+Ekz04u\nAwCcpX0chns0yVOTn59K8t5dbrwmX69crtq4FaqpLwCAebYNSyPJn1TVc1X1+OS6B8YYL01+/nqS\nB+atWFWPV9Wdqrpz9+7dLYcBALAf2751wI+MMV6sqv+Y5NNV9b+mbxxjjKqaO5lmjPFkkieT5Pbt\n20sn3Cxrf9Zpl3b91gGHfmsCAOBwtmqWxhgvTr6/nOSTSd6W5BtV9fokmXx/edtBAgAcy8Zhqaq+\nu6q+9/rnJD+W5PNJnk7y2GSxx5J8attBJldnvc078y1j8b8xxqtan+vL8/69st46Y5rZfrefTdbd\nZFkAYLe2OQz3QJJPTg453Zfk98YYf1RVn0nyiar6QJKvJnnf9sMEADiOjcPSGONvk/znOdf/Q5J3\nbjOodr+T+qd7n6Xr2xbNc5rbUM2s2y0DAFwO7+ANANA42w/S7ZqfRbd1jdNsYwUAkGiWAABawhIA\nQONsD8PtmsNvAMA8miUAgMZFNEuzrZG3BQAAVqVZAgBoXESzpEkCADalWQIAaAhLAAANYQkAoCEs\nAQA0hCUAgIawBADQuIi3DmA1Vcs/8mWMsdKy18utu9911lvXofYDwM2iWQIAaGiWeMWitqVrkWbX\nWaWdAoBzolkCAGholljouiWa1zgdas7PLpqqeWOd3a45TAAsolkCAGhcVLO0zdybTZqHQ5591bVA\nS9fNZN0tPnB4m/3P28612bPvupZonflTi5bVMAEwS7MEANC4iGZpneZhlWVvSvtw3Sjdc3nybZX/\n574bmdkxAsChaZYAABoX0SxdO6X3ADrWWV67ampm97Ors8u8bxMAp0azBADQEJYAABo3+jDc7CGn\nVQ7xrPpBsWuP5UROiZ9+e4CFh+TGktunlllk3rqL3pqgO2T3yv002d68tzlYtP7s9avsBwBmaZYA\nABo3slnaZhLzJm3OubpuZ3bxppSd2VYIAM6JZgkAoHFjmqVV5tes0w7t+oNW75l7c0JN1b4apV1s\n/555Z3seKwDM0iwBADRuTLO0zlle87yyzswy2zQZ89qoV+YJjeXzhFY9y2vdZc+BRgmAU6FZAgBo\n3JhmadouzvLa5gyudfa37zPRzo1GCYBTo1kCAGjcyGbp2lbzjQ7cRnFFkwTAqdEsAQA0hCUAgMaN\nPgx3aLOHkLrDcQ43AcB50CwBADQ0S3swr1HSJAHAedIsAQA0NEt7oEUCgJtDswQA0BCWAAAawhIA\nQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0\nhCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENY\nAgBoCEsAAA1hCYCN1eQLbjJhCQCgISwBADTuO/YAADg/53zorWr52McYay+7zr7XWWcTh9rPpdAs\nAQA0NEsArGRemzRy3s3FbPMy2yTNa2a0NpdHswQA0NAsAdC6iY3StVXmJC1bdxcN0zbjmLasKZu3\nDMtplgAAGpqlC+MsEDhNs+3NTWluTsnchmyFJmbROrtopeaNY9HfsO5v26KxmHO1G5olAICGZunC\ndK8kNnllAmznFBulhc/vscIyc5ZdvsNXr7Pr++CV+3iDP1taGBLNEgBAS1gCAGg4DMfCmvlQtfOh\nTplVo3NKTvnw28KJxVNjfGX8M4fO5i27dL8z98UhP0pl1b8/u556sMnEco5HswQA0NAsXYjrV2rb\nvnrdxWTHY50yO72cloljOcVGadZap8/vsAWad1/spHFZ4S5e9Ddh138rttlPt8w6Rwb8/VufZgkA\noKFZuuHauQDXUw6WvMrYdyNzyPkJcGrW+f3fVwt1T9u1xnyae+Yq7bB1nt7esta5u+2VMWZ5Q611\nYR7NEgBAQ7N0Q+2irZn3Km8XZ5g5C4RLdk/LsUJbdL3sJs/rRdvfVaOrkeESaJYAABqapRtq9tXr\ngoX6Zea8UNxmzsQqZ4EsGssuzgLxypdTtErDtMnzbqM26vpvwgpt7+wy+2idVx0L7JtmCQCgsTQs\nVdVHqurlqvr81HWvq6pPV9XfTL6/dnJ9VdVvVtXzVfW5qnrLPgfPcmPyNXt5na9ptcXXOjZZB87J\nvOfXPra/yvP6nnXHmPtvlWXmLbt0rM06y7a7ym3r7AfmWaVZ+miSd81c96Ekz44xHk7y7ORykrw7\nycOTf48n+fBuhgkAcBxLw9IY48+S/OPM1Y8meWry81NJ3jt1/cfGlT9P8n1V9fpdDRYA4NA2neD9\nwBjjpcnPX0/ywOTnB5N8bWq5FybXvRSOaquJ2dt+RMoWpz3DTXesjzuZ96G4p/jRK3AKtp7gPa4O\n8q79DKuqx6vqTlXduXv37rbDAADYi03D0jeuD69Nvr88uf7FJA9NLfeGyXX3GGM8Oca4Pca4fevW\nrQ2HwTlYa2LpGssCu+H5Br1Nw9LTSR6b/PxYkk9NXf/Tk7Pi3p7kn6YO1wEAnJ2lc5aq6veTvCPJ\n/VX1QpJfTvKrST5RVR9I8tUk75ss/kyS9yR5Psm/JvmZPYyZM3XPh3V6JQvAGVgalsYYP7ngpnfO\nWXYkeWLbQQEAnAofd8LBaJIAOEc+7gQAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAA\nDWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQOO+Yw8AgOOq1Ksuj4wjjQROk2YJAKAhLAEANByG\nA7hAs4fektM8/FZ17zinjfHtMa+z7Kr7XWedTRxqP2xHswQA0NAsAVyQc2mUri1qXLoWaXadZY0T\nLKNZAgBoaJYALsBNeXuAbo7Poeb97KKpWqX9Mo/pdGiWAAAamiWACzRv7tIyh2qjpse2zT53caZZ\n1/gs2v70OqvOn5o3RmfKnQ7NEgBAQ7MEcAGuG5rr1madxuZ6nU3aqHljWLafuddNvq3Ssmhk2DXN\nEgBAQ7MEcIHWmRe01byhqf1s20wt3dfMfKDZy5s0Td1cIi6HZgkAoCEsAQA0HIYDuCCzE70Ptb9V\ndGNa5RDaLid0d9tatp911t1mPxyOZgkAoKFZArhAp/hxJ/Nar1McJ5dHswQA0NAsAXBStEmcGs0S\nAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEA\nNIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBD\nWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQl\nAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANC479gDWKaq2tvHGCst\nN73sOvtdZ51NHGo/AMBmNEsAAI2Tb5auzTYvs01S18ys0joBAMyjWQIAaJxNs7RJO7Sv+UC7aKqW\nNWXzlgEADk+zBADQOMlmqbK8ZTnUPKSu8VnUXHWN1qJxd8tqmADgeDRLAAANYQkAoHFSh+HmHX7b\naDtHOny1q/EDAKdDswQA0DiJZum5PLe0lTnWG0uuM0kbALh5NEsAAI2TCEtvzVszsmB+0ej/1Zyv\nV27fwhhj4Zyn69tmlxmTr3ljW7TdVfYDABzPSYQlAIBTdRJzlq5dt0uvamI2qIiu19/k7LRN9rdo\nG86OA4Dzp1kCAGgsDUtV9ZGqermqPj913a9U1YtV9dnJv/dM3faLVfV8VX25qn58k0GNqa9t11/1\n65Xxb/C1inWWBQBOxyrN0keTvGvO9b8xxnhk8u+ZJKmqNyd5f5IfnKzzW1X1ml0NFgDg0JaGpTHG\nnyX5xxW392iSj48x/m2M8XdJnk/yti3GdzD7aKMAgPO3zZylD1bV5yaH6V47ue7BJF+bWuaFyXX3\nqKrHq+pOVd25e/fuFsMAANifTcPSh5P8QJJHkryU5NfW3cAY48kxxu0xxu1bt25tOAwAgP3aKCyN\nMb4xxvjWGOPfk/x2vn2o7cUkD00t+obJdTfSskno3aE7AOA8bBSWqur1Uxd/Isn1mXJPJ3l/VX1X\nVb0pycNJ/nK7IQIAHM/SN6Wsqt9P8o4k91fVC0l+Ock7quqRXH2wx1eS/GySjDG+UFWfSPLFJN9M\n8sQY41v7GfrxzU7i1hwBwM1Tp/DZY7dv3x537tw59jDWJiwBwPmqqufGGLeXLXdSH3dyboQjALj5\nfNwJAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAh\nLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsIS\nAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAFw\nNmryBYckLAEANO479gAAYJlTbJOq5o9pjLF0nW6Zfax7ivs5J5olAICGZgmAkzXbKI0cv+1Y1Lws\napqW3cbp0ywBADQ0SwCclHnzk06hUZq1Tlt03ULtq2HaxXZXacoudR6TZgkAoCEsAQA0HIYDgCXm\nHhpcY4L3TsfSHB5bZfL5quOed8jtUt9WQLMEANDQLAFwUqYnc183Ort4U8pNJomf4pthcniaJQCA\nhmYJgJN13QZt8+aUu2ynJju/2t6R3miym0vEfmiWAAAamiUATt6ihmmddTfR7W+TM8K2OYusW3fZ\ndtdZd5v93FSaJQCAhmYJgLNx6I89mddoneJHr7BfmiUAgIZmCQCW0CZdNs0SAEBDWAIAaAhLAAAN\nYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCW\nAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkA\noCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAa\nwhIAQENYAgBoCEsAAI2lYamqHqqqP62qL1bVF6rq5ybXv66qPl1VfzP5/trJ9VVVv1lVz1fV56rq\nLfv+TwAA7MsqzdI3k/zCGOPNSd6e5ImqenOSDyV5dozxcJJnJ5eT5N1JHp78ezzJh3c+agCAA1ka\nlsYYL40x/mry878k+VKSB5M8muSpyWJPJXnv5OdHk3xsXPnzJN9XVa/f+cgBAA5grTlLVfXGJD+U\n5C+SPDDGeGly09eTPDD5+cEkX5ta7YXJdbPberyq7lTVnbt37645bACAw1g5LFXV9yT5gyQ/P8b4\n5+nbxhgjyVhnx2OMJ8cYt8cYt2/durXOqgAAB7NSWKqq78hVUPrdMcYfTq7+xvXhtcn3lyfXv5jk\noanV3zC5DgDg7KxyNlwl+Z0kXxpj/PrUTU8neWzy82NJPjV1/U9Pzop7e5J/mjpcBwBwVu5bYZkf\nTvJTSf66qj47ue6Xkvxqkk9U1QeSfDXJ+ya3PZPkPUmeT/KvSX5mpyMGADigpWFpjPE/k9SCm985\nZ/mR5IktxwUAcBK8gzcAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIA\naAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICG\nsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhL\nAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA\n0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISN0bV1T9271D3rccQ\nOEXCEgBA475jD4DTcf2KfozjjiNZbyzHaiLW2e+x7tPpMS4aQ3dfH/u+PYXfxUPb1X1+DvfdJT/O\nnBfNEgBAQ1gCAGg4DMfZT6g9dIW/yaGDcz3ccOjxntv9sw/dfXCuv0dw7jRLAAANYQkOyKnxAOdH\nWAIAaJizdMEWzX/Y5LT9RduYZ5U5GYsuH3M+xzbb32SdVRqoQ81d2eVbOez6MdzF/TTvLRa2+X+c\nsl39Xu3icV50eVdvGXKujxGnR7MEANDQLLFT277B4eyr+kt8ZbjK//0U5z0tG/eux7yv++nQ/49D\n2cX9tcqbnK6yv22e5+f6/OC8aZYAABqaJXZiF/OcLt05vn/TOk3DNuvMW39f99NN+708x9+reW7K\n/4PzpFkCAGgISwAADYfhLswqh0A2mXy5zjImX27vFO/LUzzV/hTvp2PZ1wT7Wdf3+b7fwqPjsBu7\nplkCAGholi6YV9tsa50J/SbbHtcu7vdN3ixyV4+33zWOSbMEANDQLF2IbV5pbXuq902xizfMvMRX\nvLP3m9+nm+2Y88QW/a75PWNbmiUAgIZmCQ7gpr7CXaclcmba+VjlA7IP/bu8ydm5ftfYFc0SAEBD\ns8RaDtWQLHtleMyGZpNXrft6NXxKTdWq4952zOd+Px3avu6vXbQ2q4yta7dW3T5sS7MEANDQLF2I\nbV5hdetust111tnXsruwr/3tcru7fvf1TdZdx7Ee71P+PdvVvg/1Pkv72q6WiGPSLAEANIQlAICG\nsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhL\nAAANYQkAoCEsAQA0hCUAgIawBADQqDHGsceQqrqb5P8m+ftjj4W13B+P2bnxmJ0Xj9f58Zidl/80\nxri1bKGTCEtJUlV3xhi3jz0OVucxOz8es/Pi8To/HrObyWE4AICGsAQA0DilsPTksQfA2jxm58dj\ndl48XufHY3YDncycJQCAU3RKzRIAwMk5ibBUVe+qqi9X1fNV9aFjj4f5quorVfXXVfXZqrozue51\nVfXpqvqbyffXHnucl6qqPlJVL1fV56eum/v41JXfnDznPldVbzneyC/XgsfsV6rqxcnz7LNV9Z6p\n235x8ph9uap+/DijvlxV9VBV/WlVfbGqvlBVPze53vPshjt6WKqq1yT570neneTNSX6yqt583FHR\n+NExxiNTp8Z+KMmzY4yHkzw7ucxxfDTJu2auW/T4vDvJw5N/jyf58IHGyKt9NPc+ZknyG5Pn2SNj\njGeSZPJ38f1JfnCyzm9N/n5yON9M8gtjjDcneXuSJyaPi+fZDXf0sJTkbUmeH2P87Rjj/yX5eJJH\njzwmVvdokqcmPz+V5L1HHMtFG2P8WZJ/nLl60ePzaJKPjSt/nuT7qur1hxkp1xY8Zos8muTjY4x/\nG2P8XZLnc/X3kwMZY7w0xviryc//kuRLSR6M59mNdwph6cEkX5u6/MLkOk7PSPInVfVcVT0+ue6B\nMcZLk5+/nuSB4wyNBRY9Pp53p+2Dk8M2H5k6tO0xOyFV9cYkP5TkL+J5duOdQljifPzIGOMtuaqW\nn6iq/zp947g6tdLplSfK43M2PpzkB5I8kuSlJL923OEwq6q+J8kfJPn5McY/T9/meXYznUJYejHJ\nQ1OX3zC5jhMzxnhx8v3lJJ/M1SGAb1zXypPvLx9vhMyx6PHxvDtRY4xvjDG+Ncb49yS/nW8favOY\nnYCq+o5cBaXfHWP84eRqz7Mb7hTC0meSPFxVb6qq78zVBManjzwmZlTVd1fV917/nOTHknw+V4/V\nY5PFHkvyqeOMkAUWPT5PJ/npydk6b0/yT1OHETiimTktP5Gr51ly9Zi9v6q+q6relKtJw3956PFd\nsqqqJL+T5EtjjF+fusnz7Ia779gDGGN8s6o+mOSPk7wmyUfGGF848rC41wNJPnn1tyL3Jfm9McYf\nVdVnknyiqj6Q5KtJ3nfEMV60qvr9JO9Icn9VvZDkl5P8auY/Ps8keU+uJgn/a5KfOfiAWfSYvaOq\nHsnVoZyvJPnZJBljfKGqPpHki7k6K+uJMca3jjHuC/bDSX4qyV9X1Wcn1/1SPM9uPO/gDQDQOIXD\ncAAAJ0tYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGv8fZ1+273qugjQAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = env.render()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipo = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Start episode 0\n",
      "[100   0   0  20  44  51  21   0   9 169  10   3   5 141  20   0  18 114\n",
      "  14   3  17  65  17   0 188 127 -13  -2 157 151 -10   0 187  42 -15  -4\n",
      " 166  90 -20  -3 171 108 -11  -1]\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 0: action=0.0 reward=-90.97216637506574 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 1: action=0.0 reward=-92.91616346998327 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 2: action=0.0 reward=-94.8597116879516 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 3: action=0.0 reward=-96.80280931453188 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 0 state SPEED_CHANGE\n",
      "OBJ 6 accel 0 state SPEED_CHANGE\n",
      "OBJ 7 accel -1 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 4: action=0.0 reward=-98.74545450696978 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 0 state SPEED_CHANGE\n",
      "OBJ 6 accel 0 state SPEED_CHANGE\n",
      "OBJ 7 accel -1 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 5: action=0.0 reward=-100.68764529168755 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 0 state SPEED_CHANGE\n",
      "OBJ 6 accel 0 state SPEED_CHANGE\n",
      "OBJ 7 accel -1 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 6: action=0.0 reward=-102.62937956157323 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 0 state SPEED_CHANGE\n",
      "OBJ 6 accel 0 state SPEED_CHANGE\n",
      "OBJ 7 accel -1 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 7: action=0.0 reward=-104.5706550730582 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 0 state SPEED_CHANGE\n",
      "OBJ 6 accel 0 state SPEED_CHANGE\n",
      "OBJ 7 accel -1 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 8: action=0.0 reward=-106.51146944297302 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 9: action=0.0 reward=-108.4518201451711 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 10: action=0.0 reward=-101.0548067363552 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "done: dist_nearest_obj 8.54400374531753, y-ego 48\n",
      "Step 11: action=0.0 reward=-1103.193186007707 done=True\n",
      "End of episode 0 with cumulated_reward -2201.3952676130275\n",
      "====> Start episode 1\n",
      "[100   0   0  20  37  40  15   4   2 183  19   0  22 189  16   0  43 185\n",
      "  16   4  43  64  18   3 152 139 -13  -3 180  76 -14  -2 158 161 -15  -3\n",
      " 152 155 -18  -4 184 113 -19  -1]\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 0: action=0.0 reward=-82.95574344793835 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 1: action=0.0 reward=-85.09910798129347 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 2: action=0.0 reward=-87.21796468867537 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 3: action=0.0 reward=-89.31393360062955 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel 1 state SPEED_CHANGE\n",
      "Step 4: action=0.0 reward=-90.91726825939496 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel 1 state SPEED_CHANGE\n",
      "Step 5: action=0.0 reward=-92.48481432125092 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel 1 state SPEED_CHANGE\n",
      "Step 6: action=0.0 reward=-94.05377933864168 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel 1 state SPEED_CHANGE\n",
      "Step 7: action=0.0 reward=-95.23063284084957 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel -1 state SPEED_CHANGE\n",
      "OBJ 4 accel -1 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel 1 state SPEED_CHANGE\n",
      "Step 8: action=0.0 reward=-96.32752570305766 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 9: action=0.0 reward=-98.0933986958722 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 10: action=0.0 reward=-99.81384736082882 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 11: action=0.0 reward=-101.47945325025653 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 12: action=0.0 reward=-103.07558430196765 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 13: action=0.0 reward=-104.57723916030247 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel 1 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel -1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 1 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 14: action=0.0 reward=-105.93440234884623 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel 1 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel -1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 1 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 15: action=0.0 reward=-107.00929628324842 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel 1 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel -1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 1 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 16: action=0.0 reward=-100.83911600051523 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel 1 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel -1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 1 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 17: action=0.0 reward=-103.10432726435212 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel 0 state SPEED_CHANGE\n",
      "OBJ 3 accel 1 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel -1 state SPEED_CHANGE\n",
      "OBJ 6 accel -1 state SPEED_CHANGE\n",
      "OBJ 7 accel 1 state SPEED_CHANGE\n",
      "OBJ 8 accel 1 state SPEED_CHANGE\n",
      "OBJ 9 accel -1 state SPEED_CHANGE\n",
      "Step 18: action=0.0 reward=-105.36700474478116 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 19: action=0.0 reward=-107.62708541847721 done=False\n",
      "====> Start episode 2\n",
      "[100   0   0  20  21 106  11   3  40  54  20   2  29  78  21   2  21 129\n",
      "  17   2  32 171  14   3 178 149 -16  -2 196  88 -20  -2 152 186 -20  -4\n",
      " 171  63 -19   0 187 171 -15  -4]\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 0: action=0.0 reward=-87.6730584104202 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 1: action=0.0 reward=-89.76921903150925 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 2: action=0.0 reward=-91.86318407653025 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 3: action=0.0 reward=-93.95494704728438 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel 0 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel 1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel 0 state SPEED_CHANGE\n",
      "Step 4: action=0.0 reward=-96.04449879227161 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel 0 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel 1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel 0 state SPEED_CHANGE\n",
      "Step 5: action=0.0 reward=-98.13182745176681 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel 0 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel 1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel 0 state SPEED_CHANGE\n",
      "Step 6: action=0.0 reward=-100.2169183858902 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel 0 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel 1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel 0 state SPEED_CHANGE\n",
      "Step 7: action=0.0 reward=-102.29975408464023 done=False\n",
      "OBJ 0 accel 1 state SPEED_CHANGE\n",
      "OBJ 1 accel 1 state SPEED_CHANGE\n",
      "OBJ 2 accel -1 state SPEED_CHANGE\n",
      "OBJ 3 accel 0 state SPEED_CHANGE\n",
      "OBJ 4 accel 0 state SPEED_CHANGE\n",
      "OBJ 5 accel 1 state SPEED_CHANGE\n",
      "OBJ 6 accel 1 state SPEED_CHANGE\n",
      "OBJ 7 accel 0 state SPEED_CHANGE\n",
      "OBJ 8 accel 0 state SPEED_CHANGE\n",
      "OBJ 9 accel 0 state SPEED_CHANGE\n",
      "Step 8: action=0.0 reward=-104.38031405857666 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 9: action=0.0 reward=-106.45857470852279 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 10: action=0.0 reward=-108.53450917229534 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "Step 11: action=0.0 reward=-105.24266314303618 done=False\n",
      "OBJ 0 accel 0 state SPEED_CONSTANT\n",
      "OBJ 1 accel 0 state SPEED_CONSTANT\n",
      "OBJ 2 accel 0 state SPEED_CONSTANT\n",
      "OBJ 3 accel 0 state SPEED_CONSTANT\n",
      "OBJ 4 accel 0 state SPEED_CONSTANT\n",
      "OBJ 5 accel 0 state SPEED_CONSTANT\n",
      "OBJ 6 accel 0 state SPEED_CONSTANT\n",
      "OBJ 7 accel 0 state SPEED_CONSTANT\n",
      "OBJ 8 accel 0 state SPEED_CONSTANT\n",
      "OBJ 9 accel 0 state SPEED_CONSTANT\n",
      "done: dist_nearest_obj 8.246211251235321, y-ego 52\n",
      "Step 12: action=0.0 reward=-1107.3167890043967 done=True\n",
      "End of episode 2 with cumulated_reward -2291.8862573671404\n"
     ]
    }
   ],
   "source": [
    "max_episodes = 3\n",
    "max_steps = 20\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    print(\"====> Start episode {}\".format(episode))\n",
    "    env.reset()\n",
    "    cumulated_reward = 0\n",
    "    images = []\n",
    "    for n in range(max_steps):\n",
    "        action = 0.0\n",
    "        state, reward, done, info = env.step(action)\n",
    "        cumulated_reward += reward\n",
    "        print(\"Step {}: action={} reward={} done={}\".format(n, action, reward, done)) # PHW DEBUG\n",
    "        img = env.render()\n",
    "        images.append(img)\n",
    "        if done is True:\n",
    "            print(\"End of episode {} with cumulated_reward {}\".format(episode, cumulated_reward))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3V/ILHl5J/DnWSfJRRJQmdlhGMcd\nCXNjLnYiB1dIWAyyiXoz5kb0Ig4iTC5GSCAXO8mNufQmCQgbYULEERJdIRHnYkgiQxbZCxPPLOLf\ndR2M4gyjc7IuRlbIMua3F6d77NOn++mqrqqu6rc/Hzic962uP7+u6n556vv7VVW21gIAgN3+zdwN\nAABYMsUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFCYrFjKzLdm5tcz89nMfGyq7QAATCmnuCll\nZr4iIv5XRPyniHguIj4fEe9urX119I0BAEzojonW+8aIeLa19s2IiMz8REQ8FBE7i6U777yz3X//\n/RM1BQDgds8888w/tdbuOjTfVMXSvRHxnY3fn4uI/7A5Q2Y+EhGPRES89rWvjevXr0/UFACA22Xm\nt7vMN9sA79ba4621a621a3fddbCoAwCYxVTF0vMRcd/G769ZTQMAOCtTFUufj4gHMvN1mfnTEfGu\niHhyom0BAExmkjFLrbWXMvP9EfE3EfGKiPhIa+0rU2wLAGBKUw3wjtbaUxHx1FTrBwA4BXfwBgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUAgIJiCQCgoFgCACgolgAACoolAICCYgkAoKBYAgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUAgIJiCQCgoFgCACgolgAACoolAICCYgkAoKBYAgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUAgIJiCQCgoFgCACgolgAACoolAICCYgkAoKBYAgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUAgIJiCQCgoFgCACgolgAACoolAICCYgkAoKBYAgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUAgIJiCQCgoFgCACgolgAACooluBCZN/8B0I9iCQCg\ncMfcDQCmsytJWk9r7bRtAThXkiUAgIJiCQCgoBsOrqAuA7l1xwF0I1kCAChIluAKWqdFVcIkUQLo\nRrIEAFCQLMEVtpkeGaMEcBzJEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQUSwAABcUS\nAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQUSwAABcUS\nAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFO6YuwHAcmXWr7d23Lxdt9tnmWOcajvAeZMs\nAQAUJEtwBWynOmOlOPvWU6VI28scSpwAlk6yBABQUCwBABQGdcNl5rci4ocR8eOIeKm1di0zXx0R\n/zUi7o+Ib0XEO1tr/2dYM2Ea2aGPqK36lQ7N23r0fa3X1WeZetvr9d76f8Rmm2/d1jHdY8d02Y1t\njG69Ll2FBn0Da2MkS7/aWnuwtXZt9ftjEfF0a+2BiHh69TsAwFmaohvuoYh4YvXzExHxjgm2AaNo\nre3812eZJWntcCKSeWuS0mWZY6y3M2T963Vs/tte3/r3XdupXqvma+32/QRcrqHFUouIv83MZzLz\nkdW0u1trL6x+/m5E3L1rwcx8JDOvZ+b1GzduDGwGAMA0ht464Fdaa89n5r+NiM9k5v/cfLG11jJz\n5/lca+3xiHg8IuLatWvLOj3nYlVjiU6VInUZR3XIT8ZZ3bLmnfN0a9N6mXHnBTgHg5Kl1trzq/9f\njIhPRcQbI+J7mXlPRMTq/xeHNhIAYC5HF0uZ+bOZ+fPrnyPi1yLiyxHxZEQ8vJrt4Yj49NBGwuhG\nGJCSmZGZg8Yurdex+W97fdWYqn7jp1pE/GTe9fbGsr1Lt8caHcNYImAJhnTD3R0Rn1r9sb0jIv6i\ntfbXmfn5iPhkZr4vIr4dEe8c3kwAgHkcXSy11r4ZEf9+x/T/HRFvGdIomMSuOGI1bf1Kl4Ro7Hsk\n7WvT2IY0t8uyY+6OQ1eujbXskO0Al8MdvAEACh6ky9U3UlKzPb5n+/djkqZdy4w5jgiA4SRLAAAF\nxRIAQEE3HFff9lNmd82y/qHLPPv0eBpr1WXXttu74y6P+5bfnt5pOwCUJEsAAAXJEpdjM0mZ+pkc\n26kQAGdLsgQAUJAscZmmHq8zZP3baZSxRQCzkiwBABQkS7AUEqWzt++GoptXHh666WifqxQnf/TO\nibcDSyVZAgAoSJZgTj3uzcRNuXrscTt856uT2Ze8VClSn3mBeUmWAAAKiiUAgIJuOJiTLrdO1l1v\nS9enK23qbrcx1t+lq9Cgby6BZAkAoCBZAhZrV6K0lIHdO9s20wDvKvHpMvi8a1t2pUhuK8AlkCwB\nABQkS8DibKc2S0mTIs5n/BQwHskSAEBBsgQs3uLTnFXwNdfVcNVYImA4yRIAQEGyBCzOeozSEq+G\nq1KuLleEjXnVWLWuQ9vps+yQ7cBVIFkCAChIloDF2pUwzf0g3V1tmjvtAqYlWQIAKCiWAAAKuuGA\nxdvs5lrKbQR0vcHlkCwBABQkS8BZkegApyZZAgAoKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKiiUA\ngIJiCQCgoFgCACgolgAACoolAICCYgkAoOBBuixKZu6c3tr+h6eul6nmmWLZJW4HgPFJlgAACpIl\nZreZJm0nL/uSpn3T4SrKWCWTIZmEOUiWAAAKkiUWpWtitJlATZEyjbXOQ0mZMUzss06TZm1Dh+/B\n+jPcZ94+2zWekCWQLAEAFCRLzGbXmXPXMUtjbW/fdnYlV/vatuuMtOtVfac8g+Y87PxezDxWqc9n\nc8rvMMxFsgQAUFAsAQAUdMNxcnMNXN3syljC4FnYtP2ZnLvrbVPVlXbqbrcx1t+l61y3OJskSwAA\nBckSJ7M3zdk4gTvVYND1WfvLbWpb0w1K5YK9fBPMDo8Z2jZ20rQv8elygUWftvS5gIPLI1kCAChI\nljiZ29Kc3TPt1GWZYx4J8fJZ6mrZLmfU28t2eW3fvM5aWdv+fow1rq7P92F7m9IVuEmyBABQkCxx\ncttn0GNd9TP2GTnMoUpgj0mJxvg+9Bl3NPZ4Pze5ZAkkSwAABckSsxn7PjLHrG/J97bhsg29L9gY\n34ftq0TL7Y04rqnPeMA+8+yabjwhXUiWAAAKkiUukkSJc3Kqz+dU4wnh3EmWAAAKiiUAgIJuOC7G\n0Eux4VL4XsCtJEsAAAXJEhfD2TIAx5AsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGx\nBABQUCwBABQUSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGx\nBABQUCwBABQUSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQOFg\nsZSZH8nMFzPzyxvTXp2Zn8nMb6z+f9VqembmhzLz2cz8Yma+YcrGAwBMrUuy9NGIeOvWtMci4unW\n2gMR8fTq94iIt0XEA6t/j0TEh8dpJgDAPA4WS621z0bE97cmPxQRT6x+fiIi3rEx/WPtps9FxCsz\n856xGgsAcGrHjlm6u7X2wurn70bE3auf742I72zM99xqGgDAWRo8wLu11iKi9V0uMx/JzOuZef3G\njRtDmwEAMIlji6XvrbvXVv+/uJr+fETctzHfa1bTbtNae7y1dq21du2uu+46shkckpmRmaPPO+ay\nS9wOAKwdWyw9GREPr35+OCI+vTH9Paur4t4UET/Y6K4DADg7dxyaITM/HhFvjog7M/O5iPhARHww\nIj6Zme+LiG9HxDtXsz8VEW+PiGcj4kcR8d4J2szIJDUAsN/BYqm19u49L71lx7wtIh4d2igAgKU4\nWCxxnvqkRTdr3OkSpjHWu25jtc7teQBgDB53AgBQkCxdERm5/mH36ydKYqrtrF+rUqIuCdKu+ar1\nA8AQkiUAgIJk6Yzlrhiprf+r05wu62397zUKAFeOZAkAoKBYAgAo6IY7Qzu7346Yp+s6+nTHVQOv\nAeAcSZYAAAqSpTP08uDtLunRKujpkhLddtl+j3SqGkB+aHB5n2WHbAcAjiFZAgAoSJbO2GZKdCg5\nWr/eJS3aXsfmMm4nAMClkSwBABQkS1fEocSnSyLUJ30CgEshWQIAKEiW2JskGZ8EAJIlAICSYgkA\noKAb7oJtd7/pdgOA20mWAAAKkqULJkkCgMMkSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEE\nAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQUSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEE\nAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQUSwAAhTvmbgDLlZl7X2utlcvse73rNo9dfmnbAeD8\nSZYAAAqSJW5TpS770qYqhQKAcyZZAgAoSJbYq09atE6hpkqYxlhvl6TMGCYAtkmWAAAKkiVelnE4\nZRkzOdreXrWd7eSqatv2a32u6nOVHADbJEsAAAXFEgBAQTccZXfYlFq0WbcPAF1IlgAACpKlC7Y3\n0VmNbT7VjSbXCVPERpvara+56SUAc5EsAQAUJEsX7OCYoeLq+YOp1MbrrVrR9uLt1jat/+9yKf++\neXZN7zMvAJdNsgQAUJAscVvC1CcJ2mczWXK1GwDnTLIEAFCQLPGyMRKloeu67ZErI7YJAI4hWQIA\nKEiWmN2uMU0SJQCWQrIEAFBQLAEAFHTDMRvdbwCcA8kSAEBBssRspEgAnAPJEgBAQbIEMNCpbqaa\nufvB0uvplT4Pid63nbGdajswlGQJAKAgWQI4wpKu5tyVzEhtYDySJQCAgmQJoIc5EqUuY5IOLTtG\nwjSkHZsOjbmShrE0kiUAgIJkCaCDk13xtt5OEeJ0SWLW08ZIpXZt59CVedU4qn1t3TWflIklkCwB\nABQUSwAABd1wAEfYNdC7i33dd7etr23+eGuXWp+uL2A4yRIAQEGyBNDBy+nOKgHqM8B7MzU6JpHq\nusxYl/avHfNYFbiKJEsAAAXJEsARNtOeQylTlxSqSo9eXn7PasYeq7RvfV22U82z/dqQ7cApSZYA\nAAqSJYAetscuTbXeuR7KC9xOsgQAUJAsARxhquRHogTLI1kCACgolgAACoolAICCYgkAoKBYAgAo\nKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKB4ulzPxIZr6YmV/emPYHmfl8Zn5h9e/tG6/9XmY+m5lf\nz8xfn6rhAACn0CVZ+mhEvHXH9D9urT24+vdURERmvj4i3hURv7ha5k8y8xVjNRYA4NQOFkuttc9G\nxPc7ru+hiPhEa+1fWmv/GBHPRsQbB7QPAGBWQ8YsvT8zv7jqpnvVatq9EfGdjXmeW027TWY+kpnX\nM/P6jRs3BjQDAGA6xxZLH46IX4iIByPihYj4w74raK093lq71lq7dtdddx3ZDACAaR1VLLXWvtda\n+3Fr7V8j4k/jJ11tz0fEfRuzvmY1DQDgLB1VLGXmPRu//kZErK+UezIi3pWZP5OZr4uIByLiH4Y1\nEQBgPnccmiEzPx4Rb46IOzPzuYj4QES8OTMfjIgWEd+KiN+KiGitfSUzPxkRX42IlyLi0dbaj6dp\nOgDA9LK1Nncb4tq1a+369etzNwMAuCCZ+Uxr7dqh+dzBGwCgoFgCACgolgAACoolAICCYgkAoKBY\nAgAoHLzPEgDzyshbfm8x/y1f4JJIlgAACoolAICCbjiABdrueovQ/QZzkSwBABQkSwALsoREKfP2\nNmxbP1f00Lx9nj+6XtfUzyzdbPMSno/K8kmWAAAKkiWABVji7QH6pC4SGq4yyRIAQEGyBLBAu8Yu\nrZ0qdarGI20nSfvmHStx6jKO6pBdbdler4SMXSRLAAAFyRLAAqzTonWitCs9Wr9WpU7b6+vj5W3v\nSVd2pTt95u3cjmI71RVz+147JiGTMLFJsgQAUFAsAQAUdMMBLNBmV9u6S+1Q19rmMoe66jbXtT1v\nn64o3VZcAskSAEBBsgSwINsDvY9ZttJnkHifQdpjXNq/1uUSfzglyRIAQEGyBLBAU914srolwcZM\nndsw5lilal1dtrNvnu3pQ7fD5ZEsAQAUJEsAF67LDTHhkkmWAAAKkiV6OXRFStXfP+R+LKe6l4t7\nxnDJJEqwm2QJAKAgWeIofZIX90cB4JxJlgAACoolAICCbjiOsq9rbVf33HraVN1xY6x3u9271mnQ\nN8BlkiwBABQkSxy0+SiEfenKkHTnlvUfuHS5Snz2XfZf3Q6gT0LmtgIAl0myBABQkCyx120P14zp\n0xWPWwBgaSRLAAAFyRK32ZUo3TbPiFe2baZI623vS5j6jDuim+3jLdUDuJVkCQCgIFniNutkYWfC\ndCB0qMYcdRnntG/b1bKH1ttn2SHbOTcSJYBuJEsAAAXJEnvtSnkO3gdpa8xRn+1U65N6jOecEqUu\n49H63CH+mAdAT50oun8XLJ9kCQCgoFgCACjohuOgPt00feY9psuO451T99ta1TW13e3mETXAVCRL\nAAAFyRKLdA6px7kbaxD+qR2TFo2ZMI11E9R9D3ze9zowH8kSAEBBssTJnePYmatg+1YQXfb72LeC\n6GqsW0b0ua3A3rbsSXw2p+9Lifo8nqdKmqRMMC/JEgBAQbLEyUmSlqFLejP11Y3b699e9uXfNybv\nS1lc+QZMRbIEAFCQLMGFKR+UPMJ6D9nc7hT32BrrarW1Q1etAVefZAkAoCBZggs119ixLg9Ovm2Z\nDuOQxh6rtG99Q9uy/dqQ7QCnIVkCACgolgAACrrhgMU45saZAFOTLAEAFCRLwOJIlIAlkSwBABQU\nSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQU\nSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQU\nSwAABcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQU\nSwAAhYPFUmbel5l/l5lfzcyvZOZvr6a/OjM/k5nfWP3/qtX0zMwPZeazmfnFzHzD1G8CAGAqXZKl\nlyLid1trr4+IN0XEo5n5+oh4LCKebq09EBFPr36PiHhbRDyw+vdIRHx49FYDAJzIHYdmaK29EBEv\nrH7+YWZ+LSLujYiHIuLNq9meiIj/FhH/eTX9Y621FhGfy8xXZuY9q/Uwk8w8OM/NQ3YZ9u2PPvug\n2qfb6xlje0Md+gxM1Zbt7W5up3qt73rHXMeu9fSZ99htHrvOqQw5PmNtd982T3XsjvnbOdZnheXo\nNWYpM++PiF+KiL+PiLs3CqDvRsTdq5/vjYjvbCz23Gra9roeyczrmXn9xo0bPZsNAHAaB5Oltcz8\nuYj4y4j4ndbaP29V/i0ze5XLrbXHI+LxiIhr164ptU+kOqtZH9NLOvPZd0Z4zH7adTbZZ95Tmast\n1T4d8pmr3s+hVGLX69v7Y6pjeExicipz/S045r1Xx3D7tT7zHrNMn88V56VTspSZPxU3C6U/b639\n1Wry9zLzntXr90TEi6vpz0fEfRuLv2Y1DQDg7HS5Gi4j4s8i4muttT/aeOnJiHh49fPDEfHpjenv\nWV0V96aI+IHxSgDAuerSDffLEfGbEfGlzPzCatrvR8QHI+KTmfm+iPh2RLxz9dpTEfH2iHg2In4U\nEe8dtcUMMvbAwzGi5WrAb9/lK126Zy7BGMfsmHVUyyyxC7jPezym/WN2y4y1rmO6pce03s7Yn5Vj\numq7WOLnlml0uRruv0fEvk/uW3bM3yLi0YHtAgBYhM4DvLkadqU4Y5wVjTUget/6ugycdHbXzfbZ\n+1T7rct2lnjsuqQbm/N1mffQ8pvrGHtf9DkO+5btY8p0eCm6fka4OjzuBACgIFm6YFMmDEs/41pi\nonFqYxz/q3iJ9Pb+2Pd+ljgGblfaderjceobVx4zTmzqZbh6JEsAAAXJEqP0v3d5LMLciUOXs+4u\n42r67K8xxzbsWsdcaeCSxmyc0zGcejtdPiNLOGZDbO+n6j13SQX3LXPMflvS94JxSZYAAAqSpQvR\nJYGYuk9+SBvGflTGkHu0jLmOY435nsd81Ejfeabe9qF55ziGh9az5O/hqYzVxjG+J1P/feE8SJYA\nAAqSJTgTzlYB5iFZAgAoKJYAAAqKJQCAgmIJAKCgWAIAKCiWAAAKbh1wxY192/1Dt/M/5vL2qo1d\n1nfoPR7zaItLNscDYrsew1Pq8hiVMde/bdfjebrMe8z29i1/bg+RPbf2cj4kSwAABcnSFVc9DPKY\ns8lDD5nsc2bXZTtdHHofh+bruz2ms6SHvp76sSNdvjtjtKnL99r3AW4lWQIAKEiWGMVUZ+HHjEEY\nK93quuwuXc/Qu4xLOWbMVZ/xKV3WO9d4r13v55jPwpBtnnrM2zGJ69B9su/hsWMkTEOOwbHL9zl2\nY7xXY6SuPskSAEBBssQiXcrYiWMTk67pUJd0Ysg4oXM5oz40Pmjoex7jc1q1peu4vD7b2bWeU43T\nOjT28Zh17lrvGPtn6NW6XA2SJQCAgmIJAKCgG45RjH0DvyUP7N421qDqfV0IU0f9fbZzzK0ohrjK\nNxmc6/N6rsbssju37kvmJ1kCAChIluhlzMed9DnLm/rRE0Mcc1lydZbaZd+OsT+22zbWLQSmuh1D\nn3nOSZ/3c2jeLoPD+wwgX4I+36G1fSntkM/OVfvc0Y9kCQCgIFm6MMeMSzl2nq7maNNUj40YMu+Y\n6+vzyIxTH++h65/i2O1aZ5/9NCTZG3PeOdvYZx371ju0/cesd4xlufokSwAABckSMCpn4sBVI1kC\nACgolgAACoolAICCYgkAoKBYAgAoKJYAAApuHXAhutypf33F93reJV0BXrV/6nZu7499+2ezjUva\nd2uH2r2ENu87zkto25zmPkbV9vscs0N/h7q8vz5/C3yeGItkCQCgIFm6MMec7c2pS4oztat+FrqE\n97eE48xPHLPf+ySWQ45zl2V9nhibZAkAoCBZujC7zqz2JQu7zs66jjkYa4xRl/V1tWtMUZfxSPu2\n3WccxzHpTZd9eMx+OfSejxnfVs0zhj7jwYbut66fjerztG+dXeZZQvoxVSIz1WdiyLJLSFZZPskS\nAEBBsnQhqvRjX0Iy1hnXkKuvuow9ONWVQn2uFpz6PR/aXp/1Vo5pw5jJyNB1jpGQbC9TpY9Djtkx\nV5xVxhh3NLUh390hV9stIb3jvEiWAAAKkqULsesMbshZ1jFn7FMkDn3WWyUBc9/HZpchbVri+znG\n1O9j7KRhjPaO9Z6XfOyPeY9jXOF2Vb4XnJ5kCQCgoFgCACjohrswQy8L3/daFWuf6jL6U5sq0t/e\nx2MPqj5msPn29sZ2qoG3Q/Ztn+/FkK7tIeuYU5fPyr7B8tvLVJf2j/G4E+hLsgQAUJAsXYixLs09\nZn1D0oipk4wu2+k671j765hluszbtd1Dtzv38R6yL7rMO/Q4H5pniYOPT/23YKzP1RL3JedJsgQA\nUFAsAQAUFEsAAAVjlpiEsQIAXBWSJQCAgmKJKyPTfVWmcqp96xgCS6RYAgAoGLPEy5b0kMkhd5k+\nlT7bnfsu41Ubqn09975dwmfx1Mba5+ew7y75OHNeJEsAAAXFEgBAQTccZz+g9tQR/jFdB+fa3XDq\n9p7b/plCl4dS209wWpIlAICCYglOyKXxAOdHsQQAUDBm6YLtG/9wzGX7+9axS5cxGft+n3M8x5D1\nH7NMlwTqVGNXxryVw9jHcIz9tOsWC0Pex5KN9bka4zjv+32sW4ac6zFieSRLAAAFyRKjGnqDw+2z\n+ks8M+zy3pc47ulQu8du81T76dTv41TG2F9dbnLaZXtDvufn+v3gvEmWAAAKkiVGMcY4p0t3jvdv\n6pM0DFlm1/JT7aer9rk8x8/VLlflfXCeJEsAAAXFEgBAQTfchenSBXLM4Ms+8xh8OdwS9+USL7Vf\n4n6ay1QD7Let9/nUt/Co6HZjbJIlAICCZOmCOdtmqD4D+g22ndcY+/2Ym0WOdbx91piTZAkAoCBZ\nuhBDzrSGXup9VYxxw8xLPOPd3m8+T1fbnOPE9n3WfM4YSrIEAFCQLMEJXNUz3D4pkSvTzkeXB2Sf\n+rN8zNW5PmuMRbIEAFCQLNHLqRKSQ2eGcyY0x5y1TnU2vKSkqmu7h7b53PfTqU21v8ZIbbq0rUq3\nuq4fhpIsAQAUJEsXYsgZVrXsMevts8xU845hqu2Nud6x775+zLJ9zHW8l/w5G2vbp7rP0lTrlRIx\nJ8kSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFBRLAAAFxRIAQEGxBABQUCwBABQUSwAA\nBcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBAQbEEAFBQLAEAFLK1NncbIjNvRMT/jYh/mrst9HJnOGbn\nxjE7L47X+XHMzsu/a63ddWimRRRLERGZeb21dm3udtCdY3Z+HLPz4nidH8fsatINBwBQUCwBABSW\nVCw9PncD6M0xOz+O2XlxvM6PY3YFLWbMEgDAEi0pWQIAWJxFFEuZ+dbM/HpmPpuZj83dHnbLzG9l\n5pcy8wuZeX017dWZ+ZnM/Mbq/1fN3c5LlZkfycwXM/PLG9N2Hp+86UOr79wXM/MN87X8cu05Zn+Q\nmc+vvmdfyMy3b7z2e6tj9vXM/PV5Wn25MvO+zPy7zPxqZn4lM397Nd337IqbvVjKzFdExH+JiLdF\nxOsj4t2Z+fp5W0XhV1trD25cGvtYRDzdWnsgIp5e/c48PhoRb92atu/4vC0iHlj9eyQiPnyiNnKr\nj8btxywi4o9X37MHW2tPRUSs/i6+KyJ+cbXMn6z+fnI6L0XE77bWXh8Rb4qIR1fHxffsipu9WIqI\nN0bEs621b7bW/l9EfCIiHpoKRPvsAAACdUlEQVS5TXT3UEQ8sfr5iYh4x4xtuWittc9GxPe3Ju87\nPg9FxMfaTZ+LiFdm5j2naSlre47ZPg9FxCdaa//SWvvHiHg2bv795ERaay+01v7H6ucfRsTXIuLe\n8D278pZQLN0bEd/Z+P251TSWp0XE32bmM5n5yGra3a21F1Y/fzci7p6naeyx7/j43i3b+1fdNh/Z\n6Np2zBYkM++PiF+KiL8P37MrbwnFEufjV1prb4ib0fKjmfkfN19sNy+tdHnlQjk+Z+PDEfELEfFg\nRLwQEX84b3PYlpk/FxF/GRG/01r7583XfM+upiUUS89HxH0bv79mNY2Faa09v/r/xYj4VNzsAvje\nOlZe/f/ifC1kh33Hx/duoVpr32ut/bi19q8R8afxk642x2wBMvOn4mah9Oettb9aTfY9u+KWUCx9\nPiIeyMzXZeZPx80BjE/O3Ca2ZObPZubPr3+OiF+LiC/HzWP18Gq2hyPi0/O0kD32HZ8nI+I9q6t1\n3hQRP9joRmBGW2NafiNufs8ibh6zd2Xmz2Tm6+LmoOF/OHX7LllmZkT8WUR8rbX2Rxsv+Z5dcXfM\n3YDW2kuZ+f6I+JuIeEVEfKS19pWZm8Xt7o6IT938WxF3RMRftNb+OjM/HxGfzMz3RcS3I+KdM7bx\nomXmxyPizRFxZ2Y+FxEfiIgPxu7j81REvD1uDhL+UUS89+QNZt8xe3NmPhg3u3K+FRG/FRHRWvtK\nZn4yIr4aN6/KerS19uM52n3BfjkifjMivpSZX1hN+/3wPbvy3MEbAKCwhG44AIDFUiwBABQUSwAA\nBcUSAEBBsQQAUFAsAQAUFEsAAAXFEgBA4f8Dh+JD0VbV21QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(images[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageio.mimsave('img/visu.gif', images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu2.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_images = resize_images(images, f=2)\n",
    "imageio.mimsave('img/visu2.gif', big_images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu2.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
