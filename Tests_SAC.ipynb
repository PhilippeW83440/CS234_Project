{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Actor Critic\n",
    "Out of https://github.com/openai/spinningup/blob/master/spinup/algos/sac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.py  __pycache__  sac.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls spinup/algos/sac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sac.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spinup.algos.sac import core\n",
    "from spinup.algos.sac.core import get_vars\n",
    "from spinup.utils.logx import EpochLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A simple FIFO experience replay buffer for SAC agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs1_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.obs2_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, act_dim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs1_buf[self.ptr] = obs\n",
    "        self.obs2_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr+1) % self.max_size\n",
    "        self.size = min(self.size+1, self.max_size)\n",
    "\n",
    "    def sample_batch(self, batch_size=32):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        return dict(obs1=self.obs1_buf[idxs],\n",
    "                    obs2=self.obs2_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Soft Actor-Critic\n",
    "(With slight variations that bring it closer to TD3)\n",
    "\"\"\"\n",
    "def sac(env_fn, actor_critic=core.mlp_actor_critic, ac_kwargs=dict(), seed=0, \n",
    "        steps_per_epoch=5000, epochs=100, replay_size=int(1e6), gamma=0.99, \n",
    "        polyak=0.995, lr=1e-3, alpha=0.2, batch_size=100, start_steps=10000, \n",
    "        max_ep_len=1000, logger_kwargs=dict(), save_freq=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        env_fn : A function which creates a copy of the environment.\n",
    "            The environment must satisfy the OpenAI Gym API.\n",
    "        actor_critic: A function which takes in placeholder symbols \n",
    "            for state, ``x_ph``, and action, ``a_ph``, and returns the main \n",
    "            outputs from the agent's Tensorflow computation graph:\n",
    "            ===========  ================  ======================================\n",
    "            Symbol       Shape             Description\n",
    "            ===========  ================  ======================================\n",
    "            ``mu``       (batch, act_dim)  | Computes mean actions from policy\n",
    "                                           | given states.\n",
    "            ``pi``       (batch, act_dim)  | Samples actions from policy given \n",
    "                                           | states.\n",
    "            ``logp_pi``  (batch,)          | Gives log probability, according to\n",
    "                                           | the policy, of the action sampled by\n",
    "                                           | ``pi``. Critical: must be differentiable\n",
    "                                           | with respect to policy parameters all\n",
    "                                           | the way through action sampling.\n",
    "            ``q1``       (batch,)          | Gives one estimate of Q* for \n",
    "                                           | states in ``x_ph`` and actions in\n",
    "                                           | ``a_ph``.\n",
    "            ``q2``       (batch,)          | Gives another estimate of Q* for \n",
    "                                           | states in ``x_ph`` and actions in\n",
    "                                           | ``a_ph``.\n",
    "            ``q1_pi``    (batch,)          | Gives the composition of ``q1`` and \n",
    "                                           | ``pi`` for states in ``x_ph``: \n",
    "                                           | q1(x, pi(x)).\n",
    "            ``q2_pi``    (batch,)          | Gives the composition of ``q2`` and \n",
    "                                           | ``pi`` for states in ``x_ph``: \n",
    "                                           | q2(x, pi(x)).\n",
    "            ``v``        (batch,)          | Gives the value estimate for states\n",
    "                                           | in ``x_ph``. \n",
    "            ===========  ================  ======================================\n",
    "        ac_kwargs (dict): Any kwargs appropriate for the actor_critic \n",
    "            function you provided to SAC.\n",
    "        seed (int): Seed for random number generators.\n",
    "        steps_per_epoch (int): Number of steps of interaction (state-action pairs) \n",
    "            for the agent and the environment in each epoch.\n",
    "        epochs (int): Number of epochs to run and train agent.\n",
    "        replay_size (int): Maximum length of replay buffer.\n",
    "        gamma (float): Discount factor. (Always between 0 and 1.)\n",
    "        polyak (float): Interpolation factor in polyak averaging for target \n",
    "            networks. Target networks are updated towards main networks \n",
    "            according to:\n",
    "            .. math:: \\\\theta_{\\\\text{targ}} \\\\leftarrow \n",
    "                \\\\rho \\\\theta_{\\\\text{targ}} + (1-\\\\rho) \\\\theta\n",
    "            where :math:`\\\\rho` is polyak. (Always between 0 and 1, usually \n",
    "            close to 1.)\n",
    "        lr (float): Learning rate (used for both policy and value learning).\n",
    "        alpha (float): Entropy regularization coefficient. (Equivalent to \n",
    "            inverse of reward scale in the original SAC paper.)\n",
    "        batch_size (int): Minibatch size for SGD.\n",
    "        start_steps (int): Number of steps for uniform-random action selection,\n",
    "            before running real policy. Helps exploration.\n",
    "        max_ep_len (int): Maximum length of trajectory / episode / rollout.\n",
    "        logger_kwargs (dict): Keyword args for EpochLogger.\n",
    "        save_freq (int): How often (in terms of gap between epochs) to save\n",
    "            the current policy and value function.\n",
    "    \"\"\"\n",
    "\n",
    "    logger = EpochLogger(**logger_kwargs)\n",
    "    logger.save_config(locals())\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    env, test_env = env_fn(), env_fn()\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    # Action limit for clamping: critically, assumes all dimensions share the same bound!\n",
    "    act_limit = env.action_space.high[0]\n",
    "\n",
    "    # Share information about action space with policy architecture\n",
    "    ac_kwargs['action_space'] = env.action_space\n",
    "\n",
    "    # Inputs to computation graph\n",
    "    x_ph, a_ph, x2_ph, r_ph, d_ph = core.placeholders(obs_dim, act_dim, obs_dim, None, None)\n",
    "\n",
    "    # Main outputs from computation graph\n",
    "    with tf.variable_scope('main'):\n",
    "        mu, pi, logp_pi, q1, q2, q1_pi, q2_pi, v = actor_critic(x_ph, a_ph, **ac_kwargs)\n",
    "    \n",
    "    # Target value network\n",
    "    with tf.variable_scope('target'):\n",
    "        _, _, _, _, _, _, _, v_targ  = actor_critic(x2_ph, a_ph, **ac_kwargs)\n",
    "\n",
    "    # Experience buffer\n",
    "    replay_buffer = ReplayBuffer(obs_dim=obs_dim, act_dim=act_dim, size=replay_size)\n",
    "\n",
    "    # Count variables\n",
    "    var_counts = tuple(core.count_vars(scope) for scope in \n",
    "                       ['main/pi', 'main/q1', 'main/q2', 'main/v', 'main'])\n",
    "    print(('\\nNumber of parameters: \\t pi: %d, \\t' + \\\n",
    "           'q1: %d, \\t q2: %d, \\t v: %d, \\t total: %d\\n')%var_counts)\n",
    "\n",
    "    # Min Double-Q:\n",
    "    min_q_pi = tf.minimum(q1_pi, q2_pi)\n",
    "\n",
    "    # Targets for Q and V regression\n",
    "    q_backup = tf.stop_gradient(r_ph + gamma*(1-d_ph)*v_targ)\n",
    "    v_backup = tf.stop_gradient(min_q_pi - alpha * logp_pi)\n",
    "\n",
    "    # Soft actor-critic losses\n",
    "    pi_loss = tf.reduce_mean(alpha * logp_pi - q1_pi)\n",
    "    q1_loss = 0.5 * tf.reduce_mean((q_backup - q1)**2)\n",
    "    q2_loss = 0.5 * tf.reduce_mean((q_backup - q2)**2)\n",
    "    v_loss = 0.5 * tf.reduce_mean((v_backup - v)**2)\n",
    "    value_loss = q1_loss + q2_loss + v_loss\n",
    "\n",
    "    # Policy train op \n",
    "    # (has to be separate from value train op, because q1_pi appears in pi_loss)\n",
    "    pi_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_pi_op = pi_optimizer.minimize(pi_loss, var_list=get_vars('main/pi'))\n",
    "\n",
    "    # Value train op\n",
    "    # (control dep of train_pi_op because sess.run otherwise evaluates in nondeterministic order)\n",
    "    value_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    value_params = get_vars('main/q') + get_vars('main/v')\n",
    "    with tf.control_dependencies([train_pi_op]):\n",
    "        train_value_op = value_optimizer.minimize(value_loss, var_list=value_params)\n",
    "\n",
    "    # Polyak averaging for target variables\n",
    "    # (control flow because sess.run otherwise evaluates in nondeterministic order)\n",
    "    with tf.control_dependencies([train_value_op]):\n",
    "        target_update = tf.group([tf.assign(v_targ, polyak*v_targ + (1-polyak)*v_main)\n",
    "                                  for v_main, v_targ in zip(get_vars('main'), get_vars('target'))])\n",
    "\n",
    "    # All ops to call during one training step\n",
    "    step_ops = [pi_loss, q1_loss, q2_loss, v_loss, q1, q2, v, logp_pi, \n",
    "                train_pi_op, train_value_op, target_update]\n",
    "\n",
    "    # Initializing targets to match main variables\n",
    "    target_init = tf.group([tf.assign(v_targ, v_main)\n",
    "                              for v_main, v_targ in zip(get_vars('main'), get_vars('target'))])\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(target_init)\n",
    "\n",
    "    # Setup model saving\n",
    "    logger.setup_tf_saver(sess, inputs={'x': x_ph, 'a': a_ph}, \n",
    "                                outputs={'mu': mu, 'pi': pi, 'q1': q1, 'q2': q2, 'v': v})\n",
    "\n",
    "    def get_action(o, deterministic=False):\n",
    "        act_op = mu if deterministic else pi\n",
    "        return sess.run(act_op, feed_dict={x_ph: o.reshape(1,-1)})[0]\n",
    "\n",
    "    def test_agent(n=10):\n",
    "        global sess, mu, pi, q1, q2, q1_pi, q2_pi\n",
    "        for j in range(n):\n",
    "            o, r, d, ep_ret, ep_len = test_env.reset(), 0, False, 0, 0\n",
    "            while not(d or (ep_len == max_ep_len)):\n",
    "                # Take deterministic actions at test time \n",
    "                o, r, d, _ = test_env.step(get_action(o, True))\n",
    "                ep_ret += r\n",
    "                ep_len += 1\n",
    "            logger.store(TestEpRet=ep_ret, TestEpLen=ep_len)\n",
    "\n",
    "    start_time = time.time()\n",
    "    o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "\n",
    "    # Main loop: collect experience in env and update/log each epoch\n",
    "    for t in range(total_steps):\n",
    "\n",
    "        \"\"\"\n",
    "        Until start_steps have elapsed, randomly sample actions\n",
    "        from a uniform distribution for better exploration. Afterwards, \n",
    "        use the learned policy. \n",
    "        \"\"\"\n",
    "        if t > start_steps:\n",
    "            a = get_action(o)\n",
    "        else:\n",
    "            a = env.action_space.sample()\n",
    "\n",
    "        # Step the env\n",
    "        o2, r, d, _ = env.step(a)\n",
    "        ep_ret += r\n",
    "        ep_len += 1\n",
    "\n",
    "        # Ignore the \"done\" signal if it comes from hitting the time\n",
    "        # horizon (that is, when it's an artificial terminal signal\n",
    "        # that isn't based on the agent's state)\n",
    "        d = False if ep_len==max_ep_len else d\n",
    "\n",
    "        # Store experience to replay buffer\n",
    "        replay_buffer.store(o, a, r, o2, d)\n",
    "\n",
    "        # Super critical, easy to overlook step: make sure to update \n",
    "        # most recent observation!\n",
    "        o = o2\n",
    "\n",
    "        if d or (ep_len == max_ep_len):\n",
    "            \"\"\"\n",
    "            Perform all SAC updates at the end of the trajectory.\n",
    "            This is a slight difference from the SAC specified in the\n",
    "            original paper.\n",
    "            \"\"\"\n",
    "            for j in range(ep_len):\n",
    "                batch = replay_buffer.sample_batch(batch_size)\n",
    "                feed_dict = {x_ph: batch['obs1'],\n",
    "                             x2_ph: batch['obs2'],\n",
    "                             a_ph: batch['acts'],\n",
    "                             r_ph: batch['rews'],\n",
    "                             d_ph: batch['done'],\n",
    "                            }\n",
    "                outs = sess.run(step_ops, feed_dict)\n",
    "                logger.store(LossPi=outs[0], LossQ1=outs[1], LossQ2=outs[2],\n",
    "                             LossV=outs[3], Q1Vals=outs[4], Q2Vals=outs[5],\n",
    "                             VVals=outs[6], LogPi=outs[7])\n",
    "\n",
    "            logger.store(EpRet=ep_ret, EpLen=ep_len)\n",
    "            o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "\n",
    "\n",
    "        # End of epoch wrap-up\n",
    "        if t > 0 and t % steps_per_epoch == 0:\n",
    "            epoch = t // steps_per_epoch\n",
    "\n",
    "            # Save model\n",
    "            if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
    "                logger.save_state({'env': env}, None)\n",
    "\n",
    "            # Test the performance of the deterministic version of the agent.\n",
    "            test_agent()\n",
    "\n",
    "            # Log info about epoch\n",
    "            logger.log_tabular('Epoch', epoch)\n",
    "            logger.log_tabular('EpRet', with_min_and_max=True)\n",
    "            logger.log_tabular('TestEpRet', with_min_and_max=True)\n",
    "            logger.log_tabular('EpLen', average_only=True)\n",
    "            logger.log_tabular('TestEpLen', average_only=True)\n",
    "            logger.log_tabular('TotalEnvInteracts', t)\n",
    "            logger.log_tabular('Q1Vals', with_min_and_max=True) \n",
    "            logger.log_tabular('Q2Vals', with_min_and_max=True) \n",
    "            logger.log_tabular('VVals', with_min_and_max=True) \n",
    "            logger.log_tabular('LogPi', with_min_and_max=True)\n",
    "            logger.log_tabular('LossPi', average_only=True)\n",
    "            logger.log_tabular('LossQ1', average_only=True)\n",
    "            logger.log_tabular('LossQ2', average_only=True)\n",
    "            logger.log_tabular('LossV', average_only=True)\n",
    "            logger.log_tabular('Time', time.time()-start_time)\n",
    "            logger.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env='HalfCheetah-v1'\n",
    "env='Act-v0'\n",
    "hid=300\n",
    "l=1\n",
    "gamma=0.99\n",
    "seed=0\n",
    "epochs=10\n",
    "exp_name='sac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spinup.utils.run_utils import setup_logger_kwargs\n",
    "logger_kwargs = setup_logger_kwargs(exp_name, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:21:45,113] Making new env: Act-v0\n",
      "[2019-03-05 19:21:45,149] Making new env: Act-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Log dir /home/phw/rsl/CS234_Project/data/sac/sac_s0 already exists! Storing info there anyway.\n",
      "\u001b[32;1mLogging data to /home/phw/rsl/CS234_Project/data/sac/sac_s0/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"ac_kwargs\":\t{\n",
      "        \"hidden_sizes\":\t[\n",
      "            300\n",
      "        ]\n",
      "    },\n",
      "    \"actor_critic\":\t\"mlp_actor_critic\",\n",
      "    \"alpha\":\t0.2,\n",
      "    \"batch_size\":\t100,\n",
      "    \"env_fn\":\t\"<function <lambda> at 0x7ff57c170488>\",\n",
      "    \"epochs\":\t10,\n",
      "    \"exp_name\":\t\"sac\",\n",
      "    \"gamma\":\t0.99,\n",
      "    \"logger\":\t{\n",
      "        \"<spinup.utils.logx.EpochLogger object at 0x7ff57c1a66d8>\":\t{\n",
      "            \"epoch_dict\":\t{},\n",
      "            \"exp_name\":\t\"sac\",\n",
      "            \"first_row\":\ttrue,\n",
      "            \"log_current_row\":\t{},\n",
      "            \"log_headers\":\t[],\n",
      "            \"output_dir\":\t\"/home/phw/rsl/CS234_Project/data/sac/sac_s0\",\n",
      "            \"output_file\":\t{\n",
      "                \"<_io.TextIOWrapper name='/home/phw/rsl/CS234_Project/data/sac/sac_s0/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "                    \"mode\":\t\"w\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"logger_kwargs\":\t{\n",
      "        \"exp_name\":\t\"sac\",\n",
      "        \"output_dir\":\t\"/home/phw/rsl/CS234_Project/data/sac/sac_s0\"\n",
      "    },\n",
      "    \"lr\":\t0.001,\n",
      "    \"max_ep_len\":\t1000,\n",
      "    \"polyak\":\t0.995,\n",
      "    \"replay_size\":\t1000000,\n",
      "    \"save_freq\":\t1,\n",
      "    \"seed\":\t0,\n",
      "    \"start_steps\":\t10000,\n",
      "    \"steps_per_epoch\":\t5000\n",
      "}\n",
      "SEED 236790894182794150\n",
      "SEED 15177649620037113100\n",
      "\n",
      "Number of parameters: \t pi: 14102, \tq1: 14101, \t q2: 14101, \t v: 13801, \t total: 56105\n",
      "\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:01,964] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:01,966] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:02,289] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               1 |\n",
      "|      AverageEpRet |            -765 |\n",
      "|          StdEpRet |             424 |\n",
      "|          MaxEpRet |            42.2 |\n",
      "|          MinEpRet |       -1.01e+03 |\n",
      "|  AverageTestEpRet |            -754 |\n",
      "|      StdTestEpRet |             427 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -976 |\n",
      "|             EpLen |             250 |\n",
      "|         TestEpLen |            22.9 |\n",
      "| TotalEnvInteracts |           5e+03 |\n",
      "|     AverageQ1Vals |            -402 |\n",
      "|         StdQ1Vals |             252 |\n",
      "|         MaxQ1Vals |             299 |\n",
      "|         MinQ1Vals |       -2.42e+03 |\n",
      "|     AverageQ2Vals |            -402 |\n",
      "|         StdQ2Vals |             256 |\n",
      "|         MaxQ2Vals |             324 |\n",
      "|         MinQ2Vals |       -3.48e+03 |\n",
      "|      AverageVVals |            -406 |\n",
      "|          StdVVals |             259 |\n",
      "|          MaxVVals |             320 |\n",
      "|          MinVVals |       -2.99e+03 |\n",
      "|      AverageLogPi |            10.3 |\n",
      "|          StdLogPi |            1.05 |\n",
      "|          MaxLogPi |            32.9 |\n",
      "|          MinLogPi |           -6.55 |\n",
      "|            LossPi |             403 |\n",
      "|            LossQ1 |        1.18e+03 |\n",
      "|            LossQ2 |        2.23e+03 |\n",
      "|             LossV |        2.37e+03 |\n",
      "|              Time |            16.1 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:20,943] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:20,944] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:21,322] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               2 |\n",
      "|      AverageEpRet |            -799 |\n",
      "|          StdEpRet |             391 |\n",
      "|          MaxEpRet |            -7.9 |\n",
      "|          MinEpRet |       -1.01e+03 |\n",
      "|  AverageTestEpRet |            -956 |\n",
      "|      StdTestEpRet |            19.7 |\n",
      "|      MaxTestEpRet |            -914 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |             224 |\n",
      "|         TestEpLen |            22.2 |\n",
      "| TotalEnvInteracts |           1e+04 |\n",
      "|     AverageQ1Vals |            -468 |\n",
      "|         StdQ1Vals |             240 |\n",
      "|         MaxQ1Vals |           -58.3 |\n",
      "|         MinQ1Vals |       -1.29e+03 |\n",
      "|     AverageQ2Vals |            -468 |\n",
      "|         StdQ2Vals |             240 |\n",
      "|         MaxQ2Vals |           -56.1 |\n",
      "|         MinQ2Vals |       -1.23e+03 |\n",
      "|      AverageVVals |            -470 |\n",
      "|          StdVVals |             241 |\n",
      "|          MaxVVals |           -36.9 |\n",
      "|          MinVVals |       -1.29e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.706 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |           0.513 |\n",
      "|            LossPi |             468 |\n",
      "|            LossQ1 |             217 |\n",
      "|            LossQ2 |             211 |\n",
      "|             LossV |            86.2 |\n",
      "|              Time |            35.1 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:43,873] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:43,874] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:22:44,227] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               3 |\n",
      "|      AverageEpRet |            -844 |\n",
      "|          StdEpRet |             354 |\n",
      "|          MaxEpRet |         1.3e+03 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -749 |\n",
      "|      StdTestEpRet |             424 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |            26.9 |\n",
      "|         TestEpLen |            25.7 |\n",
      "| TotalEnvInteracts |         1.5e+04 |\n",
      "|     AverageQ1Vals |            -494 |\n",
      "|         StdQ1Vals |             235 |\n",
      "|         MaxQ1Vals |           -82.1 |\n",
      "|         MinQ1Vals |       -1.12e+03 |\n",
      "|     AverageQ2Vals |            -494 |\n",
      "|         StdQ2Vals |             235 |\n",
      "|         MaxQ2Vals |           -81.6 |\n",
      "|         MinQ2Vals |       -1.12e+03 |\n",
      "|      AverageVVals |            -496 |\n",
      "|          StdVVals |             235 |\n",
      "|          MaxVVals |           -86.2 |\n",
      "|          MinVVals |       -1.14e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.708 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |           -1.54 |\n",
      "|            LossPi |             495 |\n",
      "|            LossQ1 |             329 |\n",
      "|            LossQ2 |             325 |\n",
      "|             LossV |            87.7 |\n",
      "|              Time |            58.1 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:06,742] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:06,743] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:07,111] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               4 |\n",
      "|      AverageEpRet |            -847 |\n",
      "|          StdEpRet |             330 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -857 |\n",
      "|      StdTestEpRet |             319 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |            22.6 |\n",
      "|         TestEpLen |            21.3 |\n",
      "| TotalEnvInteracts |           2e+04 |\n",
      "|     AverageQ1Vals |            -553 |\n",
      "|         StdQ1Vals |             265 |\n",
      "|         MaxQ1Vals |             248 |\n",
      "|         MinQ1Vals |       -1.07e+03 |\n",
      "|     AverageQ2Vals |            -553 |\n",
      "|         StdQ2Vals |             265 |\n",
      "|         MaxQ2Vals |             244 |\n",
      "|         MinQ2Vals |       -1.07e+03 |\n",
      "|      AverageVVals |            -556 |\n",
      "|          StdVVals |             266 |\n",
      "|          MaxVVals |             270 |\n",
      "|          MinVVals |       -1.09e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.706 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |           -1.39 |\n",
      "|            LossPi |             554 |\n",
      "|            LossQ1 |             557 |\n",
      "|            LossQ2 |             555 |\n",
      "|             LossV |              94 |\n",
      "|              Time |            80.9 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:27,837] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:27,838] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:28,215] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               5 |\n",
      "|      AverageEpRet |            -838 |\n",
      "|          StdEpRet |             340 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -960 |\n",
      "|      StdTestEpRet |            18.9 |\n",
      "|      MaxTestEpRet |            -914 |\n",
      "|      MinTestEpRet |            -976 |\n",
      "|             EpLen |            23.2 |\n",
      "|         TestEpLen |            20.2 |\n",
      "| TotalEnvInteracts |         2.5e+04 |\n",
      "|     AverageQ1Vals |            -577 |\n",
      "|         StdQ1Vals |             278 |\n",
      "|         MaxQ1Vals |             291 |\n",
      "|         MinQ1Vals |       -1.05e+03 |\n",
      "|     AverageQ2Vals |            -577 |\n",
      "|         StdQ2Vals |             278 |\n",
      "|         MaxQ2Vals |             275 |\n",
      "|         MinQ2Vals |       -1.05e+03 |\n",
      "|      AverageVVals |            -581 |\n",
      "|          StdVVals |             279 |\n",
      "|          MaxVVals |             328 |\n",
      "|          MinVVals |       -1.06e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.707 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |           -1.32 |\n",
      "|            LossPi |             579 |\n",
      "|            LossQ1 |             910 |\n",
      "|            LossQ2 |             905 |\n",
      "|             LossV |             121 |\n",
      "|              Time |             102 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:49,319] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:49,321] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:23:49,718] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               6 |\n",
      "|      AverageEpRet |            -873 |\n",
      "|          StdEpRet |             296 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -851 |\n",
      "|      StdTestEpRet |             317 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -970 |\n",
      "|             EpLen |            21.2 |\n",
      "|         TestEpLen |            24.5 |\n",
      "| TotalEnvInteracts |           3e+04 |\n",
      "|     AverageQ1Vals |            -595 |\n",
      "|         StdQ1Vals |             279 |\n",
      "|         MaxQ1Vals |             306 |\n",
      "|         MinQ1Vals |       -1.03e+03 |\n",
      "|     AverageQ2Vals |            -595 |\n",
      "|         StdQ2Vals |             279 |\n",
      "|         MaxQ2Vals |             295 |\n",
      "|         MinQ2Vals |       -1.03e+03 |\n",
      "|      AverageVVals |            -599 |\n",
      "|          StdVVals |             279 |\n",
      "|          MaxVVals |             339 |\n",
      "|          MinVVals |       -1.04e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.708 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |          -0.823 |\n",
      "|            LossPi |             596 |\n",
      "|            LossQ1 |        1.11e+03 |\n",
      "|            LossQ2 |        1.11e+03 |\n",
      "|             LossV |             132 |\n",
      "|              Time |             124 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:10,693] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:10,694] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:11,112] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               7 |\n",
      "|      AverageEpRet |            -879 |\n",
      "|          StdEpRet |             285 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -751 |\n",
      "|      StdTestEpRet |             425 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -978 |\n",
      "|             EpLen |            21.6 |\n",
      "|         TestEpLen |            24.7 |\n",
      "| TotalEnvInteracts |         3.5e+04 |\n",
      "|     AverageQ1Vals |            -624 |\n",
      "|         StdQ1Vals |             277 |\n",
      "|         MaxQ1Vals |             284 |\n",
      "|         MinQ1Vals |       -1.06e+03 |\n",
      "|     AverageQ2Vals |            -624 |\n",
      "|         StdQ2Vals |             277 |\n",
      "|         MaxQ2Vals |             284 |\n",
      "|         MinQ2Vals |       -1.05e+03 |\n",
      "|      AverageVVals |            -628 |\n",
      "|          StdVVals |             277 |\n",
      "|          MaxVVals |             327 |\n",
      "|          MinVVals |       -1.07e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.706 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |           -1.09 |\n",
      "|            LossPi |             625 |\n",
      "|            LossQ1 |        1.13e+03 |\n",
      "|            LossQ2 |        1.13e+03 |\n",
      "|             LossV |             137 |\n",
      "|              Time |             145 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:32,119] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:32,120] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:32,579] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               8 |\n",
      "|      AverageEpRet |            -856 |\n",
      "|          StdEpRet |             317 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -982 |\n",
      "|  AverageTestEpRet |            -965 |\n",
      "|      StdTestEpRet |            11.7 |\n",
      "|      MaxTestEpRet |            -944 |\n",
      "|      MinTestEpRet |            -982 |\n",
      "|             EpLen |            22.4 |\n",
      "|         TestEpLen |            17.6 |\n",
      "| TotalEnvInteracts |           4e+04 |\n",
      "|     AverageQ1Vals |            -647 |\n",
      "|         StdQ1Vals |             276 |\n",
      "|         MaxQ1Vals |             318 |\n",
      "|         MinQ1Vals |       -1.06e+03 |\n",
      "|     AverageQ2Vals |            -647 |\n",
      "|         StdQ2Vals |             276 |\n",
      "|         MaxQ2Vals |             329 |\n",
      "|         MinQ2Vals |       -1.06e+03 |\n",
      "|      AverageVVals |            -652 |\n",
      "|          StdVVals |             276 |\n",
      "|          MaxVVals |             350 |\n",
      "|          MinVVals |       -1.07e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.706 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |          -0.231 |\n",
      "|            LossPi |             649 |\n",
      "|            LossQ1 |        1.11e+03 |\n",
      "|            LossQ2 |        1.11e+03 |\n",
      "|             LossV |             131 |\n",
      "|              Time |             166 |\n",
      "---------------------------------------\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:53,224] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:53,225] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 19:24:53,725] SavedModel written to: b'/home/phw/rsl/CS234_Project/data/sac/sac_s0/simple_save/saved_model.pb'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               9 |\n",
      "|      AverageEpRet |            -842 |\n",
      "|          StdEpRet |             334 |\n",
      "|          MaxEpRet |             100 |\n",
      "|          MinEpRet |            -980 |\n",
      "|  AverageTestEpRet |            -748 |\n",
      "|      StdTestEpRet |             424 |\n",
      "|      MaxTestEpRet |             100 |\n",
      "|      MinTestEpRet |            -972 |\n",
      "|             EpLen |            23.2 |\n",
      "|         TestEpLen |            25.8 |\n",
      "| TotalEnvInteracts |         4.5e+04 |\n",
      "|     AverageQ1Vals |            -665 |\n",
      "|         StdQ1Vals |             274 |\n",
      "|         MaxQ1Vals |             336 |\n",
      "|         MinQ1Vals |       -1.05e+03 |\n",
      "|     AverageQ2Vals |            -665 |\n",
      "|         StdQ2Vals |             274 |\n",
      "|         MaxQ2Vals |             350 |\n",
      "|         MinQ2Vals |       -1.05e+03 |\n",
      "|      AverageVVals |            -670 |\n",
      "|          StdVVals |             274 |\n",
      "|          MaxVVals |             330 |\n",
      "|          MinVVals |       -1.06e+03 |\n",
      "|      AverageLogPi |            10.4 |\n",
      "|          StdLogPi |           0.708 |\n",
      "|          MaxLogPi |            10.9 |\n",
      "|          MinLogPi |          -0.255 |\n",
      "|            LossPi |             666 |\n",
      "|            LossQ1 |        1.09e+03 |\n",
      "|            LossQ2 |        1.09e+03 |\n",
      "|             LossV |             141 |\n",
      "|              Time |             188 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sac(lambda : gym.make(env), \n",
    "    actor_critic=core.mlp_actor_critic,\n",
    "    ac_kwargs=dict(hidden_sizes=[hid]*l),\n",
    "    gamma=gamma, \n",
    "    seed=seed, \n",
    "    epochs=epochs,\n",
    "    logger_kwargs=logger_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
