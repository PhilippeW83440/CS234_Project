{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-10 15:44:14,447] Making new env: Act-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 6887498492990337069\n"
     ]
    }
   ],
   "source": [
    "# to install gym_act:\n",
    "# git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# cd gym-act\n",
    "# pip install -e .\n",
    "import gym_act\n",
    "\n",
    "# source code is in https://github.com/PhilippeW83440/CS234_Project/blob/master/gym-act/gym_act/envs/act_env.py\n",
    "# or if you did: git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# in CS234_Project/gym-act/gym_act/envs/act_env.py\n",
    "env = gym.make(\"Act-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, reward, done, info = env.step(action)\n",
    "print(\"reward {}\".format(reward))\n",
    "img = env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def  resize_images(images, f=3):\n",
    "    big_images = []\n",
    "    for img in images:\n",
    "        big_images.append(cv2.resize(img, None, fx=f, fy=f))\n",
    "    return big_images\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Start episode 0\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 0 with cumulated_reward 0\n",
      "====> Start episode 1\n",
      "PENALTY smallest_TTC 8.62521334351289 smallest_TTC penalty 1.3747866564871103\n",
      "Step 0: action=0 reward=-23.747866564871103 done=False\n",
      "PENALTY smallest_TTC 8.405147154379282 smallest_TTC penalty 1.5948528456207178\n",
      "Step 1: action=0 reward=-25.94852845620718 done=False\n",
      "PENALTY smallest_TTC 8.185222325344615 smallest_TTC penalty 1.8147776746553852\n",
      "Step 2: action=0 reward=-28.147776746553852 done=False\n",
      "PENALTY smallest_TTC 7.96543707215604 smallest_TTC penalty 2.03456292784396\n",
      "Step 3: action=0 reward=-30.345629278439603 done=False\n",
      "PENALTY smallest_TTC 7.745789722985467 smallest_TTC penalty 2.2542102770145327\n",
      "Step 4: action=0 reward=-32.54210277014533 done=False\n",
      "PENALTY smallest_TTC 7.526278712901192 smallest_TTC penalty 2.473721287098808\n",
      "Step 5: action=0 reward=-34.73721287098808 done=False\n",
      "PENALTY smallest_TTC 7.306902578817698 smallest_TTC penalty 2.693097421182302\n",
      "Step 6: action=0 reward=-36.93097421182302 done=False\n",
      "PENALTY smallest_TTC 7.0876599548824855 smallest_TTC penalty 2.9123400451175145\n",
      "Step 7: action=0 reward=-39.123400451175144 done=False\n",
      "PENALTY smallest_TTC 6.868549568263387 smallest_TTC penalty 3.1314504317366127\n",
      "Step 8: action=0 reward=-41.31450431736613 done=False\n",
      "PENALTY smallest_TTC 6.649570235303939 smallest_TTC penalty 3.3504297646960612\n",
      "Step 9: action=0 reward=-43.50429764696061 done=False\n",
      "PENALTY smallest_TTC 6.430720858017952 smallest_TTC penalty 3.569279141982048\n",
      "Step 10: action=0 reward=-45.69279141982048 done=False\n",
      "PENALTY smallest_TTC 6.212000420897688 smallest_TTC penalty 3.787999579102312\n",
      "Step 11: action=0 reward=-47.87999579102312 done=False\n",
      "PENALTY smallest_TTC 5.993407988012822 smallest_TTC penalty 4.006592011987178\n",
      "Step 12: action=0 reward=-50.06592011987178 done=False\n",
      "PENALTY smallest_TTC 5.774942700379988 smallest_TTC penalty 4.225057299620012\n",
      "Step 13: action=0 reward=-52.25057299620012 done=False\n",
      "PENALTY smallest_TTC 5.556603773584905 smallest_TTC penalty 4.443396226415095\n",
      "Step 14: action=0 reward=-54.43396226415095 done=False\n",
      "PENALTY smallest_TTC 5.338390495641209 smallest_TTC penalty 4.661609504358791\n",
      "Step 15: action=0 reward=-56.616095043587904 done=False\n",
      "PENALTY smallest_TTC 5.12030222507189 smallest_TTC penalty 4.87969777492811\n",
      "Step 16: action=0 reward=-58.796977749281105 done=False\n",
      "PENALTY smallest_TTC 4.902338389200972 smallest_TTC penalty 5.097661610799028\n",
      "Step 17: action=0 reward=-60.97661610799028 done=False\n",
      "PENALTY smallest_TTC 4.684498482644582 smallest_TTC penalty 5.315501517355418\n",
      "Step 18: action=0 reward=-63.15501517355418 done=False\n",
      "PENALTY smallest_TTC 4.466782065991939 smallest_TTC penalty 5.533217934008061\n",
      "Step 19: action=0 reward=-65.33217934008061 done=False\n",
      "PENALTY smallest_TTC 4.249188764668136 smallest_TTC penalty 5.750811235331864\n",
      "Step 20: action=0 reward=-67.50811235331864 done=False\n",
      "PENALTY smallest_TTC 4.0317182679717485 smallest_TTC penalty 5.9682817320282515\n",
      "Step 21: action=0 reward=-69.68281732028251 done=False\n",
      "PENALTY smallest_TTC 3.814370328281456 smallest_TTC penalty 6.185629671718544\n",
      "Step 22: action=0 reward=-71.85629671718544 done=False\n",
      "PENALTY smallest_TTC 3.597144760426919 smallest_TTC penalty 6.402855239573081\n",
      "Step 23: action=0 reward=-74.02855239573081 done=False\n",
      "PENALTY smallest_TTC 3.380041441220161 smallest_TTC penalty 6.619958558779839\n",
      "Step 24: action=0 reward=-76.1995855877984 done=False\n",
      "PENALTY smallest_TTC 3.1630603091446896 smallest_TTC penalty 6.83693969085531\n",
      "Step 25: action=0 reward=-78.3693969085531 done=False\n",
      "PENALTY smallest_TTC 2.946201364200504 smallest_TTC penalty 7.053798635799496\n",
      "Step 26: action=0 reward=-80.53798635799497 done=False\n",
      "PENALTY smallest_TTC 2.7294646679040975 smallest_TTC penalty 7.2705353320959025\n",
      "Step 27: action=0 reward=-82.70535332095902 done=False\n",
      "PENALTY smallest_TTC 2.512850343443447 smallest_TTC penalty 7.487149656556554\n",
      "Step 28: action=0 reward=-84.87149656556554 done=False\n",
      "PENALTY smallest_TTC 2.296358575988891 smallest_TTC penalty 7.703641424011109\n",
      "Step 29: action=0 reward=-87.03641424011109 done=False\n",
      "PENALTY smallest_TTC 2.07998961316175 smallest_TTC penalty 7.92001038683825\n",
      "Step 30: action=0 reward=-89.2001038683825 done=False\n",
      "PENALTY smallest_TTC 1.8637437656634495 smallest_TTC penalty 8.13625623433655\n",
      "Step 31: action=0 reward=-91.3625623433655 done=False\n",
      "PENALTY smallest_TTC 1.6476214080688965 smallest_TTC penalty 8.352378591931103\n",
      "Step 32: action=0 reward=-93.52378591931102 done=False\n",
      "PENALTY smallest_TTC 1.4316229797888707 smallest_TTC penalty 8.568377020211129\n",
      "Step 33: action=0 reward=-95.68377020211129 done=False\n",
      "PENALTY smallest_TTC 1.2157489862072475 smallest_TTC penalty 8.784251013792753\n",
      "Step 34: action=0 reward=-97.84251013792753 done=False\n",
      "PENALTY smallest_TTC 1.0 smallest_TTC penalty 9.0\n",
      "Step 35: action=0 reward=-100.0 done=False\n",
      "PENALTY smallest_TTC 0.7843766626441387 smallest_TTC penalty 9.215623337355861\n",
      "Step 36: action=0 reward=-102.15623337355862 done=False\n",
      "PENALTY smallest_TTC 0.5688796861260297 smallest_TTC penalty 9.43112031387397\n",
      "Step 37: action=0 reward=-104.3112031387397 done=False\n",
      "PENALTY smallest_TTC 0.35350985485995173 smallest_TTC penalty 9.646490145140048\n",
      "Step 38: action=0 reward=-106.46490145140048 done=False\n",
      "PENALTY smallest_TTC 0.13826802782927322 smallest_TTC penalty 9.861731972170727\n",
      "Step 39: action=0 reward=-108.61731972170728 done=False\n",
      "PENALTY smallest_TTC 1.350429764696061 smallest_TTC penalty 8.649570235303939\n",
      "Step 40: action=0 reward=-96.49570235303939 done=False\n",
      "PENALTY smallest_TTC 1.1314504317366125 smallest_TTC penalty 8.868549568263388\n",
      "Step 41: action=0 reward=-10098.685495682634 done=True\n",
      "End of episode 1 with cumulated_reward -12848.682019279768\n",
      "====> Start episode 2\n",
      "PENALTY smallest_TTC 4.847199279560885 smallest_TTC penalty 5.152800720439115\n",
      "Step 0: action=0 reward=-61.528007204391145 done=False\n",
      "PENALTY smallest_TTC 4.616177258025976 smallest_TTC penalty 5.383822741974024\n",
      "Step 1: action=0 reward=-63.838227419740235 done=False\n",
      "PENALTY smallest_TTC 4.385192175075469 smallest_TTC penalty 5.614807824924531\n",
      "Step 2: action=0 reward=-66.14807824924532 done=False\n",
      "PENALTY smallest_TTC 4.1542429401194925 smallest_TTC penalty 5.8457570598805075\n",
      "Step 3: action=0 reward=-68.45757059880508 done=False\n",
      "PENALTY smallest_TTC 3.923328518210845 smallest_TTC penalty 6.076671481789155\n",
      "Step 4: action=0 reward=-70.76671481789155 done=False\n",
      "PENALTY smallest_TTC 3.692447926133726 smallest_TTC penalty 6.307552073866274\n",
      "Step 5: action=0 reward=-73.07552073866275 done=False\n",
      "PENALTY smallest_TTC 3.4616002288397305 smallest_TTC penalty 6.53839977116027\n",
      "Step 6: action=0 reward=-75.3839977116027 done=False\n",
      "PENALTY smallest_TTC 3.230784536194126 smallest_TTC penalty 6.769215463805875\n",
      "Step 7: action=0 reward=-77.69215463805875 done=False\n",
      "PENALTY smallest_TTC 3.0 smallest_TTC penalty 7.0\n",
      "Step 8: action=0 reward=-80.0 done=False\n",
      "PENALTY smallest_TTC 2.769245811271768 smallest_TTC penalty 7.230754188728232\n",
      "Step 9: action=0 reward=-82.30754188728233 done=False\n",
      "PENALTY smallest_TTC 2.5385211977329587 smallest_TTC penalty 7.461478802267042\n",
      "Step 10: action=0 reward=-84.61478802267041 done=False\n",
      "PENALTY smallest_TTC 2.3078254215160987 smallest_TTC penalty 7.692174578483901\n",
      "Step 11: action=0 reward=-86.92174578483902 done=False\n",
      "PENALTY smallest_TTC 2.077157777045093 smallest_TTC penalty 7.922842222954907\n",
      "Step 12: action=0 reward=-89.22842222954907 done=False\n",
      "PENALTY smallest_TTC 1.846517589082671 smallest_TTC penalty 8.153482410917329\n",
      "Step 13: action=0 reward=-91.53482410917329 done=False\n",
      "PENALTY smallest_TTC 1.6159042109274433 smallest_TTC penalty 8.384095789072557\n",
      "Step 14: action=0 reward=-93.84095789072558 done=False\n",
      "PENALTY smallest_TTC 1.385317022746762 smallest_TTC penalty 8.614682977253239\n",
      "Step 15: action=0 reward=-96.14682977253239 done=False\n",
      "PENALTY smallest_TTC 1.1547554300330825 smallest_TTC penalty 8.845244569966917\n",
      "Step 16: action=0 reward=-98.45244569966917 done=False\n",
      "PENALTY smallest_TTC 0.9242188621728131 smallest_TTC penalty 9.075781137827187\n",
      "Step 17: action=0 reward=-100.75781137827187 done=False\n",
      "PENALTY smallest_TTC 0.6937067711177765 smallest_TTC penalty 9.306293228882224\n",
      "Step 18: action=0 reward=-103.06293228882224 done=False\n",
      "PENALTY smallest_TTC 0.46321863015042763 smallest_TTC penalty 9.536781369849573\n",
      "Step 19: action=0 reward=-105.36781369849572 done=False\n",
      "PENALTY smallest_TTC 0.23275393273485193 smallest_TTC penalty 9.767246067265148\n",
      "Step 20: action=0 reward=-107.67246067265148 done=False\n",
      "PENALTY smallest_TTC 0.0023121914463660846 smallest_TTC penalty 9.997687808553634\n",
      "Step 21: action=0 reward=-109.97687808553634 done=False\n",
      "PENALTY smallest_TTC 0.4363765882947569 smallest_TTC penalty 9.563623411705244\n",
      "Step 22: action=0 reward=-105.63623411705244 done=False\n",
      "PENALTY smallest_TTC 0.21041852477552153 smallest_TTC penalty 9.789581475224479\n",
      "Step 23: action=0 reward=-107.89581475224479 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 2 with cumulated_reward -2100.307771767913\n",
      "====> Start episode 3\n",
      "PENALTY smallest_TTC 5.277961019306151 smallest_TTC penalty 4.722038980693849\n",
      "Step 0: action=0 reward=-57.22038980693849 done=False\n",
      "PENALTY smallest_TTC 5.074759312658538 smallest_TTC penalty 4.925240687341462\n",
      "Step 1: action=0 reward=-59.252406873414614 done=False\n",
      "PENALTY smallest_TTC 4.871793566245431 smallest_TTC penalty 5.128206433754569\n",
      "Step 2: action=0 reward=-61.28206433754569 done=False\n",
      "PENALTY smallest_TTC 4.669053400624185 smallest_TTC penalty 5.330946599375815\n",
      "Step 3: action=0 reward=-63.309465993758145 done=False\n",
      "PENALTY smallest_TTC 4.466529334800141 smallest_TTC penalty 5.533470665199859\n",
      "Step 4: action=0 reward=-65.33470665199859 done=False\n",
      "PENALTY smallest_TTC 4.264212682443573 smallest_TTC penalty 5.735787317556427\n",
      "Step 5: action=0 reward=-67.35787317556427 done=False\n",
      "PENALTY smallest_TTC 4.062095463172448 smallest_TTC penalty 5.937904536827552\n",
      "Step 6: action=0 reward=-69.37904536827551 done=False\n",
      "PENALTY smallest_TTC 3.860170326308392 smallest_TTC penalty 6.139829673691608\n",
      "Step 7: action=0 reward=-71.39829673691608 done=False\n",
      "PENALTY smallest_TTC 3.658430485025356 smallest_TTC penalty 6.341569514974644\n",
      "Step 8: action=0 reward=-73.41569514974644 done=False\n",
      "PENALTY smallest_TTC 3.45686965920911 smallest_TTC penalty 6.54313034079089\n",
      "Step 9: action=0 reward=-75.4313034079089 done=False\n",
      "PENALTY smallest_TTC 3.2554820256587234 smallest_TTC penalty 6.744517974341276\n",
      "Step 10: action=0 reward=-77.44517974341277 done=False\n",
      "PENALTY smallest_TTC 3.054262174508808 smallest_TTC penalty 6.945737825491192\n",
      "Step 11: action=0 reward=-79.45737825491192 done=False\n",
      "PENALTY smallest_TTC 2.853205070948568 smallest_TTC penalty 7.146794929051432\n",
      "Step 12: action=0 reward=-81.46794929051433 done=False\n",
      "PENALTY smallest_TTC 2.652306021471986 smallest_TTC penalty 7.347693978528014\n",
      "Step 13: action=0 reward=-83.47693978528014 done=False\n",
      "PENALTY smallest_TTC 2.4515606440212148 smallest_TTC penalty 7.548439355978785\n",
      "Step 14: action=0 reward=-85.48439355978785 done=False\n",
      "PENALTY smallest_TTC 2.250964841489033 smallest_TTC penalty 7.749035158510967\n",
      "Step 15: action=0 reward=-87.49035158510966 done=False\n",
      "PENALTY smallest_TTC 2.0505147781309563 smallest_TTC penalty 7.949485221869043\n",
      "Step 16: action=0 reward=-89.49485221869043 done=False\n",
      "PENALTY smallest_TTC 1.8502068585072098 smallest_TTC penalty 8.14979314149279\n",
      "Step 17: action=0 reward=-91.4979314149279 done=False\n",
      "PENALTY smallest_TTC 1.6500377086321958 smallest_TTC penalty 8.349962291367804\n",
      "Step 18: action=0 reward=-93.49962291367804 done=False\n",
      "PENALTY smallest_TTC 1.4500041590567496 smallest_TTC penalty 8.54999584094325\n",
      "Step 19: action=0 reward=-95.49995840943251 done=False\n",
      "PENALTY smallest_TTC 1.2501032296481647 smallest_TTC penalty 8.749896770351835\n",
      "Step 20: action=0 reward=-97.49896770351836 done=False\n",
      "PENALTY smallest_TTC 1.050332115866198 smallest_TTC penalty 8.949667884133802\n",
      "Step 21: action=0 reward=-99.49667884133802 done=False\n",
      "PENALTY smallest_TTC 0.8506881763611799 smallest_TTC penalty 9.14931182363882\n",
      "Step 22: action=0 reward=-101.4931182363882 done=False\n",
      "PENALTY smallest_TTC 0.6511689217439156 smallest_TTC penalty 9.348831078256085\n",
      "Step 23: action=0 reward=-103.48831078256084 done=False\n",
      "PENALTY smallest_TTC 0.45177200439701937 smallest_TTC penalty 9.54822799560298\n",
      "Step 24: action=0 reward=-105.4822799560298 done=False\n",
      "PENALTY smallest_TTC 0.2524952092142804 smallest_TTC penalty 9.747504790785719\n",
      "Step 25: action=0 reward=-107.47504790785719 done=False\n",
      "PENALTY smallest_TTC 0.05333644516913593 smallest_TTC penalty 9.946663554830865\n",
      "Step 26: action=0 reward=-109.46663554830864 done=False\n",
      "PENALTY smallest_TTC 1.0670114447159427 smallest_TTC penalty 8.932988555284057\n",
      "Step 27: action=0 reward=-99.32988555284057 done=False\n",
      "PENALTY smallest_TTC 0.8743852585299471 smallest_TTC penalty 9.125614741470052\n",
      "Step 28: action=0 reward=-10101.2561474147 done=True\n",
      "End of episode 3 with cumulated_reward -12453.182876621355\n",
      "====> Start episode 4\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 4 with cumulated_reward 0\n",
      "====> Start episode 5\n",
      "PENALTY smallest_TTC 2.3409146893799084 smallest_TTC penalty 7.659085310620092\n",
      "Step 0: action=0 reward=-86.59085310620091 done=False\n",
      "PENALTY smallest_TTC 2.1100778606275554 smallest_TTC penalty 7.889922139372445\n",
      "Step 1: action=0 reward=-88.89922139372445 done=False\n",
      "PENALTY smallest_TTC 1.8796512425532588 smallest_TTC penalty 8.120348757446742\n",
      "Step 2: action=0 reward=-91.20348757446742 done=False\n",
      "PENALTY smallest_TTC 1.6495943390727414 smallest_TTC penalty 8.350405660927258\n",
      "Step 3: action=0 reward=-93.50405660927258 done=False\n",
      "PENALTY smallest_TTC 1.4198732948753379 smallest_TTC penalty 8.580126705124663\n",
      "Step 4: action=0 reward=-95.80126705124663 done=False\n",
      "PENALTY smallest_TTC 1.1904594590781477 smallest_TTC penalty 8.809540540921851\n",
      "Step 5: action=0 reward=-98.09540540921851 done=False\n",
      "PENALTY smallest_TTC 0.9613283260373359 smallest_TTC penalty 9.038671673962664\n",
      "Step 6: action=0 reward=-100.38671673962665 done=False\n",
      "PENALTY smallest_TTC 0.7324587388032716 smallest_TTC penalty 9.267541261196728\n",
      "Step 7: action=0 reward=-102.67541261196727 done=False\n",
      "PENALTY smallest_TTC 0.5038322796790464 smallest_TTC penalty 9.496167720320953\n",
      "Step 8: action=0 reward=-104.96167720320953 done=False\n",
      "PENALTY smallest_TTC 0.27543279676318627 smallest_TTC penalty 9.724567203236814\n",
      "Step 9: action=0 reward=-107.24567203236815 done=False\n",
      "PENALTY smallest_TTC 0.04724603109541873 smallest_TTC penalty 9.952753968904581\n",
      "Step 10: action=0 reward=-109.52753968904581 done=False\n",
      "PENALTY smallest_TTC 0.43148105570201506 smallest_TTC penalty 9.568518944297985\n",
      "Step 11: action=0 reward=-105.68518944297985 done=False\n",
      "PENALTY smallest_TTC 0.21505394647151688 smallest_TTC penalty 9.784946053528483\n",
      "Step 12: action=0 reward=-107.84946053528483 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 5 with cumulated_reward -1292.4259593986126\n",
      "====> Start episode 6\n",
      "PENALTY smallest_TTC 3.197799010744908 smallest_TTC penalty 6.802200989255092\n",
      "Step 0: action=0 reward=-78.02200989255093 done=False\n",
      "PENALTY smallest_TTC 2.9750876327194717 smallest_TTC penalty 7.024912367280528\n",
      "Step 1: action=0 reward=-80.24912367280528 done=False\n",
      "PENALTY smallest_TTC 2.752428996041964 smallest_TTC penalty 7.247571003958036\n",
      "Step 2: action=0 reward=-82.47571003958036 done=False\n",
      "PENALTY smallest_TTC 2.529822916552176 smallest_TTC penalty 7.470177083447824\n",
      "Step 3: action=0 reward=-84.70177083447824 done=False\n",
      "PENALTY smallest_TTC 2.3072692285506204 smallest_TTC penalty 7.69273077144938\n",
      "Step 4: action=0 reward=-86.9273077144938 done=False\n",
      "PENALTY smallest_TTC 2.084767784516588 smallest_TTC penalty 7.915232215483412\n",
      "Step 5: action=0 reward=-89.15232215483412 done=False\n",
      "PENALTY smallest_TTC 1.8623184548587781 smallest_TTC penalty 8.137681545141222\n",
      "Step 6: action=0 reward=-91.37681545141221 done=False\n",
      "PENALTY smallest_TTC 1.6399211276975234 smallest_TTC penalty 8.360078872302477\n",
      "Step 7: action=0 reward=-93.60078872302478 done=False\n",
      "PENALTY smallest_TTC 1.417575708677735 smallest_TTC penalty 8.582424291322265\n",
      "Step 8: action=0 reward=-95.82424291322266 done=False\n",
      "PENALTY smallest_TTC 1.1952821208118403 smallest_TTC penalty 8.80471787918816\n",
      "Step 9: action=0 reward=-98.0471787918816 done=False\n",
      "PENALTY smallest_TTC 0.9730403043521 smallest_TTC penalty 9.0269596956479\n",
      "Step 10: action=0 reward=-100.269596956479 done=False\n",
      "PENALTY smallest_TTC 0.7508502166918061 smallest_TTC penalty 9.249149783308194\n",
      "Step 11: action=0 reward=-102.49149783308195 done=False\n",
      "PENALTY smallest_TTC 0.5287118322949788 smallest_TTC penalty 9.471288167705021\n",
      "Step 12: action=0 reward=-104.7128816770502 done=False\n",
      "PENALTY smallest_TTC 0.30662514265429375 smallest_TTC penalty 9.693374857345706\n",
      "Step 13: action=0 reward=-106.93374857345705 done=False\n",
      "PENALTY smallest_TTC 0.08459015627707527 smallest_TTC penalty 9.915409843722925\n",
      "Step 14: action=0 reward=-109.15409843722925 done=False\n",
      "PENALTY smallest_TTC 0.8047178791881598 smallest_TTC penalty 9.19528212081184\n",
      "Step 15: action=0 reward=-101.9528212081184 done=False\n",
      "PENALTY smallest_TTC 0.582424291322265 smallest_TTC penalty 9.417575708677735\n",
      "Step 16: action=0 reward=-10104.175757086778 done=True\n",
      "End of episode 6 with cumulated_reward -11610.067671960478\n",
      "====> Start episode 7\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC 0.17168462806365192 smallest_TTC penalty 9.828315371936348\n",
      "Step 15: action=0 reward=-108.28315371936348 done=False\n",
      "PENALTY smallest_TTC 0.0815544331605826 smallest_TTC penalty 9.918445566839418\n",
      "Step 16: action=0 reward=-109.18445566839418 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 7 with cumulated_reward -217.46760938775765\n",
      "====> Start episode 8\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC 6.447810816283772 smallest_TTC penalty 3.5521891837162283\n",
      "Step 1: action=0 reward=-45.521891837162286 done=False\n",
      "PENALTY smallest_TTC 6.077346971997878 smallest_TTC penalty 3.922653028002122\n",
      "Step 2: action=0 reward=-49.22653028002122 done=False\n",
      "PENALTY smallest_TTC 5.784871451667988 smallest_TTC penalty 4.215128548332012\n",
      "Step 3: action=0 reward=-52.151285483320116 done=False\n",
      "PENALTY smallest_TTC 5.514898014585296 smallest_TTC penalty 4.485101985414704\n",
      "Step 4: action=0 reward=-54.85101985414704 done=False\n",
      "PENALTY smallest_TTC 5.257556723413639 smallest_TTC penalty 4.742443276586361\n",
      "Step 5: action=0 reward=-57.42443276586361 done=False\n",
      "PENALTY smallest_TTC 5.008811262806391 smallest_TTC penalty 4.991188737193609\n",
      "Step 6: action=0 reward=-59.91188737193609 done=False\n",
      "PENALTY smallest_TTC 4.7665334603869 smallest_TTC penalty 5.2334665396131\n",
      "Step 7: action=0 reward=-62.334665396131 done=False\n",
      "PENALTY smallest_TTC 4.529438742438545 smallest_TTC penalty 5.470561257561455\n",
      "Step 8: action=0 reward=-64.70561257561455 done=False\n",
      "PENALTY smallest_TTC 4.296683552803586 smallest_TTC penalty 5.703316447196414\n",
      "Step 9: action=0 reward=-67.03316447196414 done=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENALTY smallest_TTC 4.067681690592595 smallest_TTC penalty 5.932318309407405\n",
      "Step 10: action=0 reward=-69.32318309407405 done=False\n",
      "PENALTY smallest_TTC 3.8420095244079207 smallest_TTC penalty 6.157990475592079\n",
      "Step 11: action=0 reward=-71.5799047559208 done=False\n",
      "PENALTY smallest_TTC 3.6193525989104196 smallest_TTC penalty 6.380647401089581\n",
      "Step 12: action=0 reward=-73.80647401089581 done=False\n",
      "PENALTY smallest_TTC 3.3994735466361754 smallest_TTC penalty 6.600526453363825\n",
      "Step 13: action=0 reward=-76.00526453363825 done=False\n",
      "PENALTY smallest_TTC 3.1821918475037507 smallest_TTC penalty 6.81780815249625\n",
      "Step 14: action=0 reward=-78.1780815249625 done=False\n",
      "PENALTY smallest_TTC 2.967370605744518 smallest_TTC penalty 7.032629394255482\n",
      "Step 15: action=0 reward=-80.32629394255481 done=False\n",
      "PENALTY smallest_TTC 2.7549077171280647 smallest_TTC penalty 7.245092282871935\n",
      "Step 16: action=0 reward=-82.45092282871936 done=False\n",
      "PENALTY smallest_TTC 2.5447299279971354 smallest_TTC penalty 7.455270072002865\n",
      "Step 17: action=0 reward=-84.55270072002864 done=False\n",
      "PENALTY smallest_TTC 2.3367889039419247 smallest_TTC penalty 7.663211096058076\n",
      "Step 18: action=0 reward=-86.63211096058076 done=False\n",
      "PENALTY smallest_TTC 2.1310587840303916 smallest_TTC penalty 7.868941215969608\n",
      "Step 19: action=0 reward=-88.68941215969608 done=False\n",
      "PENALTY smallest_TTC 1.927534919908317 smallest_TTC penalty 8.072465080091684\n",
      "Step 20: action=0 reward=-90.72465080091683 done=False\n",
      "PENALTY smallest_TTC 1.7262336526566637 smallest_TTC penalty 8.273766347343336\n",
      "Step 21: action=0 reward=-92.73766347343337 done=False\n",
      "PENALTY smallest_TTC 1.5271931019441334 smallest_TTC penalty 8.472806898055866\n",
      "Step 22: action=0 reward=-94.72806898055866 done=False\n",
      "PENALTY smallest_TTC 1.3304750582979814 smallest_TTC penalty 8.669524941702019\n",
      "Step 23: action=0 reward=-96.6952494170202 done=False\n",
      "PENALTY smallest_TTC 1.1361682049579929 smallest_TTC penalty 8.863831795042007\n",
      "Step 24: action=0 reward=-98.63831795042006 done=False\n",
      "PENALTY smallest_TTC 0.9443930822211418 smallest_TTC penalty 9.055606917778858\n",
      "Step 25: action=0 reward=-100.55606917778859 done=False\n",
      "PENALTY smallest_TTC 0.7553094946803083 smallest_TTC penalty 9.244690505319692\n",
      "Step 26: action=0 reward=-102.44690505319693 done=False\n",
      "PENALTY smallest_TTC 0.5691275421245632 smallest_TTC penalty 9.430872457875436\n",
      "Step 27: action=0 reward=-104.30872457875437 done=False\n",
      "PENALTY smallest_TTC 0.38612431089369686 smallest_TTC penalty 9.613875689106303\n",
      "Step 28: action=0 reward=-106.13875689106303 done=False\n",
      "PENALTY smallest_TTC 0.206669885487122 smallest_TTC penalty 9.793330114512878\n",
      "Step 29: action=0 reward=-107.93330114512878 done=False\n",
      "PENALTY smallest_TTC 0.03126963468523462 smallest_TTC penalty 9.968730365314766\n",
      "Step 30: action=0 reward=-109.68730365314767 done=False\n",
      "PENALTY smallest_TTC 0.8773542857842681 smallest_TTC penalty 9.122645714215732\n",
      "Step 31: action=0 reward=-101.22645714215733 done=False\n",
      "PENALTY smallest_TTC 0.6316823632609047 smallest_TTC penalty 9.368317636739095\n",
      "Step 32: action=0 reward=-103.68317636739094 done=False\n",
      "PENALTY smallest_TTC 0.37850751086326395 smallest_TTC penalty 9.621492489136736\n",
      "Step 33: action=0 reward=-106.21492489136736 done=False\n",
      "PENALTY smallest_TTC 0.1148579729624278 smallest_TTC penalty 9.885142027037572\n",
      "Step 34: action=0 reward=-108.85142027037573 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 8 with cumulated_reward -2829.275828359952\n",
      "====> Start episode 9\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC 0.4566668463225657 smallest_TTC penalty 9.543333153677434\n",
      "Step 27: action=0 reward=-105.43333153677435 done=False\n",
      "PENALTY smallest_TTC 0.12047239514086962 smallest_TTC penalty 9.879527604859131\n",
      "Step 28: action=0 reward=-108.79527604859132 done=False\n",
      "PENALTY smallest_TTC 0.5278895708925565 smallest_TTC penalty 9.472110429107444\n",
      "Step 29: action=0 reward=-104.72110429107444 done=False\n",
      "PENALTY smallest_TTC 0.3840458897949132 smallest_TTC penalty 9.615954110205086\n",
      "Step 30: action=0 reward=-106.15954110205087 done=False\n",
      "PENALTY smallest_TTC 0.22874269274445433 smallest_TTC penalty 9.771257307255546\n",
      "Step 31: action=0 reward=-107.71257307255546 done=False\n",
      "PENALTY smallest_TTC 0.06542590139106161 smallest_TTC penalty 9.93457409860894\n",
      "Step 32: action=0 reward=-109.3457409860894 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 9 with cumulated_reward -642.1675670371358\n",
      "====> Start episode 10\n",
      "PENALTY smallest_TTC 6.100205035191854 smallest_TTC penalty 3.8997949648081462\n",
      "Step 0: action=0 reward=-48.99794964808146 done=False\n",
      "PENALTY smallest_TTC 5.864483469783781 smallest_TTC penalty 4.135516530216219\n",
      "Step 1: action=0 reward=-51.35516530216219 done=False\n",
      "PENALTY smallest_TTC 5.637093095152004 smallest_TTC penalty 4.362906904847996\n",
      "Step 2: action=0 reward=-53.62906904847996 done=False\n",
      "PENALTY smallest_TTC 5.414906486214568 smallest_TTC penalty 4.585093513785432\n",
      "Step 3: action=0 reward=-55.850935137854314 done=False\n",
      "PENALTY smallest_TTC 5.196399105560097 smallest_TTC penalty 4.803600894439903\n",
      "Step 4: action=0 reward=-58.03600894439903 done=False\n",
      "PENALTY smallest_TTC 4.980689905091919 smallest_TTC penalty 5.019310094908081\n",
      "Step 5: action=0 reward=-60.193100949080815 done=False\n",
      "PENALTY smallest_TTC 4.767214440648966 smallest_TTC penalty 5.232785559351034\n",
      "Step 6: action=0 reward=-62.327855593510336 done=False\n",
      "PENALTY smallest_TTC 4.5555849822903856 smallest_TTC penalty 5.4444150177096144\n",
      "Step 7: action=0 reward=-64.44415017709615 done=False\n",
      "PENALTY smallest_TTC 4.3455213958977925 smallest_TTC penalty 5.6544786041022075\n",
      "Step 8: action=0 reward=-66.54478604102208 done=False\n",
      "PENALTY smallest_TTC 4.136813386697596 smallest_TTC penalty 5.863186613302404\n",
      "Step 9: action=0 reward=-68.63186613302403 done=False\n",
      "PENALTY smallest_TTC 3.9292982776238565 smallest_TTC penalty 6.0707017223761435\n",
      "Step 10: action=0 reward=-70.70701722376143 done=False\n",
      "PENALTY smallest_TTC 3.7228471524944946 smallest_TTC penalty 6.277152847505505\n",
      "Step 11: action=0 reward=-72.77152847505505 done=False\n",
      "PENALTY smallest_TTC 3.5173558065677257 smallest_TTC penalty 6.482644193432274\n",
      "Step 12: action=0 reward=-74.82644193432274 done=False\n",
      "PENALTY smallest_TTC 3.312738608725503 smallest_TTC penalty 6.687261391274497\n",
      "Step 13: action=0 reward=-76.87261391274497 done=False\n",
      "PENALTY smallest_TTC 3.1089242049340933 smallest_TTC penalty 6.891075795065907\n",
      "Step 14: action=0 reward=-78.91075795065908 done=False\n",
      "PENALTY smallest_TTC 2.9058524290656007 smallest_TTC penalty 7.0941475709344\n",
      "Step 15: action=0 reward=-80.94147570934399 done=False\n",
      "PENALTY smallest_TTC 2.703472030220081 smallest_TTC penalty 7.296527969779919\n",
      "Step 16: action=0 reward=-82.96527969779919 done=False\n",
      "PENALTY smallest_TTC 2.5017389671173778 smallest_TTC penalty 7.498261032882622\n",
      "Step 17: action=0 reward=-84.98261032882623 done=False\n",
      "PENALTY smallest_TTC 2.3006151055755617 smallest_TTC penalty 7.699384894424439\n",
      "Step 18: action=0 reward=-86.99384894424439 done=False\n",
      "PENALTY smallest_TTC 2.1000672084294916 smallest_TTC penalty 7.899932791570508\n",
      "Step 19: action=0 reward=-88.99932791570508 done=False\n",
      "PENALTY smallest_TTC 1.9000661415010511 smallest_TTC penalty 8.099933858498948\n",
      "Step 20: action=0 reward=-90.99933858498949 done=False\n",
      "PENALTY smallest_TTC 1.7005862417995108 smallest_TTC penalty 8.299413758200489\n",
      "Step 21: action=0 reward=-92.99413758200488 done=False\n",
      "PENALTY smallest_TTC 1.50160480933441 smallest_TTC penalty 8.49839519066559\n",
      "Step 22: action=0 reward=-94.9839519066559 done=False\n",
      "PENALTY smallest_TTC 1.303101694375555 smallest_TTC penalty 8.696898305624446\n",
      "Step 23: action=0 reward=-96.96898305624445 done=False\n",
      "PENALTY smallest_TTC 1.1050589593123636 smallest_TTC penalty 8.894941040687636\n",
      "Step 24: action=0 reward=-98.94941040687635 done=False\n",
      "PENALTY smallest_TTC 0.9074605994733593 smallest_TTC penalty 9.09253940052664\n",
      "Step 25: action=0 reward=-100.9253940052664 done=False\n",
      "PENALTY smallest_TTC 0.7102923110303317 smallest_TTC penalty 9.289707688969669\n",
      "Step 26: action=0 reward=-102.89707688969669 done=False\n",
      "PENALTY smallest_TTC 0.513541296869302 smallest_TTC penalty 9.486458703130698\n",
      "Step 27: action=0 reward=-104.86458703130697 done=False\n",
      "PENALTY smallest_TTC 0.3171961033568648 smallest_TTC penalty 9.682803896643135\n",
      "Step 28: action=0 reward=-106.82803896643135 done=False\n",
      "PENALTY smallest_TTC 0.12124648246726576 smallest_TTC penalty 9.878753517532735\n",
      "Step 29: action=0 reward=-108.78753517532735 done=False\n",
      "PENALTY smallest_TTC 1.1625520192151257 smallest_TTC penalty 8.837447980784875\n",
      "Step 30: action=0 reward=-98.37447980784874 done=False\n",
      "PENALTY smallest_TTC 0.9753840422078914 smallest_TTC penalty 9.024615957792108\n",
      "Step 31: action=0 reward=-10100.24615957792 done=True\n",
      "End of episode 10 with cumulated_reward -12586.800882057742\n",
      "====> Start episode 11\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 11 with cumulated_reward 0\n",
      "====> Start episode 12\n",
      "PENALTY smallest_TTC 1.6906465427577613 smallest_TTC penalty 8.309353457242239\n",
      "Step 0: action=0 reward=-93.09353457242239 done=False\n",
      "PENALTY smallest_TTC 1.4804014798342375 smallest_TTC penalty 8.519598520165763\n",
      "Step 1: action=0 reward=-95.19598520165763 done=False\n",
      "PENALTY smallest_TTC 1.270223292889917 smallest_TTC penalty 8.729776707110084\n",
      "Step 2: action=0 reward=-97.29776707110084 done=False\n",
      "PENALTY smallest_TTC 1.0601132588103208 smallest_TTC penalty 8.93988674118968\n",
      "Step 3: action=0 reward=-99.3988674118968 done=False\n",
      "PENALTY smallest_TTC 0.8500727234950796 smallest_TTC penalty 9.14992727650492\n",
      "Step 4: action=0 reward=-101.4992727650492 done=False\n",
      "PENALTY smallest_TTC 0.6401031065454668 smallest_TTC penalty 9.359896893454533\n",
      "Step 5: action=0 reward=-103.59896893454533 done=False\n",
      "PENALTY smallest_TTC 0.43020590639279704 smallest_TTC penalty 9.569794093607204\n",
      "Step 6: action=0 reward=-105.69794093607203 done=False\n",
      "PENALTY smallest_TTC 0.22038270591888984 smallest_TTC penalty 9.77961729408111\n",
      "Step 7: action=0 reward=-107.79617294081109 done=False\n",
      "PENALTY smallest_TTC 0.010635178627032527 smallest_TTC penalty 9.989364821372968\n",
      "Step 8: action=0 reward=-109.89364821372968 done=False\n",
      "PENALTY smallest_TTC 0.5501661262891504 smallest_TTC penalty 9.44983387371085\n",
      "Step 9: action=0 reward=-104.4983387371085 done=False\n",
      "PENALTY smallest_TTC 0.33441752306960687 smallest_TTC penalty 9.665582476930393\n",
      "Step 10: action=0 reward=-10106.655824769305 done=True\n",
      "End of episode 12 with cumulated_reward -11124.626321553698\n",
      "====> Start episode 13\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 0: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 1: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 2: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 3: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 4: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 5: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 6: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 7: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 8: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 9: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 10: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 13 with cumulated_reward 0\n",
      "====> Start episode 14\n",
      "PENALTY smallest_TTC 6.516509149976135 smallest_TTC penalty 3.4834908500238653\n",
      "Step 0: action=0 reward=-44.834908500238654 done=False\n",
      "PENALTY smallest_TTC 6.310008127419134 smallest_TTC penalty 3.6899918725808663\n",
      "Step 1: action=0 reward=-46.89991872580866 done=False\n",
      "PENALTY smallest_TTC 6.104937487937815 smallest_TTC penalty 3.895062512062185\n",
      "Step 2: action=0 reward=-48.95062512062185 done=False\n",
      "PENALTY smallest_TTC 5.901516040981843 smallest_TTC penalty 4.098483959018157\n",
      "Step 3: action=0 reward=-50.98483959018157 done=False\n",
      "PENALTY smallest_TTC 5.70003296118202 smallest_TTC penalty 4.29996703881798\n",
      "Step 4: action=0 reward=-52.999670388179794 done=False\n",
      "PENALTY smallest_TTC 5.500884467519457 smallest_TTC penalty 4.499115532480543\n",
      "Step 5: action=0 reward=-54.99115532480543 done=False\n",
      "PENALTY smallest_TTC 5.304639656413272 smallest_TTC penalty 4.695360343586728\n",
      "Step 6: action=0 reward=-56.95360343586728 done=False\n",
      "PENALTY smallest_TTC 5.11217017342762 smallest_TTC penalty 4.88782982657238\n",
      "Step 7: action=0 reward=-58.8782982657238 done=False\n",
      "PENALTY smallest_TTC 4.924941321173248 smallest_TTC penalty 5.075058678826752\n",
      "Step 8: action=0 reward=-60.750586788267526 done=False\n",
      "PENALTY smallest_TTC 4.745811232647882 smallest_TTC penalty 5.254188767352118\n",
      "Step 9: action=0 reward=-62.54188767352118 done=False\n",
      "PENALTY smallest_TTC 4.582201800633424 smallest_TTC penalty 5.417798199366576\n",
      "Step 10: action=0 reward=-64.17798199366575 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 11: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 12: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 13: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 14: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 15: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 16: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 17: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 18: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 19: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 20: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 21: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 22: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 23: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 24: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 25: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 26: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 27: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 28: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 29: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 30: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 31: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 32: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 33: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 34: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 35: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 36: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 37: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 38: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 39: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 40: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 41: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 42: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 43: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 44: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 45: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 46: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 47: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 48: action=0 reward=0 done=False\n",
      "PENALTY smallest_TTC inf smallest_TTC penalty 0.0\n",
      "Step 49: action=0 reward=0 done=True\n",
      "End of episode 14 with cumulated_reward -602.9634758068814\n",
      "METRICS: REWARD AvgCumulatedReward = -768.4608211758252\n",
      "METRICS: SAFETY %collisions = 0.33333333333333337, COMFORT MeanHardBrake = 0.0, EFFICIENCY MeanStepsToGoal = 49.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_episodes = 15\n",
    "max_steps = 120\n",
    "\n",
    "# METRICS\n",
    "metric_success = 0 # EFFICIENCY\n",
    "metric_steps_to_goal = [] # SAFETY\n",
    "metric_hardbrake = [] # COMFORT\n",
    "metric_cumulated_reward = []\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    print(\"====> Start episode {}\".format(episode))\n",
    "    env.reset()\n",
    "    cumulated_reward = 0\n",
    "    images = []\n",
    "    \n",
    "    hardbrake = 0    \n",
    "    for n in range(max_steps):\n",
    "        action = 0\n",
    "        #action = np.random.randint(low=-2,high=3) \n",
    "        if action <= -2:\n",
    "            hardbrake += 1\n",
    "        state, reward, done, info = env.step(action)\n",
    "        env.penalty(state)\n",
    "        cumulated_reward += reward\n",
    "        print(\"Step {}: action={} reward={} done={}\".format(n, action, reward, done)) # PHW DEBUG\n",
    "        img = env.render()\n",
    "        images.append(img)\n",
    "        if done is True:\n",
    "            if info == \"success\":\n",
    "                metric_success += 1\n",
    "                metric_steps_to_goal.append(n)\n",
    "                metric_hardbrake.append(hardbrake)\n",
    "                metric_cumulated_reward.append(cumulated_reward)\n",
    "            print(\"End of episode {} with cumulated_reward {}\".format(episode, cumulated_reward))\n",
    "            break\n",
    "\n",
    "print(\"METRICS: REWARD AvgCumulatedReward = {}\".format(np.mean(metric_cumulated_reward)))\n",
    "print(\"METRICS: SAFETY %collisions = {}, COMFORT MeanHardBrake = {}, EFFICIENCY MeanStepsToGoal = {}\".format(1-metric_success/max_episodes, np.mean(metric_hardbrake), np.mean(metric_steps_to_goal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "10\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(metric_hardbrake)\n",
    "print(metric_success)\n",
    "print(metric_steps_to_goal)\n",
    "print(max_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHLxJREFUeJzt3V+odWd9J/Dvb0zbi7agkkwIMU6k\n5Ca9mFRerNAypMi06k3sjehFDSKkFxFa6MWkvbGX3rQFYSqkNBih1Qm0Yi5CWwkdZC5sfTOIGh3H\nYBUTYvJ2HKxU6BD7zMW7T92e7P07+8/a/875fOBwzl57/Xn2evY+fNdvPWvtGmMEAIDF/t2hGwAA\ncMyEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAACNnYWlqnp7VX2tqp6rqkd2tR0AgF2qXdyUsqpe\nk+R/J/nPSZ5P8vkk7x1jfGXyjQEA7NAtO1rvW5I8N8b4RpJU1SeTPJBkYVi69dZbx913372jpgAA\nvNozzzzzj2OM2y6ab1dh6c4k3557/HySX5yfoaoeSvJQkrzxjW/M9evXd9QUAIBXq6pvrTLfwQZ4\njzEeHWNcG2Ncu+22C0MdAMBB7CosvZDkrrnHb5hNAwA4KbsKS59Pck9VvamqfjLJe5I8uaNtAQDs\nzE7GLI0xXqmqDyb56ySvSfLYGOPZXWwLAGCXdjXAO2OMp5I8tav1AwDsgzt4AwA0hCUAgIawBADQ\nEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1h\nCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYA\nABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCg\nISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrC\nEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwB\nADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCElwR\nVTd/AFiPsAQA0Ljl0A0AdmdRJels2hj7bQvAqVJZAgBoqCzBJbTK2CQVJoDVqCwBADRUluASOqsW\ndRUmFSWA1agsAQA0VJbgEpuvHhmjBLAZlSUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAh\nLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgccs2C1fVN5N8P8kPk7wyxrhWVa9P\n8t+S3J3km0nePcb4v9s1EwDgMKaoLP3KGOO+Mca12eNHkjw9xrgnydOzxwAAJ2kXp+EeSPL47O/H\nk7xrB9sAANiLbcPSSPI3VfVMVT00m3b7GOPF2d/fSXL7ogWr6qGqul5V12/cuLFlMwAAdmOrMUtJ\nfnmM8UJV/fskn6mq/zX/5BhjVNVYtOAY49EkjybJtWvXFs4DAHBoW1WWxhgvzH6/nORTSd6S5KWq\nuiNJZr9f3raRAACHsnFYqqqfrqqfPfs7ya8m+XKSJ5M8OJvtwSSf3raRAACHss1puNuTfKqqztbz\n52OMv6qqzyd5oqo+kORbSd69fTMBAA5j47A0xvhGkv+4YPr/SfK2bRoFAHAs3MEbAKAhLAEANIQl\nAICGsAQA0Nj2ppTAJXbzYtflxtztZNeZd9XtrrPMJva1HeC0qSwBADRUluASOF/VmaqKs2w9XRXp\n/DIXVZwAjp3KEgBAQ2UJLoGzas5ZFWeVsTibVHw2qUJNbYpK1SrVL+OYgDMqSwAADZUluESWVZjm\nbTO+aR1TXGnWVXyWrX9+mVXHTy1qoyvlgDMqSwAADZUluITOV1+6eVaxTpVFRQa4bFSWAAAawhIA\nQMNpOLjEFn0dya4HdC97vMl2u4HXAPuisgQA0FBZgitim4rSKstOWbHq1nXRdtZZdpvtAFeHyhIA\nQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0\nhCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENY\nAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUA\ngIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBo\nCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIaw\nBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsA\nAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEDjwrBUVY9V1ctV9eW5aa+vqs9U1ddnv183m15V\n9ZGqeq6qvlhVb95l4wEAdm2VytLHkrz93LRHkjw9xrgnydOzx0nyjiT3zH4eSvLRaZoJAHAYF4al\nMcZnk3z33OQHkjw++/vxJO+am/7xcdPnkry2qu6YqrEAAPu26Zil28cYL87+/k6S22d/35nk23Pz\nPT+bBgBwkrYe4D3GGEnGustV1UNVdb2qrt+4cWPbZgAA7MSmYemls9Nrs98vz6a/kOSuufneMJv2\nKmOMR8cY18YY12677bYNmwEAsFubhqUnkzw4+/vBJJ+em/6+2VVxb03yvbnTdQAAJ+eWi2aoqk8k\nuT/JrVX1fJIPJflwkieq6gNJvpXk3bPZn0ryziTPJflBkvfvoM0AAHtzYVgaY7x3yVNvWzDvSPLw\nto0CADgW7uANANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBA\nQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBo3HLoBrAbVXXhPGOMleY9\nm2+d7a6zzCbm27zrbQFwtaksAQA0VJYuqfPVlq7is6wys0p1CgAuO5UlAICGytIVs8pYn12NO5qi\nUrWoTefXawwTAFNSWQIAaKgsXTZnVZZz1ZWVrnybcIzSou2cb0NXJVo25mqRdcZnAcC6VJYAABoq\nS5fFucrLJtWVszWoxwDAj6gsAQA0hCUAgIbTcKdshQHZW12uv2Sw+CpWucQfAE6ByhIAQENl6ZTN\nV2/O35hxo9WdW2qDSlA3oHyVwebL5jk/fdvtwCmpnP98r/8eX+fLtVdZZtXP2T6/9NptQ9gVlSUA\ngIbK0mVxdiR10Tij+SPFZUeNXYXJERvsxflqUrJZRenflm2qRqve2NW4Q64qlSUAgIbK0mVzUeWn\ne/7sqNHRIxzM1BWllbZ5oEqSL9fmVKgsAQA0VJZYfewSsDNTXPHWrff8+uarLcsqPFNXmpZVfHy5\nNsdOZQkAoKGydJWdPzJz1AVHY9HYpWUWVaHOL6+6AptTWQIAaAhLAAANp+GuMuV4OBpnp9KWDche\n5GzedU7ZrfO1J1PfOsBNLjlVKksAAA2VJYAjNF8tWlZl6qpPr6o2jYuXedX6J6g+7+vLtdedF9ah\nsgQA0FBZAjgi58cuTbWeXX9lClxmKksAAA2VJYAjNFUlSEUJtqeyBADQEJYAABrCEgBAQ1gCAGgI\nSwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAE\nANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAA\nDWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQ\nlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQuDAsVdVjVfVyVX15btrvV9ULVfWF\n2c8755773ap6rqq+VlW/tquGAwDswyqVpY8lefuC6X80xrhv9vNUklTVvUnek+TnZ8v8cVW9ZqrG\nAgDs24VhaYzx2STfXXF9DyT55BjjX8YY/5DkuSRv2aJ9AAAHtc2YpQ9W1Rdnp+leN5t2Z5Jvz83z\n/Gzaq1TVQ1V1vaqu37hxY4tmAADszqZh6aNJfi7JfUleTPIH665gjPHoGOPaGOPabbfdtmEzAAB2\na6OwNMZ4aYzxwzHGvyb5k/zoVNsLSe6am/UNs2kAACdpo7BUVXfMPfz1JGdXyj2Z5D1V9VNV9aYk\n9yT5++2aCABwOLdcNENVfSLJ/Ulurarnk3woyf1VdV+SkeSbSX4zScYYz1bVE0m+kuSVJA+PMX64\nm6YDAOxejTEO3YZcu3ZtXL9+/dDNAACukKp6Zoxx7aL53MEbAKAhLAEANIQlAICGsAQA0BCWAAAa\nwhIAQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEs\nAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIA\nQENYAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0\nhCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENY\nAgBoCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUA\ngIawBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBo\nCEsAAA1hCQCgISwBADSEJQCAhrAEANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIaw\nBADQEJYAABrCEgBAQ1gCAGgISwAADWEJAKAhLAEANIQlAICGsAQA0LgwLFXVXVX1t1X1lap6tqp+\nazb99VX1mar6+uz362bTq6o+UlXPVdUXq+rNu34RAAC7skpl6ZUkvzPGuDfJW5M8XFX3JnkkydNj\njHuSPD17nCTvSHLP7OehJB+dvNUAAHtyy0UzjDFeTPLi7O/vV9VXk9yZ5IEk989mezzJf0/yX2bT\nPz7GGEk+V1Wvrao7ZuvhQKrqwnludtnVsGx/rLMPun16fj1TbG9bF70HdtWW89ud30733LrrnXId\ni9azzrybbnPTde7KNv0zxfa6bW/TH9v+Pzxb/hj6iP1Ya8xSVd2d5BeS/F2S2+cC0HeS3D77+84k\n355b7PnZtPPreqiqrlfV9Rs3bqzZbACA/biwsnSmqn4myV8k+e0xxj/NJ/MxxqiqtSL2GOPRJI8m\nybVr18TzPXG09OOWHa1usp8WHa2uM+++HKot3T7d5j3XvZ5l6+36+fz+2FUfXtS2Qzr0/4KuX84/\nt868q24LzlupslRVP5GbQenPxhh/OZv8UlXdMXv+jiQvz6a/kOSuucXfMJsGAHByVrkarpL8aZKv\njjH+cO6pJ5M8OPv7wSSfnpv+vtlVcW9N8j3jlQCAU7XKabhfSvIbSb5UVV+YTfu9JB9O8kRVfSDJ\nt5K8e/bcU0nemeS5JD9I8v5JW8xWphqkusr6VtUN+F13+c4qp2eugin6bJN1dMsc+rTPIuu8xk3a\nP+XptqnWtclp6V1Y9HqmPv3WbWvROo7h9CiHs8rVcP8jybJ3ydsWzD+SPLxluwAAjsLKA7y5HBZV\ncaY4apxqQPSy9a0yIPeYqhLH7Gw/7Xq/rbKdY+y78+2+aL5V5r1o+fl1TL0v1umHZcuuY4p9sev3\nyir/r5Y97p47pvcx0/J1JwAADZWlK2yXFYZjP79/jBWNfZui/9epUpyK8/tj2es5xjFwi6pd++6P\nQ45v2sX4xVOpiLJbKksAAA2VJVYeo9FZ5dz9oSsOqxx1r3IUuc7+mmLfnm/HovVPYZ02Tvm6tnVK\nfbjr7azyHjmGPrtI9zo2GUO0yXgtmKeyBADQUFm6Io7htv/btGHqr8pYZ5lN2rTNvLta3xSvY5Nl\n9/U1J5vMe4g+3GSMzJSO4X/BNtud4r2/7eszVunqUVkCAGioLMGJcDQLcBgqSwAADWEJAKAhLAEA\nNIQlAICGsAQA0BCWAAAabh1wyU19K/+LvnJgqsvb1/miyote4yZfbXGVHeILYlftw31a5WtU9rWd\nKfZPt45VvxLl2D8fvuCWXVFZAgBoqCxdct0R47Kjr1W+dHLZerc9stukEnbR61hnGQ7rmL70ddfv\nkYs+S4u2P8X+Wedzvcn/D7iMVJYAABoqS0xim6PMRUer21QUVqluTTEmY5XK1TpjTS5q0zpjrqYY\nn7LuPLuoNCx6PVP10arbPKYxb1NU2hatY9Xq7Cavb9vq1ybLr9N3U/zPUWW7/FSWAAAaKksczKIj\nufPTpry6ZZNK065tWjHZ5uqli6oF6+yLUzmivmhc0LaveYoK1ibb3qQqeMgxS8uqdsvaus46F613\nijFdxj6SqCwBALSEJQCAhtNwTGKTgaCrnBbbZDDvKoNVpyyfTzWoetkphENdwr7Ivi8lv8w3GZzy\nVNQqTn0fTnnKbte3XODyUVkCAGioLLGWfX3dyXlTf/XElOvb5LLk7ih1lX07RfvPt22qWwhsc7Q9\nVRtOyTp9edFr724LsM0l+Ku0bVfW+QydWValneKWJFxNKksAAA2VpStm27FE68yzjYsuYV5lmXWf\nX9c2l/rven3d87vYt9uael+uu45VvlpknX26SRummHeqNu5iTN8q69+2/Zusd4plufxUlgAAGipL\nwKQciQOXjcoSAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIZbB1wRq9yp/+yK77N5j/EK8FXatuy1\n7vr1zG/3on15Cvs4Oe52H6qfj1nXd/vc9rz5dlz0f2iVNnfruGj5Y3r/clpUlgAAGipLV8yiI6pT\n+H7IVdp4URVn167C0eoxvMZD9zM/bpP+2KTvtqkKeW+wLZUlAICGytIVs+gIa9mR2qIjuVXHHGwz\nrmDT9V5knfEcq4w/Wva4W98qR9RTHjmv03fdejd5zefbMPV7YplN+/m8i9q9aN+usp9WXe82bTuE\n821ZtO+n6OdNKlbHuL84LSpLAAANlaUrohurtKzqMdXR/qGvqDrEUeWqVxZ2/bLOlUHbjBdZts5V\n27Bs3l1Vuy7a/ibrnGos3/lluursFGN8phq3NcU+2+Rzvs57fZsr5Zb1y6rrBZUlAICGytIVsegI\nbsoj8XWuZtm3TSpZ64xHOQZTXCl0TK9nE7t+HVNXKKdo71Sv+VD3ZFpnu1OM+7ss73X2T2UJAKAh\nLAEANJyGu2K2vdR72XPrfP3IqZwmmdKuyv/nX/PUl5tvMtj8/Pamtq9+3mbfrvMZ2uY0+DbrmMo6\n/xO6gdbL1jXlxQuwKZUlAICGytIVsc2NILdd35RHe1NdYrzNNte5DcA6867y3BTLXDTvOm3bdrvb\n9NUU/Tz1+2md/bNNP6wzz75M2d5d3dDymPYXp0VlCQCgISwBADSEJQCAhjFL7ISxAQBcFipLAAAN\nYYlLo+o477F0Gexr3+pD4BgJSwAADWOW+DfH9CWT29w5el/W2e6h9ml3J+Tz86xyx+V9Oab34r5N\ntc9PYd9d5X7mtKgsAQA0hCUAgIbTcJz8gNp9l/A3OXVwqqcb9t3eU9s/u7DKl1LbT7BfKksAAA1h\nCfbIpfEAp0dYAgBoGLN0hS0b/7DJZfvL1rHIKmMylj0+5HiObda/yTKrVKD2NXZlyls5TN2HU+yn\nRbdY2OZ1HLOp3ldT9POyx1PdMuRU+4jjo7IEANBQWWJS297g8PxR/VU8MlzltR/juKeL2j11m3e1\nn/b9OvZliv21yk1OV9neNp/zU/18cNpUlgAAGipLTGKKcU5X3Snev2mdSsM2yyxaflf76bK9L0/x\nfbXIZXkdnCaVJQCAhrAEANBwGu6KWeUUyCaDL9eZx+DL7R3jvjzGS+2PcT8dyq4G2J93ts93fQuP\njtNuTE1lCQCgobJ0hTnaZlvrDOg32Pawptjvm9wscqr+9l7jkFSWAAAaKktXxDZHWtte6n1ZTHHD\nzKt4xHt+v3k/XW6HHCe27L3mfca2VJYAABoqS7AHl/UId50qkSvTTscqX5C97/fyJlfneq8xFZUl\nAICGyhJr2VeF5KIjw0NWaDY5at3V0fAxVapWbfe2bT71/bRvu9pfU1RtVmlbV91adf2wLZUlAICG\nytIVsc0RVrfsJutdZ5ldzTuFXW1vyvVOfff1TZZdx6H6+5jfZ1Nte1/3WdrVelWJOCSVJQCAhrAE\nANAQlgAAGsISAEBDWAIAaAhLAAANYQkAoCEsAQA0hCUAgIawBADQEJYAABrCEgBAQ1gCAGgISwAA\nDWEJAKAhLAEANIQlAICGsAQA0BCWAAAaNcY4dBtSVTeS/HOSfzx0W1jLrdFnp0afnRb9dXr02Wn5\nD2OM2y6a6SjCUpJU1fUxxrVDt4PV6bPTo89Oi/46PfrscnIaDgCgISwBADSOKSw9eugGsDZ9dnr0\n2WnRX6dHn11CRzNmCQDgGB1TZQkA4OgcRViqqrdX1deq6rmqeuTQ7WGxqvpmVX2pqr5QVddn015f\nVZ+pqq/Pfr/u0O28qqrqsap6uaq+PDdtYf/UTR+Zfea+WFVvPlzLr64lffb7VfXC7HP2hap659xz\nvzvrs69V1a8dptVXV1XdVVV/W1Vfqapnq+q3ZtN9zi65g4elqnpNkv+a5B1J7k3y3qq697CtovEr\nY4z75i6NfSTJ02OMe5I8PXvMYXwsydvPTVvWP+9Ics/s56EkH91TG/lxH8ur+yxJ/mj2ObtvjPFU\nksz+L74nyc/Plvnj2f9P9ueVJL8zxrg3yVuTPDzrF5+zS+7gYSnJW5I8N8b4xhjj/yX5ZJIHDtwm\nVvdAksdnfz+e5F0HbMuVNsb4bJLvnpu8rH8eSPLxcdPnkry2qu7YT0s5s6TPlnkgySfHGP8yxviH\nJM/l5v9P9mSM8eIY43/O/v5+kq8muTM+Z5feMYSlO5N8e+7x87NpHJ+R5G+q6pmqemg27fYxxouz\nv7+T5PbDNI0llvWPz91x++DstM1jc6e29dkRqaq7k/xCkr+Lz9mldwxhidPxy2OMN+dmafnhqvpP\n80+Om5dWurzySOmfk/HRJD+X5L4kLyb5g8M2h/Oq6meS/EWS3x5j/NP8cz5nl9MxhKUXktw19/gN\ns2kcmTHGC7PfLyf5VG6eAnjprKw8+/3y4VrIAsv6x+fuSI0xXhpj/HCM8a9J/iQ/OtWmz45AVf1E\nbgalPxtj/OVsss/ZJXcMYenzSe6pqjdV1U/m5gDGJw/cJs6pqp+uqp89+zvJryb5cm721YOz2R5M\n8unDtJAllvXPk0neN7ta561Jvjd3GoEDOjem5ddz83OW3Oyz91TVT1XVm3Jz0PDf77t9V1lVVZI/\nTfLVMcYfzj3lc3bJ3XLoBowxXqmqDyb56ySvSfLYGOPZAzeLV7s9yadu/q/ILUn+fIzxV1X1+SRP\nVNUHknwrybsP2MYrrao+keT+JLdW1fNJPpTkw1ncP08leWduDhL+QZL3773BLOuz+6vqvtw8lfPN\nJL+ZJGOMZ6vqiSRfyc2rsh4eY/zwEO2+wn4pyW8k+VJVfWE27ffic3bpuYM3AEDjGE7DAQAcLWEJ\nAKAhLAEANIQlAICGsAQA0BCWAAAawhIAQENYAgBo/H8zj9uaFgF3swAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(images[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('img/visu.gif', images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_images = resize_images(images, f=2)\n",
    "imageio.mimsave('img/visu2.gif', big_images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu2.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
