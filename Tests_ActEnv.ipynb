{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-14 10:59:52,175] Making new env: Act10cv-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT (Anti Collision Tests) with 10 cars using cv driver model\n",
      "SEED 10971597703429474133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philippew/anaconda3/envs/py36/lib/python3.6/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# to install gym_act:\n",
    "# git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# cd gym-act\n",
    "# pip install -e .\n",
    "import gym_act\n",
    "\n",
    "# source code is in https://github.com/PhilippeW83440/CS234_Project/blob/master/gym-act/gym_act/envs/act_env.py\n",
    "# or if you did: git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# in CS234_Project/gym-act/gym_act/envs/act_env.py\n",
    "\n",
    "# By default: ACT with 2 cars with CV (Constant Velocity) driver model\n",
    "#env = gym.make(\"Act-v0\")\n",
    "\n",
    "# ACT with 10 cars with CV (Constant Velocity) driver model\n",
    "env = gym.make(\"Act10cv-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -1\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, reward, done, info = env.step(action)\n",
    "print(\"reward {}\".format(reward))\n",
    "img = env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def  resize_images(images, f=3):\n",
    "    big_images = []\n",
    "    for img in images:\n",
    "        big_images.append(cv2.resize(img, None, fx=f, fy=f))\n",
    "    return big_images\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Start episode 0\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1001 done=True\n",
      "End of episode 0 with cumulated_reward -1018\n",
      "====> Start episode 1\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1001 done=True\n",
      "End of episode 1 with cumulated_reward -1016\n",
      "====> Start episode 2\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1001 done=True\n",
      "End of episode 2 with cumulated_reward -1017\n",
      "====> Start episode 3\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1001 done=True\n",
      "End of episode 3 with cumulated_reward -1019\n",
      "====> Start episode 4\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1 done=False\n",
      "Step 19: action=0 reward=-1 done=False\n",
      "Step 20: action=0 reward=-1 done=False\n",
      "Step 21: action=0 reward=-1001 done=True\n",
      "End of episode 4 with cumulated_reward -1022\n",
      "====> Start episode 5\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1 done=False\n",
      "Step 19: action=0 reward=-1 done=False\n",
      "Step 20: action=0 reward=-1001 done=True\n",
      "End of episode 5 with cumulated_reward -1021\n",
      "====> Start episode 6\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1001 done=True\n",
      "End of episode 6 with cumulated_reward -1018\n",
      "====> Start episode 7\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1001 done=True\n",
      "End of episode 7 with cumulated_reward -1019\n",
      "====> Start episode 8\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1001 done=True\n",
      "End of episode 8 with cumulated_reward -1016\n",
      "====> Start episode 9\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1 done=False\n",
      "Step 19: action=0 reward=-1 done=False\n",
      "Step 20: action=0 reward=-1 done=False\n",
      "Step 21: action=0 reward=-1 done=False\n",
      "Step 22: action=0 reward=-1 done=False\n",
      "Step 23: action=0 reward=-1 done=False\n",
      "Step 24: action=0 reward=-1 done=False\n",
      "Step 25: action=0 reward=-1 done=False\n",
      "Step 26: action=0 reward=-1 done=False\n",
      "Step 27: action=0 reward=-1 done=False\n",
      "Step 28: action=0 reward=-1 done=False\n",
      "Step 29: action=0 reward=-1 done=False\n",
      "Step 30: action=0 reward=-1 done=False\n",
      "Step 31: action=0 reward=-1 done=False\n",
      "Step 32: action=0 reward=-1 done=False\n",
      "Step 33: action=0 reward=-1 done=False\n",
      "Step 34: action=0 reward=-1 done=False\n",
      "Step 35: action=0 reward=-1 done=False\n",
      "Step 36: action=0 reward=-1 done=False\n",
      "Step 37: action=0 reward=-1 done=False\n",
      "Step 38: action=0 reward=-1 done=False\n",
      "Step 39: action=0 reward=-1 done=False\n",
      "Step 40: action=0 reward=-1 done=False\n",
      "Step 41: action=0 reward=-1 done=False\n",
      "Step 42: action=0 reward=-1 done=False\n",
      "Step 43: action=0 reward=-1 done=False\n",
      "Step 44: action=0 reward=-1 done=False\n",
      "Step 45: action=0 reward=-1 done=False\n",
      "Step 46: action=0 reward=-1 done=False\n",
      "Step 47: action=0 reward=-1 done=False\n",
      "Step 48: action=0 reward=-1 done=False\n",
      "Step 49: action=0 reward=999 done=True\n",
      "End of episode 9 with cumulated_reward 950\n",
      "====> Start episode 10\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1 done=False\n",
      "Step 16: action=0 reward=-1 done=False\n",
      "Step 17: action=0 reward=-1 done=False\n",
      "Step 18: action=0 reward=-1001 done=True\n",
      "End of episode 10 with cumulated_reward -1019\n",
      "====> Start episode 11\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1001 done=True\n",
      "End of episode 11 with cumulated_reward -1012\n",
      "====> Start episode 12\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1001 done=True\n",
      "End of episode 12 with cumulated_reward -1016\n",
      "====> Start episode 13\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1001 done=True\n",
      "End of episode 13 with cumulated_reward -1016\n",
      "====> Start episode 14\n",
      "Step 0: action=0 reward=-1 done=False\n",
      "Step 1: action=0 reward=-1 done=False\n",
      "Step 2: action=0 reward=-1 done=False\n",
      "Step 3: action=0 reward=-1 done=False\n",
      "Step 4: action=0 reward=-1 done=False\n",
      "Step 5: action=0 reward=-1 done=False\n",
      "Step 6: action=0 reward=-1 done=False\n",
      "Step 7: action=0 reward=-1 done=False\n",
      "Step 8: action=0 reward=-1 done=False\n",
      "Step 9: action=0 reward=-1 done=False\n",
      "Step 10: action=0 reward=-1 done=False\n",
      "Step 11: action=0 reward=-1 done=False\n",
      "Step 12: action=0 reward=-1 done=False\n",
      "Step 13: action=0 reward=-1 done=False\n",
      "Step 14: action=0 reward=-1 done=False\n",
      "Step 15: action=0 reward=-1001 done=True\n",
      "End of episode 14 with cumulated_reward -1016\n",
      "METRICS: REWARD AvgCumulatedReward = 950.0\n",
      "METRICS: SAFETY %collisions = 0.9333333333333333, COMFORT MeanHardBrake = 0.0, EFFICIENCY MeanStepsToGoal = 49.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_episodes = 15\n",
    "max_steps = 120\n",
    "\n",
    "# METRICS\n",
    "metric_success = 0 # EFFICIENCY\n",
    "metric_steps_to_goal = [] # SAFETY\n",
    "metric_hardbrake = [] # COMFORT\n",
    "metric_cumulated_reward = []\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    print(\"====> Start episode {}\".format(episode))\n",
    "    env.reset()\n",
    "    cumulated_reward = 0\n",
    "    images = []\n",
    "    \n",
    "    hardbrake = 0    \n",
    "    for n in range(max_steps):\n",
    "        action = 0\n",
    "        #action = np.random.randint(low=-2,high=3) \n",
    "        if action <= -2:\n",
    "            hardbrake += 1\n",
    "        state, reward, done, info = env.step(action)\n",
    "        env.penalty(state)\n",
    "        cumulated_reward += reward\n",
    "        print(\"Step {}: action={} reward={} done={}\".format(n, action, reward, done)) # PHW DEBUG\n",
    "        img = env.render()\n",
    "        images.append(img)\n",
    "        if done is True:\n",
    "            if info == \"success\":\n",
    "                metric_success += 1\n",
    "                metric_steps_to_goal.append(n)\n",
    "                metric_hardbrake.append(hardbrake)\n",
    "                metric_cumulated_reward.append(cumulated_reward)\n",
    "            print(\"End of episode {} with cumulated_reward {}\".format(episode, cumulated_reward))\n",
    "            break\n",
    "\n",
    "print(\"METRICS: REWARD AvgCumulatedReward = {}\".format(np.mean(metric_cumulated_reward)))\n",
    "print(\"METRICS: SAFETY %collisions = {}, COMFORT MeanHardBrake = {}, EFFICIENCY MeanStepsToGoal = {}\".format(1-metric_success/max_episodes, np.mean(metric_hardbrake), np.mean(metric_steps_to_goal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "1\n",
      "[49]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(metric_hardbrake)\n",
    "print(metric_success)\n",
    "print(metric_steps_to_goal)\n",
    "print(max_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(images[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageio.mimsave('img/visu.gif', images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu2.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_images = resize_images(images, f=2)\n",
    "imageio.mimsave('img/visu2.gif', big_images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu2.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
