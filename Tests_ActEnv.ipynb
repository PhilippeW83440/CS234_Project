{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-03-05 16:51:28,700] Making new env: Act-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 17460018659593759927\n",
      "[100   0   0  20  43 181  13   4  36  25  19   2  33  87  19   0  20  63\n",
      "  16   0   6  47  17   4 151 110 -16  -4 169  91 -16  -3 175 161 -16   0\n",
      " 171 164 -18  -1 170  49 -13  -2]\n"
     ]
    }
   ],
   "source": [
    "# to install gym_act:\n",
    "# git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# cd gym-act\n",
    "# pip install -e .\n",
    "import gym_act\n",
    "\n",
    "# source code is in https://github.com/PhilippeW83440/CS234_Project/blob/master/gym-act/gym_act/envs/act_env.py\n",
    "# or if you did: git clone https://github.com/PhilippeW83440/CS234_Project.git\n",
    "# in CS234_Project/gym-act/gym_act/envs/act_env.py\n",
    "env = gym.make(\"Act-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -76.68876729219286\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "obs, reward, done, info = env.step(action)\n",
    "print(\"reward {}\".format(reward))\n",
    "img = env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def show_img(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def  resize_images(images, f=3):\n",
    "    big_images = []\n",
    "    for img in images:\n",
    "        big_images.append(cv2.resize(img, None, fx=f, fy=f))\n",
    "    return big_images\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Start episode 0\n",
      "[100   0   0  20  35  83  20   2  22  76  10   1   7 182  10   1  45 164\n",
      "  14   0  18  34  20   2 174  72 -16  -2 180 160 -11   0 181  96 -21  -2\n",
      " 156 125 -21  -3 155 180 -19   0]\n",
      "Step 0: action=0.0 reward=-75.30370087968163 done=False\n",
      "Step 1: action=0.0 reward=-77.5942966206093 done=False\n",
      "Step 2: action=0.0 reward=-79.88391016722936 done=False\n",
      "Step 3: action=0.0 reward=-82.17251655448307 done=False\n",
      "Step 4: action=0.0 reward=-84.46008920152308 done=False\n",
      "Step 5: action=0.0 reward=-86.74659977248324 done=False\n",
      "Step 6: action=0.0 reward=-89.03201802091131 done=False\n",
      "Step 7: action=0.0 reward=-91.31631161546605 done=False\n",
      "Step 8: action=0.0 reward=-94.53116479902133 done=False\n",
      "Step 9: action=0.0 reward=-97.43793671352891 done=False\n",
      "Step 10: action=0.0 reward=-100.16644677563656 done=False\n",
      "Step 11: action=0.0 reward=-102.8197390199079 done=False\n",
      "Step 12: action=0.0 reward=-105.42808463986196 done=False\n",
      "Step 13: action=0.0 reward=-108.00542885607774 done=False\n",
      "Step 14: action=0.0 reward=-107.27161935678625 done=False\n",
      "Step 15: action=0.0 reward=-109.54542333082486 done=False\n",
      "Step 16: action=0.0 reward=-109.51877995333014 done=False\n",
      "Step 17: action=0.0 reward=-107.14412778116684 done=False\n",
      "done: dist_nearest_obj 7.280109889280518, y-ego 76\n",
      "Step 18: action=0.0 reward=-1109.5238453979225 done=True\n",
      "End of episode 0 with cumulated_reward -2817.902039456452\n",
      "====> Start episode 1\n",
      "[100   0   0  20  47 143  16   4  31  51  12   3  35  99  24   0  27 115\n",
      "  13   4  24 140  21   2 187 109 -23   0 196 137 -10  -4 192 133 -10  -1\n",
      " 166  69 -15   0 163 129 -17   0]\n",
      "Step 0: action=0.0 reward=-77.97953843422526 done=False\n",
      "Step 1: action=0.0 reward=-79.97953843422526 done=False\n",
      "Step 2: action=0.0 reward=-81.97953843422526 done=False\n",
      "Step 3: action=0.0 reward=-83.97953843422526 done=False\n",
      "Step 4: action=0.0 reward=-85.97953843422526 done=False\n",
      "Step 5: action=0.0 reward=-87.97953843422526 done=False\n",
      "Step 6: action=0.0 reward=-89.97953843422526 done=False\n",
      "Step 7: action=0.0 reward=-91.97953843422526 done=False\n",
      "Step 8: action=0.0 reward=-93.97953843422526 done=False\n",
      "Step 9: action=0.0 reward=-95.97953843422528 done=False\n",
      "Step 10: action=0.0 reward=-97.97953843422526 done=False\n",
      "Step 11: action=0.0 reward=-99.97953843422525 done=False\n",
      "Step 12: action=0.0 reward=-101.97953843422526 done=False\n",
      "Step 13: action=0.0 reward=-103.97953843422526 done=False\n",
      "Step 14: action=0.0 reward=-105.97953843422528 done=False\n",
      "Step 15: action=0.0 reward=-107.97953843422526 done=False\n",
      "Step 16: action=0.0 reward=-109.97953843422525 done=False\n",
      "Step 17: action=0.0 reward=-104.18046156577473 done=False\n",
      "Step 18: action=0.0 reward=-106.18046156577475 done=False\n",
      "Step 19: action=0.0 reward=-108.18046156577473 done=False\n",
      "Step 20: action=0.0 reward=-95.78628088138043 done=False\n",
      "Step 21: action=0.0 reward=-97.73758074536603 done=False\n",
      "Step 22: action=0.0 reward=-99.65106350547359 done=False\n",
      "Step 23: action=0.0 reward=-101.52306701455774 done=False\n",
      "Step 24: action=0.0 reward=-103.34852492935559 done=False\n",
      "Step 25: action=0.0 reward=-105.1202648944905 done=False\n",
      "Step 26: action=0.0 reward=-106.82772941899371 done=False\n",
      "Step 27: action=0.0 reward=-108.45441334695549 done=False\n",
      "Step 28: action=0.0 reward=-109.97197379216807 done=False\n",
      "Step 29: action=0.0 reward=-104.4883618531077 done=False\n",
      "Step 30: action=0.0 reward=-107.69709042930668 done=False\n",
      "Step 31: action=0.0 reward=0.0 done=False\n",
      "Step 32: action=0.0 reward=0.0 done=False\n",
      "Step 33: action=0.0 reward=0.0 done=False\n",
      "Step 34: action=0.0 reward=0.0 done=False\n",
      "Step 35: action=0.0 reward=0.0 done=False\n",
      "Step 36: action=0.0 reward=0.0 done=False\n",
      "Step 37: action=0.0 reward=0.0 done=False\n",
      "Step 38: action=0.0 reward=0.0 done=False\n",
      "Step 39: action=0.0 reward=0.0 done=False\n",
      "Step 40: action=0.0 reward=0.0 done=False\n",
      "Step 41: action=0.0 reward=0.0 done=False\n",
      "Step 42: action=0.0 reward=0.0 done=False\n",
      "Step 43: action=0.0 reward=0.0 done=False\n",
      "Step 44: action=0.0 reward=0.0 done=False\n",
      "Step 45: action=0.0 reward=0.0 done=False\n",
      "Step 46: action=0.0 reward=0.0 done=False\n",
      "Step 47: action=0.0 reward=0.0 done=False\n",
      "Step 48: action=0.0 reward=0.0 done=False\n",
      "done: dist_nearest_obj 85.0235261559999, y-ego 200\n",
      "Step 49: action=0.0 reward=0.0 done=True\n",
      "End of episode 1 with cumulated_reward -3056.79988889031\n",
      "====> Start episode 2\n",
      "[100   0   0  20  20  96  21   2  25 103  17   1  31  47  18   4  47  74\n",
      "  20   4  21 127  23   1 195 160 -18  -4 162  44 -12   0 172  60 -24  -3\n",
      " 196  38 -19   0 191 152 -16  -1]\n",
      "Step 0: action=0.0 reward=-88.0449957911259 done=False\n",
      "Step 1: action=0.0 reward=-90.14900313804468 done=False\n",
      "Step 2: action=0.0 reward=-92.25236980405907 done=False\n",
      "Step 3: action=0.0 reward=-94.35508450826832 done=False\n",
      "Step 4: action=0.0 reward=-96.45713537672509 done=False\n",
      "Step 5: action=0.0 reward=-98.55850990440614 done=False\n",
      "Step 6: action=0.0 reward=-100.65919491376546 done=False\n",
      "Step 7: action=0.0 reward=-102.75917650949332 done=False\n",
      "Step 8: action=0.0 reward=-104.8584400290535 done=False\n",
      "Step 9: action=0.0 reward=-106.95696998851267 done=False\n",
      "Step 10: action=0.0 reward=-109.05475002310807 done=False\n",
      "Step 11: action=0.0 reward=-103.6355674948223 done=False\n",
      "done: dist_nearest_obj 8.602325267042627, y-ego 52\n",
      "Step 12: action=0.0 reward=-1105.7927339259784 done=True\n",
      "End of episode 2 with cumulated_reward -2293.5339314073626\n",
      "====> Start episode 3\n",
      "[100   0   0  20  42  95  10   0  30  88  11   1  44  93  21   3  30  49\n",
      "  17   1  23  75  16   0 156  91 -14  -4 188  33 -18  -3 150 121 -24   0\n",
      " 185  39 -23  -2 164 103 -12  -2]\n",
      "Step 0: action=0.0 reward=-78.97912592280521 done=False\n",
      "Step 1: action=0.0 reward=-81.08179115009811 done=False\n",
      "Step 2: action=0.0 reward=-83.18432722849946 done=False\n",
      "Step 3: action=0.0 reward=-85.2867344548772 done=False\n",
      "Step 4: action=0.0 reward=-87.38901311588116 done=False\n",
      "Step 5: action=0.0 reward=-89.49116348804979 done=False\n",
      "Step 6: action=0.0 reward=-91.59318583791287 done=False\n",
      "Step 7: action=0.0 reward=-93.69508042208992 done=False\n",
      "Step 8: action=0.0 reward=-95.79684748738457 done=False\n",
      "Step 9: action=0.0 reward=-97.89848727087491 done=False\n",
      "Step 10: action=0.0 reward=-100.0 done=False\n",
      "Step 11: action=0.0 reward=-102.10138589264233 done=False\n",
      "Step 12: action=0.0 reward=-104.20264515720677 done=False\n",
      "Step 13: action=0.0 reward=-106.30377799269566 done=False\n",
      "Step 14: action=0.0 reward=-108.40478458878019 done=False\n",
      "Step 15: action=0.0 reward=-101.05021792506366 done=False\n",
      "done: dist_nearest_obj 7.810249675906654, y-ego 68\n",
      "Step 16: action=0.0 reward=-1103.2913609753507 done=True\n",
      "End of episode 3 with cumulated_reward -2609.749928910212\n",
      "====> Start episode 4\n",
      "[100   0   0  20   1  43  24   2  26 138  21   1  47 109  17   0  38 134\n",
      "  19   4  12 117  23   0 158 134 -23  -4 189 153 -18  -2 190  59 -12   0\n",
      " 163 134 -12   0 172  25 -21  -1]\n",
      "Step 0: action=0.0 reward=0.0 done=False\n",
      "Step 1: action=0.0 reward=0.0 done=False\n",
      "Step 2: action=0.0 reward=0.0 done=False\n",
      "Step 3: action=0.0 reward=0.0 done=False\n",
      "Step 4: action=0.0 reward=0.0 done=False\n",
      "Step 5: action=0.0 reward=0.0 done=False\n",
      "Step 6: action=0.0 reward=0.0 done=False\n",
      "Step 7: action=0.0 reward=0.0 done=False\n",
      "Step 8: action=0.0 reward=0.0 done=False\n",
      "Step 9: action=0.0 reward=0.0 done=False\n",
      "Step 10: action=0.0 reward=0.0 done=False\n",
      "Step 11: action=0.0 reward=0.0 done=False\n",
      "Step 12: action=0.0 reward=0.0 done=False\n",
      "Step 13: action=0.0 reward=0.0 done=False\n",
      "Step 14: action=0.0 reward=0.0 done=False\n",
      "Step 15: action=0.0 reward=-93.40046216218786 done=False\n",
      "Step 16: action=0.0 reward=-96.17994974842648 done=False\n",
      "Step 17: action=0.0 reward=-98.705010166098 done=False\n",
      "Step 18: action=0.0 reward=-100.91369401424322 done=False\n",
      "Step 19: action=0.0 reward=-102.98619585308855 done=False\n",
      "Step 20: action=0.0 reward=-105.0 done=False\n",
      "Step 21: action=0.0 reward=-106.99933595746094 done=False\n",
      "Step 22: action=0.0 reward=-108.99735399262718 done=False\n",
      "Step 23: action=0.0 reward=-97.07932587535896 done=False\n",
      "done: dist_nearest_obj 9.055385138137417, y-ego 100\n",
      "Step 24: action=0.0 reward=-1099.0288552067423 done=True\n",
      "End of episode 4 with cumulated_reward -2009.2901829762334\n",
      "METRICS: SAFETY %collisions = 0.8, COMFORT MeanHardBrake = 0.0, EFFICIENCY MeanStepsToGoal = 49.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_episodes = 5\n",
    "max_steps = 120\n",
    "\n",
    "# METRICS\n",
    "metric_success = 0 # EFFICIENCY\n",
    "metric_steps_to_goal = [] # SAFETY\n",
    "metric_hardbrake = [] # COMFORT\n",
    "\n",
    "for episode in range(max_episodes):\n",
    "    print(\"====> Start episode {}\".format(episode))\n",
    "    env.reset()\n",
    "    cumulated_reward = 0\n",
    "    images = []\n",
    "    \n",
    "    hardbrake = 0    \n",
    "    for n in range(max_steps):\n",
    "        action = 0.0\n",
    "        if action <= -2:\n",
    "            hardbrake += 1\n",
    "        state, reward, done, info = env.step(action)\n",
    "        cumulated_reward += reward\n",
    "        print(\"Step {}: action={} reward={} done={}\".format(n, action, reward, done)) # PHW DEBUG\n",
    "        img = env.render()\n",
    "        images.append(img)\n",
    "        if done is True:\n",
    "            if info == \"success\":\n",
    "                metric_success += 1\n",
    "                metric_steps_to_goal.append(n)\n",
    "                metric_hardbrake.append(hardbrake)\n",
    "            print(\"End of episode {} with cumulated_reward {}\".format(episode, cumulated_reward))\n",
    "            break\n",
    "            \n",
    "print(\"METRICS: SAFETY %collisions = {}, COMFORT MeanHardBrake = {}, EFFICIENCY MeanStepsToGoal = {}\".format(1-metric_success/max_episodes, np.mean(metric_hardbrake), np.mean(metric_steps_to_goal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "1\n",
      "[49]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(metric_hardbrake)\n",
    "print(metric_success)\n",
    "print(metric_steps_to_goal)\n",
    "print(max_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJCCAYAAADQsoPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(images[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageio.mimsave('img/visu.gif', images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/visu2.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_images = resize_images(images, f=2)\n",
    "imageio.mimsave('img/visu2.gif', big_images, duration=0.2)\n",
    "HTML(\"\"\"<img src=\"img/visu2.gif\"/>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
